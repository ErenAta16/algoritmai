import os
from openai import OpenAI
from typing import Dict, List, Optional
from services.algorithm_recommender import AlgorithmRecommender
from dotenv import load_dotenv
import random

# Load environment variables from .env file
load_dotenv()

class OpenAIService:
    def __init__(self):
        """
        Advanced Hybrid AI-powered algorithm consultant with intelligent fallback
        """
        self.algorithm_recommender = AlgorithmRecommender()
        
        # Initialize OpenAI with modern client
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key and api_key != 'your_openai_api_key_here':
            try:
                self.openai_client = OpenAI(api_key=api_key)
                # Test the connection
                self.openai_client.models.list()
                self.openai_enabled = True
                print("âœ… OpenAI API successfully initialized and tested")
            except Exception as e:
                print(f"âš ï¸ OpenAI API issue (quota/connection): {str(e)[:100]}...")
                self.openai_enabled = False
                self.openai_client = None
        else:
            self.openai_enabled = False
            self.openai_client = None
            print("âš ï¸ OpenAI API key not found, using advanced fallback system")
        
        # Always use our advanced AI system regardless of OpenAI status
        self.use_advanced_ai = True
        print("ğŸ¤– Advanced AI Algorithm Consultant initialized with intelligent conversation engine")
        
        # System prompts for different scenarios
        self.algorithm_expert_prompt = """Sen deneyimli bir makine Ã¶ÄŸrenmesi algoritma uzmanÄ±sÄ±n. KullanÄ±cÄ±lara algoritma Ã¶nerileri verirken:

1. Paragraf halinde, akÄ±cÄ± ve detaylÄ± aÃ§Ä±klamalar yap
2. Teknik terimleri aÃ§Ä±kla ama anlaÅŸÄ±lÄ±r tut
3. GerÃ§ek dÃ¼nya Ã¶rnekleri ver
4. Avantaj ve dezavantajlarÄ± dengeli ÅŸekilde aÃ§Ä±kla
5. Pratik uygulama ipuÃ§larÄ± ekle
6. TÃ¼rkÃ§e konuÅŸ ve dostane bir ton kullan

Algoritma veri setinde ÅŸu kodlama sistemi kullanÄ±lÄ±yor:
- Ã–ÄŸrenme tÃ¼rÃ¼: sl (Supervised), ul (Unsupervised), ssl (Semi-supervised), rl (Reinforcement)
- KullanÄ±m alanÄ±: cl (Classification), re (Regression), ts (Time Series), np (NLP), vb.
- KarmaÅŸÄ±klÄ±k: comp1-comp5 (1=basit, 5=Ã§ok karmaÅŸÄ±k)
- Veri bÃ¼yÃ¼klÃ¼ÄŸÃ¼: MB, MB-GB, GB, GB-TB, TB
- PopÃ¼lerlik: p1-p5 (1=az popÃ¼ler, 5=Ã§ok popÃ¼ler)

Her zaman paragraf ÅŸeklinde detaylÄ± aÃ§Ä±klamalar yap."""

        self.consultation_prompt = """Sen bir makine Ã¶ÄŸrenmesi danÄ±ÅŸmanÄ±sÄ±n. KullanÄ±cÄ±larÄ±n proje gereksinimlerini anlamaya Ã§alÄ±ÅŸÄ±yorsun. 

GÃ¶revin:
1. Eksik bilgileri nazikÃ§e sor
2. Paragraf halinde, samimi ve yÃ¶nlendirici konuÅŸ
3. KullanÄ±cÄ±nÄ±n seviyesine uygun aÃ§Ä±klamalar yap
4. Projenin hedefini net anlayÄ±p doÄŸru yÃ¶nlendir
5. TÃ¼rkÃ§e konuÅŸ ve dostane ol

KÄ±sa listeler yerine akÄ±cÄ± paragraflar halinde konuÅŸ."""
    
    def get_chat_response(self, user_message: str, conversation_history: Optional[List[Dict]] = None) -> Dict:
        """
        Hybrid AI response: OpenAI + Custom Algorithm Model
        """
        try:
            # Handle None or empty messages
            if user_message is None:
                user_message = ""
            
            print(f"\nğŸ” Processing: '{user_message}'")
            
            # Analyze project context from conversation
            project_context = self._extract_project_context(user_message, conversation_history)
            print(f"ğŸ“Š Project Context: {project_context}")
            
            # Check if user is asking algorithm-specific questions (don't restart consultation)
            if self._is_algorithm_specific_question(user_message, project_context):
                return self._handle_algorithm_question(user_message, project_context)
            
            # Check if we have enough info for algorithm recommendation
            if self._should_recommend_algorithms(project_context):
                return self._generate_algorithm_recommendations(user_message, project_context)
            else:
                return self._generate_consultation_response(user_message, project_context)
                
        except Exception as e:
            print(f"âŒ Error in AI service: {str(e)}")
            return self._get_emergency_fallback()
    
    def _extract_project_context(self, current_message: str, conversation_history: Optional[List[Dict]] = None) -> Dict:
        """
        Extract project context using AI analysis
        """
        # Handle None or empty messages
        if current_message is None:
            current_message = ""
            
        context = {
            'project_type': None,
            'data_size': None,
            'data_type': None,
            'class_count': None,
            'use_case': None,
            'constraints': [],
            'mentioned_algorithms': [],
            'conversation_stage': 'information_gathering'
        }
        
        # Combine all conversation content
        full_conversation = ""
        if conversation_history:
            for msg in conversation_history[-10:]:  # Last 10 messages
                if isinstance(msg, dict):
                    role = msg.get('role', '')
                    content = msg.get('content', '')
                    full_conversation += f"{role}: {content}\n"
        
        full_conversation += f"user: {current_message}"
        
        # Enhanced pattern matching with AI-like context understanding
        text_lower = full_conversation.lower()
        
        # Project type detection (more sophisticated)
        if any(word in text_lower for word in ['sÄ±nÄ±flandÄ±rma', 'classification', 'kategorilere ayÄ±r', 'sÄ±nÄ±flama', 'tahmin et', 'predict class']):
            context['project_type'] = 'classification'
        elif any(word in text_lower for word in ['kÃ¼meleme', 'clustering', 'segmentasyon', 'gruplama', 'segment']):
            context['project_type'] = 'clustering'
        elif any(word in text_lower for word in ['regresyon', 'regression', 'deÄŸer tahmin', 'fiyat tahmin', 'forecast']):
            context['project_type'] = 'regression'
        elif any(word in text_lower for word in ['anomali', 'outlier', 'anormal', 'dolandÄ±rÄ±cÄ±lÄ±k', 'fraud']):
            context['project_type'] = 'anomaly_detection'
        elif any(word in text_lower for word in ['Ã¶neri', 'recommendation', 'tavsiye', 'suggest']):
            context['project_type'] = 'recommendation'
        
        # Data type detection (more intelligent defaults)
        if any(word in text_lower for word in ['sayÄ±sal', 'numerical', 'numeric', 'number', 'regresyon', 'regression']):
            context['data_type'] = 'numerical'
        elif any(word in text_lower for word in ['kategorik', 'categorical', 'category']):
            context['data_type'] = 'categorical'
        elif any(word in text_lower for word in ['metin', 'text', 'kelime', 'word']):
            context['data_type'] = 'text'
        elif any(word in text_lower for word in ['gÃ¶rÃ¼ntÃ¼', 'image', 'resim', 'photo']):
            context['data_type'] = 'image'
        elif context.get('project_type'):
            # Default to numerical if project type is known but data type isn't specified
            context['data_type'] = 'numerical'
            
        # Data size defaults (more intelligent guessing)
        import re
        numbers = re.findall(r'\d+', text_lower)
        size_detected = False
        for num in numbers:
            num_val = int(num)
            if num_val < 1000:
                context['data_size'] = 'small'
                size_detected = True
                break
            elif num_val < 10000:
                context['data_size'] = 'medium'
                size_detected = True
                break
            else:
                context['data_size'] = 'large'
                size_detected = True
                break
        
        # Default data size if not detected but project type is known        
        if not size_detected and context.get('project_type'):
            context['data_size'] = 'medium'  # Safe default
                
        # Class count for classification
        if context['project_type'] == 'classification':
            if any(word in text_lower for word in ['2 sÄ±nÄ±f', 'binary', 'ikili', 'two class']):
                context['class_count'] = 'binary'
            elif any(word in text_lower for word in ['3', '4', '5', 'few', 'az sÄ±nÄ±f']):
                context['class_count'] = 'multiclass'
            elif any(word in text_lower for word in ['Ã§ok sÄ±nÄ±f', 'many class', 'multiple']):
                context['class_count'] = 'multilabel'
            else:
                # Default to multiclass if classification is detected but no specific count given
                context['class_count'] = 'multiclass'
        
        # Extract mentioned algorithms
        algorithms = ['xgboost', 'random forest', 'svm', 'neural network', 'logistic regression', 'naive bayes', 'knn', 'decision tree']
        for algo in algorithms:
            if algo in text_lower:
                context['mentioned_algorithms'].append(algo)
        
        return context
    
    def _is_algorithm_specific_question(self, user_message: str, context: Dict) -> bool:
        """
        Check if user is asking specific questions about algorithms
        """
        user_msg_lower = user_message.lower()
        
        # Specific algorithm names that should always be handled regardless of context
        specific_algorithms = [
            'xgboost', 'random forest', 'svm', 'neural network', 'logistic regression',
            'holt-winters', 'linear regression', 'decision tree', 'naive bayes',
            'k-means', 'dbscan', 'pca', 'lstm', 'cnn', 'bert', 'transformer'
        ]
        
        # Algorithm-specific keywords that should bypass consultation
        algorithm_keywords = [
            'nasÄ±l uygulanÄ±r', 'karÅŸÄ±laÅŸtÄ±r', 'kod Ã¶rneÄŸi', 'performans', 
            'implementasyon', 'hangi algoritma', 'detay', 'aÃ§Ä±kla',
            'Ã¶rnek gÃ¶ster', 'nasÄ±l yapÄ±lÄ±r', 'kÄ±yasla', 'comparison', 'compare',
            'nasÄ±l Ã§alÄ±ÅŸÄ±r', 'avantaj', 'dezavantaj', 'ne zaman kullan',
            'performans karÅŸÄ±laÅŸtÄ±r', 'algoritma karÅŸÄ±laÅŸtÄ±r', 'hangisi daha iyi'
        ]
        
        # Check for specific algorithm names (these are handled regardless of context)
        contains_specific_algo = any(algo in user_msg_lower for algo in specific_algorithms)
        
        # Check for algorithm-specific keywords
        contains_algo_keyword = any(keyword in user_msg_lower for keyword in algorithm_keywords)
        
        # If user mentions specific algorithm, handle immediately
        if contains_specific_algo:
            return True
            
        # For general algorithm questions, we're more flexible now
        # Performance comparison and code examples should always be handled
        if contains_algo_keyword:
            # These specific types should always be handled
            if any(word in user_msg_lower for word in ['performans', 'karÅŸÄ±laÅŸtÄ±r', 'kod Ã¶rneÄŸi', 'nasÄ±l uygulanÄ±r']):
                return True
            # For other algorithm keywords, require some context
            has_minimum_info = context.get('project_type') is not None
            return has_minimum_info
        
        return False
    
    def _handle_algorithm_question(self, user_message: str, context: Dict) -> Dict:
        """
        Handle specific algorithm questions without restarting consultation
        """
        user_msg_lower = user_message.lower()
        
        # Code example requests
        if 'kod Ã¶rneÄŸi' in user_msg_lower or 'nasÄ±l uygulanÄ±r' in user_msg_lower:
            return self._generate_code_example(user_message, context)
        
        # Performance comparison requests
        elif 'performans' in user_msg_lower or 'karÅŸÄ±laÅŸtÄ±r' in user_msg_lower:
            return self._generate_performance_comparison(context)
        
        # Algorithm explanation requests - expanded keywords
        elif any(word in user_msg_lower for word in ['detay', 'aÃ§Ä±kla', 'nedir', 'nasÄ±l Ã§alÄ±ÅŸÄ±r', 'ne yapar', 'avantaj', 'dezavantaj', 'ne zaman kullan']):
            return self._generate_algorithm_explanation(user_message, context)
        
        # Default: generate new recommendations
        else:
            return self._generate_algorithm_recommendations(user_message, context)
    
    def _generate_code_example(self, user_message: str, context: Dict) -> Dict:
        """
        Generate code examples using GPT-4 or enhanced fallback system
        """
        # Try GPT-4 first for personalized code examples
        if self.openai_enabled and self.openai_client:
            try:
                return self._generate_gpt4_code_example(user_message, context)
            except Exception as e:
                print(f"âš ï¸ GPT-4 code generation failed, using template: {e}")
        
        # Fallback to template system
        return self._generate_template_code_example(user_message, context)
    
    def _generate_gpt4_code_example(self, user_message: str, context: Dict) -> Dict:
        """
        Generate personalized code examples using GPT-4
        """
        project_type = context.get('project_type', 'classification')
        data_size = context.get('data_size', 'medium')
        
        # Detect which algorithm user is asking about
        user_msg_lower = user_message.lower()
        algorithm = "genel"
        
        for algo in ['xgboost', 'random forest', 'svm', 'neural network', 'logistic regression', 'holt-winters', 'linear regression']:
            if algo in user_msg_lower:
                algorithm = algo
                break
        
        context_info = f"""
Proje tÃ¼rÃ¼: {project_type}
Veri boyutu: {data_size}
Veri tÃ¼rÃ¼: {context.get('data_type', 'numerical')}
Ä°stenilen algoritma: {algorithm}
KullanÄ±cÄ± sorusu: "{user_message}"
"""
        
        prompt = f"""
Sen senior-level bir makine Ã¶ÄŸrenmesi uzmanÄ± ve Python geliÅŸtiricisisin. KullanÄ±cÄ±ya industry-standard, production-ready kod Ã¶rnekleri sunuyorsun.

{context_info}

LÃ¼tfen profesyonel bir danÄ±ÅŸman gibi:

ğŸ“‹ **Kod Kalitesi:**
- Clean, readable ve well-documented Python kodu yaz
- Best practices ve design patterns kullan
- Error handling ve edge case'leri dahil et
- Type hints ve docstring'ler ekle

ğŸ¯ **Algoritma SeÃ§imi:**
- Projenin gereksinimlerine gÃ¶re en optimal algoritmalarÄ± Ã¶ner
- Hyperparameter tuning stratejileri sun
- Performance optimization ipuÃ§larÄ± ver
- Cross-validation ve model evaluation detaylarÄ± ekle

ğŸ’¡ **AÃ§Ä±klamalar:**
- Teknik detaylarÄ± paragraf halinde aÃ§Ä±kla
- AlgoritmanÄ±n Ã§alÄ±ÅŸma prensiplerini anlat
- Ne zaman hangi algoritmanÄ±n kullanÄ±lacaÄŸÄ±nÄ± belirt
- Production environment iÃ§in deployment ipuÃ§larÄ± ver

ğŸš€ **Professional Touch:**
- Industry best practices dahil et
- Scalability ve maintainability dikkate al
- Memory ve computational efficiency Ã¶nerileri sun
- Real-world kullanÄ±m senaryolarÄ±nÄ± anlat

YanÄ±tÄ±n hem teknik derinlikte hem de kolayca uygulanabilir olsun. Senior developer seviyesinde kod ve aÃ§Ä±klama bekliyorum.
"""
        
        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": f"Bu proje iÃ§in {algorithm} algoritmasÄ±nÄ±n Python implementasyonunu ve aÃ§Ä±klamasÄ±nÄ± verir misin?"}
        ]
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o",  # Use the latest GPT-4 Omni model for best quality
            messages=messages,
            max_tokens=1500,  # Increased for more detailed responses
            temperature=0.2   # Lower temperature for more consistent professional responses
        )
        
        gpt_response = response.choices[0].message.content
        
        suggestions = [
            "Hiperparametre optimizasyonu",
            "Cross-validation ekleme",
            "Feature engineering ipuÃ§larÄ±",
            "BaÅŸka algoritma kodu"
        ]
        
        return {
            "response": gpt_response,
            "suggestions": suggestions,
            "success": True,
            "ai_powered": True
        }
    
    def _generate_template_code_example(self, user_message: str, context: Dict) -> Dict:
        """
        Enhanced template-based code examples with detailed explanations
        """
        project_type = context.get('project_type', 'classification')
        
        if 'xgboost' in user_message.lower() or 'random forest' in user_message.lower():
            algo_name = 'XGBoost' if 'xgboost' in user_message.lower() else 'Random Forest'
            
            if project_type == 'classification':
                code_example = f"""**{algo_name} ile SÄ±nÄ±flandÄ±rma - DetaylÄ± Uygulama:**

Bu algoritma {context.get('data_size', 'orta')} boyuttaki veri setiniz iÃ§in mÃ¼kemmel bir seÃ§im. Hem yÃ¼ksek performans hem de gÃ¼venilirlik sunar.

```python
# Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleme
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt

# Veri yÃ¼kleme ve ilk inceleme
df = pd.read_csv('your_data.csv')
print(f"Veri seti boyutu: {{df.shape}}")
print(f"Eksik deÄŸer sayÄ±sÄ±: {{df.isnull().sum().sum()}}")

# Ã–zellik ve hedef deÄŸiÅŸkenleri ayÄ±rma
X = df.drop('target_column', axis=1)  # Hedef sÃ¼tununuzun adÄ±nÄ± yazÄ±n
y = df['target_column']

# Veriyi eÄŸitim ve test olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Random Forest modelini oluÅŸturma ve eÄŸitme
# n_estimators: AÄŸaÃ§ sayÄ±sÄ± (daha fazla = daha iyi performans ama yavaÅŸ)
# max_depth: AÄŸaÃ§larÄ±n maksimum derinliÄŸi (overfitting'i kontrol eder)
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42,
    n_jobs=-1  # TÃ¼m CPU'larÄ± kullan
)

# Modeli eÄŸitme
print("Model eÄŸitiliyor...")
rf_model.fit(X_train, y_train)

# Tahmin yapma
y_pred = rf_model.predict(X_test)
y_pred_proba = rf_model.predict_proba(X_test)

# Performans deÄŸerlendirme
accuracy = accuracy_score(y_test, y_pred)
print(f"DoÄŸruluk oranÄ±: {{accuracy:.3f}}")

# DetaylÄ± performans raporu
print("\\nDetaylÄ± Performans Raporu:")
print(classification_report(y_test, y_pred))

# Cross-validation ile daha gÃ¼venilir performans Ã¶lÃ§Ã¼mÃ¼
cv_scores = cross_val_score(rf_model, X, y, cv=5)
print(f"\\n5-Fold CV Ortalama DoÄŸruluk: {{cv_scores.mean():.3f}} (+/- {{cv_scores.std()*2:.3f}})")

# Ã–zellik Ã¶nemlerini gÃ¶rÃ¼ntÃ¼leme
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\\nEn Ã¶nemli Ã¶zellikler:")
print(feature_importance.head(10))
```

**Ã–nemli Ä°puÃ§larÄ±:**

Veri setinizin boyutuna gÃ¶re parametreleri ayarlayÄ±n. KÃ¼Ã§Ã¼k veri setlerde n_estimators=50-100 yeterli, bÃ¼yÃ¼k veri setlerde 200-500 arasÄ± deneyebilirsiniz. max_depth parametresi overfitting'i kontrol eder - baÅŸlangÄ±Ã§ iÃ§in 10-15 arasÄ±nda deneyin.

Model eÄŸitildikten sonra feature_importance deÄŸerleriyle hangi Ã¶zelliklerin en Ã§ok etkili olduÄŸunu gÃ¶rebilirsiniz. Bu size veri anlama konusunda bÃ¼yÃ¼k insight verir."""
            else:
                code_example = f"""**{algo_name} ile Regresyon - KapsamlÄ± Uygulama:**

SayÄ±sal tahmin problemleriniz iÃ§in {algo_name} mÃ¼kemmel bir seÃ§im. Ã–zellikle {context.get('data_size', 'orta')} boyuttaki veri setlerde Ã§ok baÅŸarÄ±lÄ±.

```python
# Gerekli kÃ¼tÃ¼phaneler
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt

# Veri hazÄ±rlama
df = pd.read_csv('your_regression_data.csv')
X = df.drop('target_column', axis=1)
y = df['target_column']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Model oluÅŸturma - regresyon iÃ§in optimize edilmiÅŸ parametreler
rf_regressor = RandomForestRegressor(
    n_estimators=100,
    max_depth=15,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)

# Model eÄŸitimi
rf_regressor.fit(X_train, y_train)

# Tahminler
y_pred = rf_regressor.predict(X_test)

# Performans metrikleri
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)

print(f"Model PerformansÄ±:")
print(f"RÂ² Score: {{r2:.3f}}")
print(f"RMSE: {{rmse:.3f}}")
print(f"MAE: {{mae:.3f}}")

# Tahmin vs GerÃ§ek deÄŸerler grafiÄŸi
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('GerÃ§ek DeÄŸerler')
plt.ylabel('Tahmin Edilen DeÄŸerler')
plt.title('Tahmin vs GerÃ§ek DeÄŸerler')
plt.show()
```

Bu kod size hem model performansÄ±nÄ± hem de tahminlerin gÃ¶rsel analizini saÄŸlar. RÂ² deÄŸeri 0.8'in Ã¼stÃ¼ndeyse modeliniz Ã§ok baÅŸarÄ±lÄ± demektir."""
        else:
            code_example = f"""**Genel Machine Learning Pipeline - {project_type.title()} iÃ§in:**

Projeniz iÃ§in kapsamlÄ± bir baÅŸlangÄ±Ã§ ÅŸablonu hazÄ±rladÄ±m. Bu kod yapÄ±sÄ±nÄ± temel alarak istediÄŸiniz algoritmalarÄ± deneyebilirsiniz.

```python
# Temel kÃ¼tÃ¼phaneler
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Veri YÃ¼kleme ve Ä°nceleme
print("=== VERÄ° ANALÄ°ZÄ° ===")
df = pd.read_csv('your_data.csv')
print(f"Veri boyutu: {{df.shape}}")
print(f"SÃ¼tunlar: {{list(df.columns)}}")
print(f"\\nVeri tipleri:\\n{{df.dtypes}}")
print(f"\\nEksik deÄŸerler:\\n{{df.isnull().sum()}}")

# 2. Veri Ã–n Ä°ÅŸleme
print("\\n=== VERÄ° Ã–N Ä°ÅLEME ===")

# Kategorik deÄŸiÅŸkenleri encode etme
categorical_columns = df.select_dtypes(include=['object']).columns
for col in categorical_columns:
    if col != 'target_column':  # Hedef deÄŸiÅŸken deÄŸilse
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))

# Ã–zellik ve hedef ayÄ±rma
X = df.drop('target_column', axis=1)
y = df['target_column']

# Verileri normalize etme (Ã¶nemli!)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. Model SeÃ§imi ve EÄŸitimi
print("\\n=== MODEL EÄÄ°TÄ°MÄ° ===")
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# Buraya istediÄŸiniz algoritmanÄ±n kodunu ekleyebilirsiniz
# Ã–rnek: RandomForestClassifier, SVM, XGBoost vb.

print("Model baÅŸarÄ±yla eÄŸitildi!")
print("Åimdi istediÄŸiniz algoritma kodunu ekleyebilirsiniz.")
```

Bu temel yapÄ±yÄ± kullanarak istediÄŸiniz algoritmanÄ±n detaylÄ± kodunu sorabilirsiniz. Hangi algoritma ile devam etmek istersiniz?"""
        
        return {
            "response": code_example,
            "suggestions": [
                "XGBoost kodu",
                "SVM implementasyonu",
                "Hiperparametre optimizasyonu",
                "Cross-validation ekleme"
            ],
            "success": True
        }
    
    def _generate_performance_comparison(self, context: Dict) -> Dict:
        """
        Generate performance comparison between algorithms
        """
        project_type = context.get('project_type', 'classification')
        data_size = context.get('data_size', 'medium')
        
        if project_type == 'classification':
            comparison = """SÄ±nÄ±flandÄ±rma AlgoritmalarÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±:

1. Logistic Regression
   - DoÄŸruluk: Orta
   - HÄ±z: Ã‡ok hÄ±zlÄ±
   - AnlaÅŸÄ±labilirlik: Ã‡ok kolay
   - En iyi: KÃ¼Ã§Ã¼k veri setleri

2. Random Forest
   - DoÄŸruluk: Ä°yi
   - HÄ±z: Orta
   - AnlaÅŸÄ±labilirlik: Kolay
   - En iyi: Genel kullanÄ±m

3. XGBoost
   - DoÄŸruluk: Ã‡ok iyi
   - HÄ±z: Orta
   - AnlaÅŸÄ±labilirlik: Zor
   - En iyi: BÃ¼yÃ¼k veri setleri

4. SVM
   - DoÄŸruluk: Ä°yi
   - HÄ±z: YavaÅŸ
   - AnlaÅŸÄ±labilirlik: Zor
   - En iyi: KÃ¼Ã§Ã¼k, karmaÅŸÄ±k veriler

"""
            if data_size == 'small':
                comparison += "KÃ¼Ã§Ã¼k veri setiniz iÃ§in: Logistic Regression veya SVM Ã¶nerilir."
            elif data_size == 'large':
                comparison += "BÃ¼yÃ¼k veri setiniz iÃ§in: XGBoost veya Random Forest Ã¶nerilir."
            else:
                comparison += "Genel kullanÄ±m iÃ§in: Random Forest ile baÅŸlayÄ±n."
        else:
            comparison = """Regresyon AlgoritmalarÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±:

1. Linear Regression
   - DoÄŸruluk: Orta
   - HÄ±z: Ã‡ok hÄ±zlÄ±
   - AnlaÅŸÄ±labilirlik: Ã‡ok kolay

2. Random Forest
   - DoÄŸruluk: Ä°yi
   - HÄ±z: Orta
   - AnlaÅŸÄ±labilirlik: Kolay

3. XGBoost
   - DoÄŸruluk: Ã‡ok iyi
   - HÄ±z: Orta
   - AnlaÅŸÄ±labilirlik: Zor

En iyi seÃ§im veri setinizin boyutuna baÄŸlÄ±dÄ±r."""
        
        return {
            "response": comparison,
            "suggestions": [
                "Hangi metrik kullanmalÄ±yÄ±m?",
                "Cross-validation nasÄ±l yapÄ±lÄ±r?",
                "Hiperparametre optimizasyonu"
            ],
            "success": True
        }
    
    def _generate_algorithm_explanation(self, user_message: str, context: Dict) -> Dict:
        """
        Generate detailed explanation about specific algorithms
        """
        explanations = {
            'xgboost': """
ğŸ† **XGBoost (Extreme Gradient Boosting):**

**Ne yapar?**
ZayÄ±f Ã¶ÄŸrenicileri (karar aÄŸaÃ§larÄ±) sÄ±ralÄ± olarak birleÅŸtirerek gÃ¼Ã§lÃ¼ bir model oluÅŸturur.

**AvantajlarÄ±:**
âœ… Ã‡ok yÃ¼ksek doÄŸruluk
âœ… Eksik verilerle baÅŸa Ã§Ä±kabilir
âœ… Ã–zellik Ã¶nemini gÃ¶sterir
âœ… BÃ¼yÃ¼k veri setlerinde hÄ±zlÄ±

**DezavantajlarÄ±:**
âŒ KarmaÅŸÄ±k hiperparametre ayarÄ±
âŒ Overfitting eÄŸilimi
âŒ YorumlanmasÄ± zor

**Ne zaman kullanmalÄ±?**
â€¢ Maksimum performans istediÄŸinizde
â€¢ YarÄ±ÅŸmalarda (Kaggle'da Ã§ok popÃ¼ler)
â€¢ BÃ¼yÃ¼k ve karmaÅŸÄ±k veri setlerinde
""",
            'random forest': """
ğŸŒ³ **Random Forest:**

**Ne yapar?**
BirÃ§ok karar aÄŸacÄ±nÄ± aynÄ± anda eÄŸitir ve sonuÃ§larÄ±nÄ± birleÅŸtirir.

**AvantajlarÄ±:**
âœ… Overfitting'e direnÃ§li
âœ… DeÄŸiÅŸken Ã¶nemini gÃ¶sterir
âœ… Eksik verilerle Ã§alÄ±ÅŸabilir
âœ… Hem classification hem regression

**DezavantajlarÄ±:**
âŒ BÃ¼yÃ¼k model boyutu
âŒ GerÃ§ek zamanlÄ± tahminlerde yavaÅŸ olabilir

**Ne zaman kullanmalÄ±?**
â€¢ GÃ¼venilir bir baÅŸlangÄ±Ã§ algoritmasÄ± olarak
â€¢ Ã–zellik Ã¶nemini anlamak iÃ§in
â€¢ Hem hÄ±z hem doÄŸruluk istediÄŸinizde
""",
            'holt-winters': """
ğŸ“ˆ **Holt-Winters (Triple Exponential Smoothing):**

**Ne yapar?**
Zaman serisi verilerindeki trend, sezonluk ve seviye bileÅŸenlerini ayrÄ± ayrÄ± modelleyerek gelecek tahminleri yapar.

**AvantajlarÄ±:**
âœ… Sezonsal verilerde Ã§ok baÅŸarÄ±lÄ±
âœ… Trend ve mevsimsellik yakalar
âœ… Yorumlanabilir sonuÃ§lar
âœ… Hesaplama aÃ§Ä±sÄ±ndan hÄ±zlÄ±

**DezavantajlarÄ±:**
âŒ Sadece zaman serisi verileri iÃ§in
âŒ Ani deÄŸiÅŸimlere karÅŸÄ± hassas
âŒ Parametrelerin doÄŸru ayarlanmasÄ± gerekli

**Ne zaman kullanmalÄ±?**
â€¢ Mevsimsel satÄ±ÅŸ tahminleri
â€¢ Enerji tÃ¼ketim projeksiyonlarÄ±
â€¢ DÃ¼zenli dÃ¶ngÃ¼sel veriler
â€¢ KÄ±sa-orta vadeli tahminler

**Python Ã–rneÄŸi:**
```python
from statsmodels.tsa.holtwinters import ExponentialSmoothing

# Model oluÅŸturma
model = ExponentialSmoothing(data, trend='add', seasonal='add')
fitted_model = model.fit()

# Tahmin yapma
forecast = fitted_model.forecast(steps=12)
```
"""
        }
        
        user_msg_lower = user_message.lower()
        
        for algo, explanation in explanations.items():
            if algo in user_msg_lower:
                return {
                    "response": explanation,
                    "suggestions": [
                        f"{algo.title()} kod Ã¶rneÄŸi",
                        "Hiperparametre ayarlarÄ±",
                        "DiÄŸer algoritmalarla karÅŸÄ±laÅŸtÄ±r"
                    ],
                    "success": True
                }
        
        # Generic algorithm explanation
        return {
            "response": "ğŸ¤– Hangi algoritma hakkÄ±nda bilgi almak istiyorsunuz? Size detaylarÄ±nÄ± aÃ§Ä±klayabilirim.",
            "suggestions": [
                "XGBoost nedir?",
                "Random Forest aÃ§Ä±kla",
                "SVM nasÄ±l Ã§alÄ±ÅŸÄ±r?"
            ],
            "success": True
        }
    
    def _should_recommend_algorithms(self, context: Dict) -> bool:
        """
        Determine if we have enough information to make algorithm recommendations
        """
        required_info = ['project_type', 'data_size', 'data_type']
        
        # For classification, we're more flexible about class_count
        # We can still give recommendations without it
        
        gathered_info = [key for key in required_info if context.get(key) is not None]
        
        print(f"ğŸ“‹ Required: {required_info}")
        print(f"ğŸ“‹ Gathered: {gathered_info}")
        
        # If we have project_type, we can give basic recommendations
        # Even more flexible: just 1 piece of info is enough for basic suggestions
        return len(gathered_info) >= 1
    
    def _generate_algorithm_recommendations(self, user_message: str, context: Dict) -> Dict:
        """
        Generate algorithm recommendations using our custom model + advanced AI explanation
        """
        try:
            # Use our algorithm recommender
            recommendations = self.algorithm_recommender.get_recommendations(
                project_type=context.get('project_type', 'classification'),
                data_size=context.get('data_size', 'medium'),
                data_type=context.get('data_type', 'numerical'),
                complexity_preference=context.get('complexity', 'medium')
            )
            
            # Always use our advanced AI system for better explanations
            return self._advanced_ai_recommendations(user_message, context, recommendations)
                
        except Exception as e:
            print(f"âŒ Error in recommendations: {e}")
            return self._get_emergency_fallback()
    
    def _advanced_ai_recommendations(self, user_message: str, context: Dict, recommendations: List[Dict]) -> Dict:
        """
        Hybrid AI system: GPT-4 + Custom Algorithm Model for personalized recommendations
        """
        try:
            if not recommendations:
                return self._get_emergency_fallback()
            
            # Get top 3 recommendations
            top_algos = recommendations[:3]
            
            # Try GPT-4 first for detailed paragraph responses
            if self.openai_enabled and self.openai_client:
                try:
                    return self._generate_gpt4_recommendations(user_message, context, top_algos)
                except Exception as e:
                    print(f"âš ï¸ GPT-4 failed, using advanced fallback: {e}")
            
            # Fallback to enhanced template system
            return self._generate_enhanced_template_recommendations(user_message, context, top_algos)
                
        except Exception as e:
            print(f"âŒ Advanced AI recommendation error: {e}")
            return self._template_recommendations(context, recommendations)
    
    def _generate_gpt4_recommendations(self, user_message: str, context: Dict, recommendations: List[Dict]) -> Dict:
        """
        Generate detailed paragraph recommendations using GPT-4
        """
        try:
            # Prepare algorithm details for GPT-4
            algo_details = []
            for algo in recommendations:
                algo_details.append(f"- {algo['algorithm']}: GÃ¼ven skoru {algo['confidence_score']:.1f}/5.0")
            
            # Create context string
            project_info = f"""
Proje tÃ¼rÃ¼: {context.get('project_type', 'Belirsiz')}
Veri boyutu: {context.get('data_size', 'Orta')}
Veri tÃ¼rÃ¼: {context.get('data_type', 'SayÄ±sal')}
SÄ±nÄ±f sayÄ±sÄ±: {context.get('class_count', 'Belirsiz')}

Ã–nerilen algoritmalar:
{chr(10).join(algo_details)}

KullanÄ±cÄ± mesajÄ±: "{user_message}"
"""
            
            # GPT-4 prompt
            messages = [
                {"role": "system", "content": self.algorithm_expert_prompt},
                {"role": "user", "content": f"""
YukarÄ±daki proje bilgilerine dayanarak algoritma Ã¶nerilerimi paragraf halinde detaylÄ± aÃ§Ä±kla.

{project_info}

LÃ¼tfen:
1. Her algoritmayÄ± neden Ã¶nerdiÄŸimi paragraf halinde aÃ§Ä±kla
2. Projenin Ã¶zelliklerine gÃ¶re avantajlarÄ± belirt
3. Pratik uygulama ipuÃ§larÄ± ver
4. Hangi algoritma ile baÅŸlanmasÄ±nÄ± Ã¶neriyorsan belirt
5. Samimi ve anlaÅŸÄ±lÄ±r bir dille yaz

KÄ±sa maddeler yerine akÄ±cÄ± paragraflar halinde cevap ver.
"""}
            ]
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",  # Use GPT-4 Omni for superior algorithmic advice and detailed explanations
                messages=messages,
                max_tokens=800,
                temperature=0.7
            )
            
            gpt_response = response.choices[0].message.content
            
            # Generate smart suggestions
            suggestions = []
            if recommendations:
                suggestions.append(f"{recommendations[0]['algorithm']} kod Ã¶rneÄŸi")
                suggestions.append("Performans karÅŸÄ±laÅŸtÄ±rmasÄ± yap")
                suggestions.append("Hiperparametre optimizasyonu")
                if len(recommendations) > 1:
                    suggestions.append(f"{recommendations[1]['algorithm']} detaylarÄ±")
            
            return {
                "response": gpt_response,
                "suggestions": suggestions,
                "success": True,
                "ai_powered": True
            }
            
        except Exception as e:
            print(f"âŒ GPT-4 recommendation error: {e}")
            raise e
    
    def _generate_enhanced_template_recommendations(self, user_message: str, context: Dict, recommendations: List[Dict]) -> Dict:
        """
        Enhanced fallback system with paragraph-style responses
        """
        project_type = context.get('project_type') or 'machine learning'
        data_size = context.get('data_size') or 'medium' 
        data_type = context.get('data_type') or 'numerical'
        
        # Create paragraph-style introduction
        if project_type == 'classification':
            intro = f"SÄ±nÄ±flandÄ±rma projeniz iÃ§in detaylÄ± analiz yaptÄ±m ve size en uygun algoritmalarÄ± seÃ§tim. {data_size.title()} boyuttaki {data_type} veriniz iÃ§in Ã¶zellikle etkili olacak Ã§Ã¶zÃ¼mler buldum."
        elif project_type == 'regression':
            intro = f"Regresyon analiziniz iÃ§in algoritma seÃ§iminde dikkat ettiÄŸim temel faktÃ¶rler veri boyutunuz ({data_size}) ve veri tipinizdir ({data_type}). Bu Ã¶zelliklere gÃ¶re en baÅŸarÄ±lÄ± sonuÃ§larÄ± verecek algoritmalarÄ± Ã¶nceledim."
        else:
            intro = f"Projeniz iÃ§in uygun algoritma seÃ§iminde veri karakteristiklerinizi gÃ¶z Ã¶nÃ¼nde bulundurdum. {data_size.title()} boyuttaki {data_type} verileriniz iÃ§in optimize edilmiÅŸ Ã¶nerilerimi paylaÅŸÄ±yorum."
        
        response = intro + "\n\n"
        
        # Detailed algorithm explanations in paragraph form
        for i, algo in enumerate(recommendations[:3], 1):
            algo_name = algo['algorithm']
            confidence = algo['confidence_score']
            
            if i == 1:
                response += f"**{algo_name}** algoritmasÄ±nÄ± ilk sÄ±rada Ã¶neriyorum Ã§Ã¼nkÃ¼ {confidence:.1f}/5.0 gÃ¼ven skoru ile projenize en uygun seÃ§enek. "
            else:
                response += f"**{algo_name}** da {confidence:.1f}/5.0 gÃ¼ven skoru ile gÃ¼Ã§lÃ¼ bir alternatif. "
            
            # Get detailed explanation
            explanation = self._get_enhanced_explanation(algo_name, context)
            response += explanation + "\n\n"
        
        # Contextual advice paragraph
        if data_size == 'small':
            response += "KÃ¼Ã§Ã¼k veri setiniz gÃ¶z Ã¶nÃ¼nde bulundurulduÄŸunda, overfitting riskini minimize etmek iÃ§in daha basit modelleri tercih etmenizi Ã¶neriyorum. BaÅŸlangÄ±Ã§ iÃ§in ilk Ã¶nerdiÄŸim algoritmayÄ± deneyip sonuÃ§larÄ± deÄŸerlendirdikten sonra diÄŸer seÃ§eneklere geÃ§ebilirsiniz."
        elif data_size == 'large':
            response += "BÃ¼yÃ¼k veri setinizin avantajÄ±nÄ± kullanarak daha karmaÅŸÄ±k modelleri gÃ¼venle deneyebilirsiniz. Bu durumda ensemble metotlarÄ± ve derin Ã¶ÄŸrenme yaklaÅŸÄ±mlarÄ± Ã¶zellikle etkili sonuÃ§lar verebilir."
        else:
            response += "Orta boyuttaki veri setiniz iÃ§in dengeli bir yaklaÅŸÄ±m Ã¶neriyorum. Ä°lk etapta daha basit algoritmalarla baÅŸlayÄ±p performans sonuÃ§larÄ±na gÃ¶re karmaÅŸÄ±klÄ±ÄŸÄ± artÄ±rabilirsiniz."
        
        # Generate suggestions
        suggestions = [
            f"{recommendations[0]['algorithm']} nasÄ±l uygulanÄ±r?",
            "Performans karÅŸÄ±laÅŸtÄ±rmasÄ±",
            "Kod Ã¶rneÄŸi"
        ]
        
        if len(recommendations) > 1:
            suggestions.append(f"{recommendations[1]['algorithm']} detaylarÄ±")
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
    
    def _get_simple_explanation(self, algorithm: str, context: Dict) -> str:
        """
        Get simple, clean explanation for each algorithm
        """
        explanations = {
            'XGBoost': "YÃ¼ksek doÄŸruluk oranÄ±na sahip, gÃ¼Ã§lÃ¼ bir algoritma. Ã‡oÄŸu durumda Ã§ok iyi sonuÃ§lar verir.",
            'Random Forest': "GÃ¼venilir ve dengeli bir seÃ§im. Overfitting yapmaz, sonuÃ§larÄ± yorumlamasÄ± kolay.",
            'Logistic Regression': "Basit ve hÄ±zlÄ±. BaÅŸlangÄ±Ã§ iÃ§in ideal, sonuÃ§larÄ± anlaÅŸÄ±lÄ±r.",
            'SVM': "KarmaÅŸÄ±k veri iliÅŸkilerini iyi yakalar. KÃ¼Ã§Ã¼k veri setlerinde baÅŸarÄ±lÄ±.",
            'Neural Network': "KarmaÅŸÄ±k problemleri Ã§Ã¶zebilir. BÃ¼yÃ¼k veri setleri gerektir.",
            'Linear Regression': "Basit ve hÄ±zlÄ± regresyon algoritmasÄ±. YorumlamasÄ± kolay.",
            'Decision Tree': "AnlaÅŸÄ±lmasÄ± kolay kural tabanlÄ± algoritma.",
            'Naive Bayes': "HÄ±zlÄ± ve basit sÄ±nÄ±flandÄ±rma algoritmasÄ±.",
            'K-Means': "Veri gruplarÄ±nÄ± otomatik olarak bulur.",
            'DBSCAN': "GÃ¼rÃ¼ltÃ¼lÃ¼ verilerde grup bulma algoritmasÄ±.",
        }
        
        return explanations.get(algorithm, "GÃ¼venilir bir makine Ã¶ÄŸrenmesi algoritmasÄ±.")
    
    def _get_algorithm_explanation(self, algorithm: str, context: Dict, confidence: float) -> str:
        """
        Get intelligent, contextual explanation for each algorithm
        """
        explanations = {
            'XGBoost': {
                'classification': "ğŸ† Gradient boosting'in ÅŸampiyonu! KarmaÅŸÄ±k iliÅŸkileri yakalama konusunda uzman. Kaggle yarÄ±ÅŸmalarÄ±nÄ±n favorisi.",
                'regression': "ğŸ“ˆ SayÄ±sal tahminlerde Ã§ok gÃ¼Ã§lÃ¼! Eksik verilerle bile baÅŸarÄ±lÄ± Ã§alÄ±ÅŸÄ±r.",
                'general': "âš¡ HÄ±zlÄ±, gÃ¼Ã§lÃ¼ ve esnek. Ã‡oÄŸu problemde harika sonuÃ§lar verir."
            },
            'Random Forest': {
                'classification': "ğŸŒ³ Karar aÄŸaÃ§larÄ±nÄ±n gÃ¼cÃ¼nÃ¼ birleÅŸtirir. Overfitting'e karÅŸÄ± direnÃ§li ve yorumlanabilir.",
                'regression': "ğŸŒ² Stabil tahminler yapar. Ã–zellik Ã¶nemini gÃ¶sterir.",
                'general': "ğŸ”’ GÃ¼venilir ve robust. Hemen hemen her veri tÃ¼rÃ¼yle Ã§alÄ±ÅŸÄ±r."
            },
            'Logistic Regression': {
                'classification': "ğŸ“Š Basit ama etkili! Ä°kili sÄ±nÄ±flandÄ±rmada mÃ¼kemmel. SonuÃ§larÄ± anlamak kolay.",
                'general': "âœ¨ HÄ±zlÄ± ve yorumlanabilir. BaÅŸlangÄ±Ã§ iÃ§in ideal seÃ§im."
            },
            'SVM': {
                'classification': "ğŸ¯ KarmaÅŸÄ±k veri sÄ±nÄ±rlarÄ±nÄ± Ã§izer. YÃ¼ksek boyutlu verilerde baÅŸarÄ±lÄ±.",
                'general': "ğŸ’ª GÃ¼Ã§lÃ¼ matematik temeli. Kernel trick ile sihir yapar."
            },
            'Neural Network': {
                'classification': "ğŸ§  Beyin yapÄ±sÄ±nÄ± taklit eder. Ã‡ok karmaÅŸÄ±k iliÅŸkileri Ã¶ÄŸrenebilir.",
                'general': "ğŸš€ Derin Ã¶ÄŸrenmenin kapÄ±sÄ±. BÃ¼yÃ¼k verilerle ÅŸaha kalkar."
            }
        }
        
        project_type = context.get('project_type', 'general')
        
        if algorithm in explanations:
            if project_type in explanations[algorithm]:
                base_explanation = explanations[algorithm][project_type]
            else:
                base_explanation = explanations[algorithm]['general']
        else:
            base_explanation = "ğŸ”§ GÃ¼venilir bir algoritma. Projenizde iyi sonuÃ§lar verebilir."
        
        # Add confidence-based comment
        if confidence >= 4.5:
            confidence_note = "âœ… Size Ã¶zel olarak optimize edilmiÅŸ!"
        elif confidence >= 4.0:
            confidence_note = "ğŸ‘ Verilerinizle uyumlu!"
        elif confidence >= 3.5:
            confidence_note = "ğŸ“ Denemeye deÄŸer!"
        else:
            confidence_note = "ğŸ¤” Alternatif seÃ§enek olabilir."
            
        return f"{base_explanation} {confidence_note}"
    
    def _generate_consultation_response(self, user_message: str, context: Dict) -> Dict:
        """
        Generate consultation questions using advanced AI to gather more information
        """
        # Always use our advanced AI system for better user experience
        return self._advanced_ai_consultation_response(user_message, context)
    
    def _advanced_ai_consultation_response(self, user_message: str, context: Dict) -> Dict:
        """
        Hybrid AI consultation: GPT-4 + template fallback for gathering project information
        """
        try:
            # Handle None or empty messages
            if user_message is None:
                user_message = ""
            
            # Try GPT-4 first for personalized consultation
            if self.openai_enabled and self.openai_client:
                try:
                    return self._generate_gpt4_consultation(user_message, context)
                except Exception as e:
                    print(f"âš ï¸ GPT-4 consultation failed, using template: {e}")
            
            # Fallback to enhanced template consultation
            return self._generate_template_consultation(user_message, context)
            
        except Exception as e:
            print(f"âŒ Advanced AI consultation error: {e}")
            return self._template_consultation_response(context)
    
    def _generate_gpt4_consultation(self, user_message: str, context: Dict) -> Dict:
        """
        Generate personalized consultation using GPT-4
        """
        # Determine what information we still need
        missing_info = []
        if not context.get('project_type'):
            missing_info.append('proje tÃ¼rÃ¼')
        if not context.get('data_size'):
            missing_info.append('veri boyutu')
        if not context.get('data_type'):
            missing_info.append('veri tÃ¼rÃ¼')
        if context.get('project_type') == 'classification' and not context.get('class_count'):
            missing_info.append('sÄ±nÄ±f sayÄ±sÄ±')
        
        # Prepare context for GPT-4
        context_info = f"""
Mevcut proje bilgileri:
- Proje tÃ¼rÃ¼: {context.get('project_type', 'Belirsiz')}
- Veri boyutu: {context.get('data_size', 'Belirsiz')}
- Veri tÃ¼rÃ¼: {context.get('data_type', 'Belirsiz')}
- SÄ±nÄ±f sayÄ±sÄ±: {context.get('class_count', 'Belirsiz')}

Eksik bilgiler: {', '.join(missing_info) if missing_info else 'Yok'}

KullanÄ±cÄ± mesajÄ±: "{user_message}"
"""
        
        messages = [
            {"role": "system", "content": self.consultation_prompt},
            {"role": "user", "content": f"""
Bir kullanÄ±cÄ± algoritma danÄ±ÅŸmanlÄ±ÄŸÄ± iÃ§in geldi. AÅŸaÄŸÄ±daki bilgileri gÃ¶z Ã¶nÃ¼nde bulundurarak ona yardÄ±m et:

{context_info}

LÃ¼tfen:
1. KullanÄ±cÄ±nÄ±n mesajÄ±na samimi ve paragraf halinde cevap ver
2. Eksik bilgi varsa nazikÃ§e sor ama zorlama
3. Projesini anlayÄ±p doÄŸru yÃ¶nlendir
4. Teknik terimlerden kaÃ§Ä±n, sade konuÅŸ
5. 2-3 paragraf halinde cevap ver

KÄ±sa listeler yerine akÄ±cÄ± konuÅŸma yap.
"""}
        ]
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o",  # Premium GPT-4 for consultation responses
            messages=messages,
            max_tokens=400,
            temperature=0.8
        )
        
        gpt_response = response.choices[0].message.content
        
        # Generate contextual suggestions
        suggestions = self._generate_consultation_suggestions(missing_info, context)
        
        return {
            "response": gpt_response,
            "suggestions": suggestions,
            "success": True,
            "ai_powered": True
        }
    
    def _generate_template_consultation(self, user_message: str, context: Dict) -> Dict:
        """
        Enhanced template-based consultation with paragraph responses
        """
        # Determine what information we still need
        missing_info = []
        if not context.get('project_type'):
            missing_info.append('project_type')
        if not context.get('data_size'):
            missing_info.append('data_size')
        if not context.get('data_type'):
            missing_info.append('data_type')
        if context.get('project_type') == 'classification' and not context.get('class_count'):
            missing_info.append('class_count')
        
        # Analyze user's message sentiment and content
        user_msg_lower = user_message.lower()
        
        # Generate paragraph-style responses
        if any(word in user_msg_lower for word in ['merhaba', 'selam', 'hello', 'hi']):
            if not context.get('project_type'):
                response = "Merhaba! Size en uygun makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ± bulmaya yardÄ±mcÄ± olmaktan memnuniyet duyarÄ±m. Projenizin detaylarÄ±nÄ± anlayarak size Ã¶zel Ã¶neriler geliÅŸtirebilirim.\n\nHangi tÃ¼r bir problem Ã§Ã¶zmek istediÄŸinizi paylaÅŸabilir misiniz? Bu ÅŸekilde size en uygun algoritmalarÄ± Ã¶nerebilirim."
                suggestions = [
                    "Veri sÄ±nÄ±flandÄ±rmasÄ± yapacaÄŸÄ±m",
                    "SayÄ±sal deÄŸer tahmini yapmak istiyorum", 
                    "Veri kÃ¼melerini gruplamaya ihtiyacÄ±m var"
                ]
            else:
                response = f"Merhaba! {context['project_type']} projesi Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±zÄ± gÃ¶rÃ¼yorum, bu gerÃ§ekten ilginÃ§ bir alan. Size en uygun algoritmalarÄ± Ã¶nerebilmek iÃ§in birkaÃ§ detay daha Ã¶ÄŸrenmem gerekiyor."
                suggestions = self._generate_consultation_suggestions(missing_info, context)
        
        elif not context.get('project_type'):
            response = "Projenizin amacÄ±nÄ± biraz daha detayÄ±na inmek istiyorum. Makine Ã¶ÄŸrenmesinde farklÄ± problem tÃ¼rleri iÃ§in farklÄ± yaklaÅŸÄ±mlar gerekiyor ve size en uygun Ã§Ã¶zÃ¼mÃ¼ sunabilmek iÃ§in projenizin hedefini anlamam Ã¶nemli.\n\nHangi tÃ¼r bir sonuÃ§ elde etmeyi hedefliyorsunuz?"
            suggestions = [
                "Verileri kategorilere ayÄ±rma (sÄ±nÄ±flandÄ±rma)",
                "SayÄ±sal deÄŸer tahmin etme (regresyon)",
                "Veri gruplarÄ±nÄ± keÅŸfetme (kÃ¼meleme)"
            ]
        
        elif not context.get('data_size'):
            response = f"{context['project_type'].title()} projesi harika bir seÃ§im! Bu alandaki deneyimime dayanarak size Ã§ok etkili algoritmalar Ã¶nerebilirim. Ancak veri setinizin boyutu algoritma seÃ§iminde kritik bir faktÃ¶r.\n\nKaÃ§ tane veri kaydÄ±nÄ±z var? Bu bilgi sayesinde performans ve hÄ±z aÃ§Ä±sÄ±ndan en uygun algoritmalarÄ± seÃ§ebilirim."
            suggestions = [
                "1000'den az kayÄ±t (kÃ¼Ã§Ã¼k veri)",
                "1000-10000 arasÄ± (orta boyut)",
                "10000'den fazla (bÃ¼yÃ¼k veri)"
            ]
        
        elif not context.get('data_type'):
            response = "Veri boyutunu Ã¶ÄŸrendiÄŸim iÃ§in teÅŸekkÃ¼rler! Åimdi veri tÃ¼rÃ¼nÃ¼ anlamam gerekiyor Ã§Ã¼nkÃ¼ farklÄ± veri tÃ¼rleri iÃ§in optimize edilmiÅŸ algoritmalar var. Bu bilgi ile size en uygun ve verimli Ã§Ã¶zÃ¼mÃ¼ Ã¶nerebilirim.\n\nVerileriniz hangi tÃ¼rde? Bu detay algoritma performansÄ±nÄ± doÄŸrudan etkiliyor."
            suggestions = [
                "SayÄ±sal veriler (rakamlar, Ã¶lÃ§Ã¼mler)",
                "Kategorik veriler (gruplar, etiketler)",
                "Metin verileri (yazÄ±lar, yorumlar)",
                "GÃ¶rÃ¼ntÃ¼ verileri (fotoÄŸraflar, resimler)"
            ]
        
        elif context.get('project_type') == 'classification' and not context.get('class_count'):
            response = "SÄ±nÄ±flandÄ±rma projesi iÃ§in son bir Ã¶nemli detay kaldÄ±! KaÃ§ farklÄ± kategori veya sÄ±nÄ±fÄ±nÄ±z olduÄŸu algoritma seÃ§imini etkileyecek. Ä°kili sÄ±nÄ±flandÄ±rma ile Ã§ok sÄ±nÄ±flÄ± problemler farklÄ± yaklaÅŸÄ±mlar gerektiriyor.\n\nVerilerinizi kaÃ§ kategoriye ayÄ±rmayÄ± planlÄ±yorsunuz?"
            suggestions = [
                "2 kategori (ikili sÄ±nÄ±flandÄ±rma)",
                "3-10 kategori arasÄ± (Ã§oklu sÄ±nÄ±f)",
                "10'dan fazla kategori (karmaÅŸÄ±k sÄ±nÄ±flandÄ±rma)"
            ]
        
        else:
            # We have enough info, this shouldn't happen
            response = "Harika! Proje detaylarÄ±nÄ±zÄ± topladÄ±m ve size Ã¶zel algoritma Ã¶nerilerini hazÄ±rlÄ±yorum. Bir an iÃ§inde en uygun seÃ§enekleri sunacaÄŸÄ±m."
            suggestions = ["Algoritma Ã¶nerilerini gÃ¶ster"]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
    
    def _generate_consultation_suggestions(self, missing_info: List[str], context: Dict) -> List[str]:
        """
        Generate contextual suggestions based on missing information and context
        """
        if 'proje tÃ¼rÃ¼' in missing_info or 'project_type' in missing_info:
            return [
                "SÄ±nÄ±flandÄ±rma projesi yapÄ±yorum",
                "Regresyon analizi yapmak istiyorum",
                "Veri kÃ¼meleme yapacaÄŸÄ±m"
            ]
        elif 'veri boyutu' in missing_info or 'data_size' in missing_info:
            return [
                "KÃ¼Ã§Ã¼k veri setim var (1000<)",
                "Orta boyut veri (1000-10000)",
                "BÃ¼yÃ¼k veri setim var (10000+)"
            ]
        elif 'veri tÃ¼rÃ¼' in missing_info or 'data_type' in missing_info:
            return [
                "SayÄ±sal verilerle Ã§alÄ±ÅŸÄ±yorum",
                "Kategorik verilerim var",
                "Metin verileri iÅŸliyorum"
            ]
        else:
            return [
                "Algoritma Ã¶nerilerini ver",
                "Performans karÅŸÄ±laÅŸtÄ±rmasÄ± yap",
                "Hangi metrik kullanmalÄ±yÄ±m?"
            ]
    
    def _ai_consultation_response(self, user_message: str, context: Dict) -> Dict:
        """
        Fallback to advanced AI when OpenAI fails
        """
        return self._advanced_ai_consultation_response(user_message, context)
    
    def _template_consultation_response(self, context: Dict) -> Dict:
        """
        Template-based consultation when AI is not available
        """
        if not context.get('project_type'):
            return {
                "response": "Merhaba! Projeniz iÃ§in en uygun algoritmalarÄ± Ã¶nerebilmek iÃ§in biraz daha bilgiye ihtiyacÄ±m var. Hangi tÃ¼r bir makine Ã¶ÄŸrenmesi problemi Ã§Ã¶zmek istiyorsunuz?",
                "suggestions": [
                    "Veri sÄ±nÄ±flandÄ±rmasÄ± yapacaÄŸÄ±m",
                    "SayÄ±sal deÄŸer tahmini (regresyon)",
                    "Veri kÃ¼meleme iÅŸlemi"
                ],
                "success": True
            }
        elif not context.get('data_size'):
            return {
                "response": f"Harika! {context['project_type']} projesi iÃ§in size yardÄ±mcÄ± olabilirim. Veri setinizin boyutu nasÄ±l?",
                "suggestions": [
                    "1000'den az veri",
                    "1000-10000 arasÄ± veri",
                    "10000+ bÃ¼yÃ¼k veri seti"
                ],
                "success": True
            }
        else:
            return self._get_emergency_fallback()
    
    def _template_recommendations(self, context: Dict, recommendations: List[Dict]) -> Dict:
        """
        Template-based recommendations when AI is not available
        """
        response = f"ğŸ¯ **{context.get('project_type', 'ML').title()} Projesi iÃ§in Ã–nerilerim:**\n\n"
        
        for i, rec in enumerate(recommendations[:3], 1):
            response += f"**{i}. {rec['algorithm']}**\n"
            response += f"   â€¢ GÃ¼ven Skoru: {rec['confidence_score']:.2f}\n"
            response += f"   â€¢ {rec.get('description', 'GÃ¼venilir algoritma')}\n\n"
        
        response += "Bu algoritmalarÄ±n hangisi hakkÄ±nda daha fazla bilgi almak istersiniz?"
        
        suggestions = [rec['algorithm'] for rec in recommendations[:3]]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
    
    def _generate_smart_suggestions(self, context: Dict, recommendations: List[Dict]) -> List[str]:
        """
        Generate contextual suggestions based on recommendations
        """
        suggestions = []
        
        if recommendations:
            suggestions.append(f"{recommendations[0]['algorithm']} hakkÄ±nda detay")
            suggestions.append("Implementasyon Ã¶rneÄŸi")
            suggestions.append("Performans karÅŸÄ±laÅŸtÄ±rmasÄ±")
        
        return suggestions[:3]
    
    def _generate_context_suggestions(self, missing_info: List[str]) -> List[str]:
        """
        Generate suggestions based on missing information
        """
        if 'proje tÃ¼rÃ¼' in str(missing_info):
            return [
                "SÄ±nÄ±flandÄ±rma projesi yapÄ±yorum",
                "Regresyon analizi yapacaÄŸÄ±m",
                "Veri kÃ¼meleme yapacaÄŸÄ±m"
            ]
        elif 'veri boyutu' in str(missing_info):
            return [
                "KÃ¼Ã§Ã¼k veri setim var (1000<)",
                "Orta boyut veri (1000-10000)",
                "BÃ¼yÃ¼k veri setim var (10000+)"
            ]
        else:
            return [
                "Daha fazla detay ver",
                "Ã–rnek gÃ¶ster",
                "BaÅŸka yaklaÅŸÄ±m"
            ]
    
    def _get_enhanced_explanation(self, algorithm: str, context: Dict) -> str:
        """
        Get enhanced paragraph-style explanation for each algorithm
        """
        project_type = context.get('project_type', 'general')
        data_size = context.get('data_size', 'medium')
        
        explanations = {
            'XGBoost': {
                'classification': f"Bu gradient boosting algoritmasÄ±, sÄ±nÄ±flandÄ±rma problemlerinde Ã§ok yÃ¼ksek doÄŸruluk oranlarÄ± saÄŸlar. Ã–zellikle {data_size} boyuttaki veri setlerde mÃ¼kemmel sonuÃ§lar verir Ã§Ã¼nkÃ¼ birÃ§ok zayÄ±f Ã¶ÄŸreniciyi birleÅŸtirerek gÃ¼Ã§lÃ¼ bir model oluÅŸturur. Eksik verilerle bile baÅŸarÄ±lÄ± Ã§alÄ±ÅŸmasÄ± ve Ã¶zellik Ã¶nemini gÃ¶stermesi bÃ¼yÃ¼k avantajlarÄ±.",
                'regression': f"SayÄ±sal tahminlerde Ã¼stÃ¼n performans gÃ¶steren bu algoritma, karmaÅŸÄ±k veri iliÅŸkilerini yakalama konusunda uzman. {data_size.title()} veri setinizde trend analizi ve pattern recognition konularÄ±nda Ã§ok baÅŸarÄ±lÄ± olacak.",
                'general': "Hemen hemen her machine learning probleminde gÃ¼venle kullanabileceÄŸiniz, endÃ¼stri standardÄ± bir algoritma. Kaggle yarÄ±ÅŸmalarÄ±nÄ±n favorisi olmasÄ±nÄ±n sebebi yÃ¼ksek performansÄ± ve esnekliÄŸi."
            },
            'Random Forest': {
                'classification': f"Karar aÄŸaÃ§larÄ±nÄ±n kollektif gÃ¼cÃ¼nÃ¼ kullanarak overfitting problemini Ã§Ã¶zen akÄ±llÄ± bir yaklaÅŸÄ±m. {data_size.title()} veri setinizde hem hÄ±zlÄ± Ã§alÄ±ÅŸacak hem de yorumlanabilir sonuÃ§lar verecek. Ã–zellik Ã¶nemini gÃ¶rmek iÃ§in ideal.",
                'regression': f"Tahmin problemlerinde gÃ¼venilirlik arÄ±yorsanÄ±z mÃ¼kemmel bir seÃ§im. BirÃ§ok karar aÄŸacÄ±nÄ±n oybirliÄŸi ile tahmin yaptÄ±ÄŸÄ± iÃ§in tek bir aÄŸaca gÃ¶re Ã§ok daha stabil sonuÃ§lar verir.",
                'general': "BaÅŸlangÄ±Ã§ iÃ§in ideal Ã§Ã¼nkÃ¼ hiperparametre ayarlamaya Ã§ok ihtiyaÃ§ duymaz ve neredeyse her durumda makul sonuÃ§lar verir. GÃ¼venilir bir algoritma."
            },
            'Logistic Regression': {
                'classification': f"BasitliÄŸi ve etkinliÄŸi ile Ã¶ne Ã§Ä±kan bu algoritma, {data_size} veri setlerde hÄ±zlÄ± sonuÃ§lar verir. Ä°kili sÄ±nÄ±flandÄ±rmada Ã¶zellikle baÅŸarÄ±lÄ± ve sonuÃ§larÄ± anlamak Ã§ok kolay. DoÄŸrusal iliÅŸkileri Ã§ok iyi yakalar.",
                'general': "Machine learning'e yeni baÅŸlayanlar iÃ§in mÃ¼kemmel bir baÅŸlangÄ±Ã§ noktasÄ±. Hem hÄ±zlÄ± hem de yorumlanabilir sonuÃ§lar verir."
            },
            'SVM': {
                'classification': f"KarmaÅŸÄ±k sÄ±nÄ±r Ã§izgilerini Ã§izme konusunda uzman bu algoritma, Ã¶zellikle doÄŸrusal olmayan iliÅŸkilerin olduÄŸu durumlarda Ã§ok baÅŸarÄ±lÄ±. {data_size} veri setlerde kernel trick sayesinde yÃ¼ksek boyutlu problemleri Ã§Ã¶zebilir.",
                'general': "GÃ¼Ã§lÃ¼ matematik temeli olan, teorik olarak saÄŸlam bir algoritma. Ã–zellikle yÃ¼ksek boyutlu verilerde etkili."
            },
            'Neural Network': {
                'classification': f"Ä°nsan beyninden ilham alan bu algoritma, Ã§ok karmaÅŸÄ±k pattern'leri Ã¶ÄŸrenebilir. {data_size} veri setiniz bÃ¼yÃ¼kse harika sonuÃ§lar verecek, ancak parametre ayarlamasÄ± biraz sabÄ±r gerektirir.",
                'general': "Derin Ã¶ÄŸrenmenin kapÄ±sÄ±nÄ± aÃ§an temel algoritma. KarmaÅŸÄ±k problemlerde Ã§ok gÃ¼Ã§lÃ¼ ama yeterli veri gerektirir."
            }
        }
        
        if algorithm in explanations:
            if project_type in explanations[algorithm]:
                return explanations[algorithm][project_type]
            else:
                return explanations[algorithm]['general']
        else:
            return f"Bu algoritma {project_type} problemlerde gÃ¼venilir sonuÃ§lar verir ve veri setinizin karakteristikleriyle uyumlu Ã§alÄ±ÅŸacaktÄ±r."
    
    def _get_emergency_fallback(self) -> Dict:
        """
        Emergency response when everything fails
        """
        return {
            "response": "ÃœzgÃ¼nÃ¼m, ÅŸu anda teknik bir sorun yaÅŸÄ±yorum. Projeniz hakkÄ±nda daha basit terimlerle anlatabilir misiniz?",
            "suggestions": [
                "Hangi tÃ¼r veri analizi yapacaÄŸÄ±m?",
                "Ne tÃ¼r sonuÃ§ elde etmek istiyorum?",
                "Elimde ne kadar veri var?"
            ],
            "success": True
        } 