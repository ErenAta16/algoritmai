import os
from openai import OpenAI
from typing import Dict, List, Optional
from services.algorithm_recommender import AlgorithmRecommender
from dotenv import load_dotenv
import random
import time
import json
from functools import lru_cache
import logging

# Load environment variables from .env file
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OpenAIService:
    def __init__(self):
        """
        Advanced Hybrid AI-powered algorithm consultant with intelligent fallback
        """
        self.algorithm_recommender = AlgorithmRecommender()
        self.request_count = 0
        self.last_request_time = 0
        self.rate_limit_delay = 1.0  # 1 second between requests
        
        # Initialize OpenAI with modern client
        api_key = os.getenv('OPENAI_API_KEY')
        if api_key and api_key != 'your_openai_api_key_here':
            try:
                self.openai_client = OpenAI(api_key=api_key)
                # Test the connection
                self.openai_client.models.list()
                self.openai_enabled = True
                logger.info("âœ… OpenAI API successfully initialized and tested")
            except Exception as e:
                logger.warning(f"âš ï¸ OpenAI API issue (quota/connection): {str(e)[:100]}...")
                self.openai_enabled = False
                self.openai_client = None
        else:
            self.openai_enabled = False
            self.openai_client = None
            logger.warning("âš ï¸ OpenAI API key not found, using advanced fallback system")
        
        # Always use our advanced AI system regardless of OpenAI status
        self.use_advanced_ai = True
        logger.info("ğŸ¤– Advanced AI Algorithm Consultant initialized with intelligent conversation engine")
        
        # Enhanced conversation-focused system prompts
        self.algorithm_expert_prompt = """Sen deneyimli, samimi ve yardÄ±msever bir makine Ã¶ÄŸrenmesi uzmanÄ±sÄ±n. AdÄ±n "AlgoMentor" ve kullanÄ±cÄ±larla gerÃ§ek bir arkadaÅŸ gibi konuÅŸuyorsun.

KiÅŸiliÄŸin:
- MeraklÄ± ve Ã¶ÄŸretmeyi seven
- Teknik bilgiyi basit Ã¶rneklerle anlatan
- SabÄ±rlÄ± ve destekleyici
- GerÃ§ek dÃ¼nya deneyimlerini paylaÅŸan
- YaratÄ±cÄ± Ã§Ã¶zÃ¼mler Ã¶neren

KonuÅŸma tarzÄ±n:
- DoÄŸal, akÄ±cÄ± paragraflar halinde konuÅŸ
- "ÅÃ¶yle ki", "Mesela", "AslÄ±nda" gibi gÃ¼nlÃ¼k ifadeler kullan
- KiÅŸisel deneyimlerini paylaÅŸ ("Benim deneyimime gÃ¶re...")
- Merak uyandÄ±rÄ±cÄ± sorular sor
- Cesaretlendirici ve pozitif ol

Algoritma bilgilerini ÅŸu ÅŸekilde sun:
- Ã–nce hikayesini anlat (nasÄ±l ortaya Ã§Ä±ktÄ±, neden Ã¶nemli)
- GerÃ§ek dÃ¼nya Ã¶rnekleri ver
- Avantaj/dezavantajlarÄ± dengeli ÅŸekilde aÃ§Ä±kla
- Uygulama ipuÃ§larÄ± ve pÃ¼f noktalarÄ± paylaÅŸ
- Hangi durumda kullanÄ±lacaÄŸÄ±nÄ± net belirt

Her zaman TÃ¼rkÃ§e konuÅŸ ve dostane, samimi bir ton kullan. Robotik cevaplar verme!"""

        self.consultation_prompt = """Sen "AlgoMentor" adÄ±nda deneyimli bir makine Ã¶ÄŸrenmesi danÄ±ÅŸmanÄ±sÄ±n. KullanÄ±cÄ±larla gerÃ§ek bir mentÃ¶r gibi konuÅŸuyorsun.

GÃ¶revin:
- KullanÄ±cÄ±nÄ±n projesini samimi bir ÅŸekilde dinle ve anla
- MeraklÄ± sorular sor ama sorgulama gibi yapma
- Hikayeler ve Ã¶rneklerle aÃ§Ä±kla
- KiÅŸisel deneyimlerini paylaÅŸ
- Cesaretlendirici ve destekleyici ol
- YaratÄ±cÄ± Ã§Ã¶zÃ¼mler Ã¶ner

KonuÅŸma yaklaÅŸÄ±mÄ±n:
- "Vay, bu Ã§ok ilginÃ§ bir proje!" gibi doÄŸal tepkiler ver
- "Benim de benzer bir projede Ã§alÄ±ÅŸmÄ±ÅŸtÄ±m..." diye deneyim paylaÅŸ
- "ÅÃ¶yle bir yaklaÅŸÄ±m deneyebiliriz..." diye Ã¶neriler sun
- Teknik terimleri gÃ¼nlÃ¼k dille aÃ§Ä±kla
- KÄ±sa listeler yerine akÄ±cÄ± paragraflar kullan

Bilgi toplarken:
- DoÄŸal soru akÄ±ÅŸÄ± oluÅŸtur
- KullanÄ±cÄ±nÄ±n motivasyonunu anla
- Proje hedeflerini keÅŸfet
- KÄ±sÄ±tlamalarÄ± Ã¶ÄŸren
- Deneyim seviyesini kavra

Her zaman samimi, yardÄ±msever ve konuÅŸkan ol!"""

        # Conversation memory for context
        self.conversation_memory = []
        self.user_profile = {
            'experience_level': 'unknown',
            'preferred_style': 'unknown',
            'project_domain': 'unknown',
            'technical_comfort': 'unknown'
        }
        
        # Response diversity tracking
        self.response_cache = {}
        self.response_variations = {}
        self.conversation_turn = 0
        
        # Recommendation memory and context tracking
        self.recommendation_history = []
        self.user_preferences = {}
        self.conversation_context = {
            'last_recommendations': [],
            'user_selections': [],
            'discussed_algorithms': [],
            'user_feedback': []
        }

    def _rate_limit_check(self):
        """Rate limiting implementation"""
        current_time = time.time()
        if current_time - self.last_request_time < self.rate_limit_delay:
            time.sleep(self.rate_limit_delay - (current_time - self.last_request_time))
        self.last_request_time = time.time()
        self.request_count += 1

    @lru_cache(maxsize=100)
    def _cached_gpt_request(self, prompt_hash: str, content: str) -> str:
        """Cache GPT responses to avoid repeated API calls"""
        try:
            self._rate_limit_check()
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": self.algorithm_expert_prompt},
                    {"role": "user", "content": content}
                ],
                max_tokens=1000,
                temperature=0.3,
                timeout=30
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"GPT request failed: {e}")
            raise e
    
    def get_chat_response(self, user_message: str, conversation_history: Optional[List[Dict]] = None) -> Dict:
        """
        Enhanced conversational AI response with natural dialogue flow and response diversity
        """
        try:
            # Handle None or empty messages
            if user_message is None:
                user_message = ""
            
            print(f"\nğŸ” Processing: '{user_message}'")
            
            # Increment conversation turn for diversity tracking
            self.conversation_turn += 1
            
            # Update conversation memory
            self._update_conversation_memory(user_message, conversation_history)
            
            # Analyze user profile and adapt response style
            self._analyze_user_profile(user_message)
            
            # Extract project context with conversation awareness
            project_context = self._extract_enhanced_project_context(user_message, conversation_history)
            project_context['conversation_turn'] = self.conversation_turn
            project_context['conversation_length'] = len(self.conversation_memory)
            
            # Add conversation context for memory awareness
            project_context['conversation_context'] = self.conversation_context
            project_context['conversation_memory'] = self.conversation_memory
            
            print(f"ğŸ“Š Enhanced Context: {project_context}")
            print(f"ğŸ§  Memory: {len(self.conversation_memory)} messages, {len(self.conversation_context['discussed_algorithms'])} algorithms discussed")
            
            # Determine response type based on conversation flow
            response_type = self._determine_response_type(user_message, project_context)
            print(f"ğŸ¯ Response Type: {response_type}")
            
            # Generate contextual response with diversity check
            response = self._generate_diverse_response(user_message, project_context, response_type)
            
            # Store response for diversity tracking
            self._store_response_for_diversity(user_message, response['response'])
            
            # Store recommendations if present
            if 'recommendations' in response:
                self.conversation_context['last_recommendations'] = response['recommendations']
            
            # Add response to conversation memory
            self.conversation_memory.append({
                'role': 'assistant',
                'content': response['response'],
                'timestamp': time.time()
            })
            
            return response
                
        except Exception as e:
            print(f"âŒ Error in AI service: {str(e)}")
            return self._get_emergency_fallback()

    def _generate_diverse_response(self, user_message: str, project_context: Dict, response_type: str) -> Dict:
        """Generate diverse responses based on conversation history"""
        # Check if we've seen similar messages before
        similar_responses = self._find_similar_responses(user_message)
        
        # Add diversity instruction to context
        if similar_responses:
            project_context['diversity_instruction'] = f"Bu soruya daha Ã¶nce benzer cevap verdin. Åimdi farklÄ± bir yaklaÅŸÄ±m, farklÄ± Ã¶rnekler ve farklÄ± ifadeler kullan. Ã–nceki cevaplarÄ±nÄ± tekrar etme."
            project_context['previous_responses'] = similar_responses[:3]  # Last 3 similar responses
        
        # Generate response based on type
        if response_type == 'algorithm_selection':
            return self._handle_algorithm_selection(user_message, project_context)
        elif response_type == 'recommendation_response':
            return self._handle_recommendation_response(user_message, project_context)
        elif response_type == 'algorithm_question':
                return self._handle_algorithm_question(user_message, project_context)
        elif response_type == 'code_request':
            return self._generate_code_example(user_message, project_context)
        elif response_type == 'comparison_request':
            return self._generate_performance_comparison(project_context)
        elif response_type == 'recommendation_ready':
            return self._generate_enhanced_recommendations(user_message, project_context)
        else:
            return self._generate_natural_consultation(user_message, project_context)
    
    def _find_similar_responses(self, user_message: str) -> List[str]:
        """Find similar previous responses to avoid repetition"""
        similar_responses = []
        user_words = set(user_message.lower().split())
        
        for cached_message, cached_response in self.response_cache.items():
            cached_words = set(cached_message.lower().split())
            
            # Calculate similarity
            if user_words and cached_words:
                intersection = user_words.intersection(cached_words)
                similarity = len(intersection) / len(user_words.union(cached_words))
                
                if similarity > 0.5:  # 50% similarity threshold
                    similar_responses.append(cached_response)
        
        return similar_responses
    
    def _store_response_for_diversity(self, user_message: str, response: str):
        """Store response for future diversity checking"""
        # Keep only last 20 responses to prevent memory bloat
        if len(self.response_cache) >= 20:
            # Remove oldest entry
            oldest_key = next(iter(self.response_cache))
            del self.response_cache[oldest_key]
        
        self.response_cache[user_message] = response
    
    def _track_algorithm_mentions(self, user_message: str):
        """Track mentioned algorithms in conversation"""
        text_lower = user_message.lower()
        
        # Algorithm names to track - expanded list
        algorithms = {
            'xgboost': ['xgboost', 'xgb'],
            'random forest': ['random forest', 'rf'],
            'svm': ['svm', 'support vector'],
            'neural network': ['neural network', 'nn', 'deep learning'],
            'logistic regression': ['logistic regression', 'logistic'],
            'naive bayes': ['naive bayes', 'nb'],
            'knn': ['knn', 'k-nearest'],
            'decision tree': ['decision tree', 'dt'],
            'linear regression': ['linear regression'],
            'k-means': ['kmeans', 'k-means'],
            'dbscan': ['dbscan'],
            'optics': ['optics'],
            'mean shift': ['mean shift'],
            'ensemble': ['ensemble'],
            'gradient boosting': ['gradient boosting', 'gbm'],
            'ada boost': ['ada boost', 'adaboost']
        }
        
        for algo_name, keywords in algorithms.items():
            if any(keyword in text_lower for keyword in keywords):
                if algo_name not in self.conversation_context['discussed_algorithms']:
                    self.conversation_context['discussed_algorithms'].append(algo_name)
                
                # Track user selection/preference
                if any(word in text_lower for word in ['seÃ§mek', 'istiyorum', 'tercih', 'daha iyi', 'kullanmak']):
                    self.conversation_context['user_selections'].append({
                        'algorithm': algo_name,
                        'message': user_message,
                        'timestamp': time.time()
                    })
    
    def _track_user_preferences(self, user_message: str):
        """Track user feedback and preferences"""
        text_lower = user_message.lower()
        
        # Positive feedback
        if any(word in text_lower for word in ['iyi', 'gÃ¼zel', 'mÃ¼kemmel', 'harika', 'beÄŸendim', 'evet']):
            self.conversation_context['user_feedback'].append({
                'type': 'positive',
                'message': user_message,
                'timestamp': time.time()
            })
        
        # Negative feedback
        elif any(word in text_lower for word in ['hayÄ±r', 'kÃ¶tÃ¼', 'beÄŸenmedim', 'istemiyorum', 'farklÄ±']):
            self.conversation_context['user_feedback'].append({
                'type': 'negative',
                'message': user_message,
                'timestamp': time.time()
            })
        
        # Questions about algorithms
        elif any(word in text_lower for word in ['neden', 'avantaj', 'dezavantaj', 'niye', 'hangisi']):
            self.conversation_context['user_feedback'].append({
                'type': 'question',
                'message': user_message,
                'timestamp': time.time()
            })
    
    def _update_conversation_memory(self, user_message: str, conversation_history: Optional[List[Dict]] = None):
        """Update conversation memory for better context awareness"""
        if conversation_history:
            self.conversation_memory = conversation_history[-10:]  # Keep last 10 messages
        
        # Add current message
        self.conversation_memory.append({
            'role': 'user',
            'content': user_message,
            'timestamp': time.time()
        })
        
        # Track algorithm mentions and user preferences
        self._track_algorithm_mentions(user_message)
        self._track_user_preferences(user_message)

    def _analyze_user_profile(self, user_message: str):
        """Analyze user's communication style and technical level"""
        text_lower = user_message.lower()
        
        # Detect experience level
        if any(word in text_lower for word in ['yeni baÅŸlÄ±yorum', 'baÅŸlangÄ±Ã§', 'bilmiyorum', 'Ã¶ÄŸreniyorum']):
            self.user_profile['experience_level'] = 'beginner'
        elif any(word in text_lower for word in ['deneyimli', 'uzman', 'profesyonel', 'Ã§alÄ±ÅŸÄ±yorum']):
            self.user_profile['experience_level'] = 'advanced'
        elif any(word in text_lower for word in ['orta', 'biraz', 'temel']):
            self.user_profile['experience_level'] = 'intermediate'
        
        # Detect communication style preference
        if any(word in text_lower for word in ['detaylÄ±', 'aÃ§Ä±kla', 'nasÄ±l', 'neden']):
            self.user_profile['preferred_style'] = 'detailed'
        elif any(word in text_lower for word in ['hÄ±zlÄ±', 'kÄ±sa', 'Ã¶zet', 'direkt']):
            self.user_profile['preferred_style'] = 'concise'

    def _determine_response_type(self, user_message: str, context: Dict) -> str:
        """Determine the most appropriate response type"""
        text_lower = user_message.lower()
        
        # Check if user is responding to previous recommendations
        if self._is_responding_to_recommendations(user_message):
            return 'recommendation_response'
        
        # Algorithm selection/preference - expanded algorithm list
        if any(word in text_lower for word in ['seÃ§mek', 'istiyorum', 'tercih', 'daha iyi olur', 'kullanmak']):
            algorithms_to_check = [
                'xgboost', 'random forest', 'svm', 'neural', 'logistic',
                'k-means', 'kmeans', 'dbscan', 'optics', 'mean shift',
                'naive bayes', 'decision tree', 'knn', 'linear regression',
                'ensemble', 'gradient boosting', 'ada boost'
            ]
            if any(algo in text_lower for algo in algorithms_to_check):
                return 'algorithm_selection'
        
        # Check if user is asking about previously discussed algorithms
        if self.conversation_context['discussed_algorithms']:
            for algo in self.conversation_context['discussed_algorithms']:
                if algo in text_lower:
                    if any(word in text_lower for word in ['neden', 'avantaj', 'dezavantaj', 'nasÄ±l']):
                        return 'algorithm_question'
        
        # Algorithm-specific questions - check if any algorithm mentioned
        algorithms_to_check = [
            'xgboost', 'random forest', 'svm', 'neural', 'logistic',
            'k-means', 'kmeans', 'dbscan', 'optics', 'mean shift',
            'naive bayes', 'decision tree', 'knn', 'linear regression',
            'ensemble', 'gradient boosting', 'ada boost', 'algoritma'
        ]
        
        if any(algo in text_lower for algo in algorithms_to_check):
            if any(word in text_lower for word in ['nasÄ±l Ã§alÄ±ÅŸÄ±r', 'nedir', 'aÃ§Ä±kla', 'anlat', 'avantaj', 'dezavantaj', 'bilgi', 'hakkÄ±nda']):
                return 'algorithm_question'
        
        # Code requests
        if any(word in text_lower for word in ['kod', 'Ã¶rnek', 'implement', 'uygula', 'python']):
            return 'code_request'
        
        # Alternative/comparison requests
        if any(word in text_lower for word in ['karÅŸÄ±laÅŸtÄ±r', 'hangisi', 'fark', 'vs', 'compare', 'baÅŸka', 'alternatif', 'farklÄ±']):
            if any(word in text_lower for word in ['algoritma', 'Ã¶ner', 'Ã¶neri', 'tavsiye']):
                return 'recommendation_response'
        
        # Comparison requests
        if any(word in text_lower for word in ['karÅŸÄ±laÅŸtÄ±r', 'hangisi', 'fark', 'vs', 'compare']):
            return 'comparison_request'
        
        # Ready for recommendations
        if self._is_ready_for_recommendations(context):
            return 'recommendation_ready'
        
        # Default to consultation
        return 'consultation'

    def _is_ready_for_recommendations(self, context: Dict) -> bool:
        """Check if we have enough context for recommendations"""
        required_fields = ['project_type', 'data_size', 'data_type']
        return all(context.get(field) for field in required_fields)
    
    def _is_responding_to_recommendations(self, user_message: str) -> bool:
        """Check if user is responding to previous recommendations"""
        text_lower = user_message.lower()
        
        # Special case: Alternative requests should always be handled as recommendation responses
        if any(word in text_lower for word in ['baÅŸka', 'alternatif']) and any(word in text_lower for word in ['algoritma', 'Ã¶ner', 'Ã¶neri', 'tavsiye']):
            return True
        
        # Check if there were recent recommendations
        if not self.conversation_context['last_recommendations']:
            return False
        
        # Response indicators
        response_indicators = [
            'hayÄ±r', 'evet', 'daha iyi', 'tercih', 'seÃ§mek', 'istiyorum',
            'farklÄ±', 'baÅŸka', 'alternatif', 'neden', 'avantaj', 'dezavantaj'
        ]
        
        return any(indicator in text_lower for indicator in response_indicators)
    
    def _handle_algorithm_selection(self, user_message: str, context: Dict) -> Dict:
        """Handle when user selects a specific algorithm"""
        text_lower = user_message.lower()
        
        # Find selected algorithm
        selected_algorithm = None
        conversation_context = context.get('conversation_context', {})
        user_selections = conversation_context.get('user_selections', [])
        
        # Check if this algorithm was mentioned before
        for selection in user_selections:
            if selection['algorithm'] in text_lower:
                selected_algorithm = selection['algorithm']
                break
        
        if not selected_algorithm:
            # Try to extract from current message - expanded algorithm list
            algorithms = [
                'xgboost', 'random forest', 'svm', 'neural network', 'logistic regression',
                'k-means', 'kmeans', 'dbscan', 'optics', 'mean shift',
                'naive bayes', 'decision tree', 'knn', 'linear regression',
                'ensemble', 'gradient boosting', 'ada boost'
            ]
            for algo in algorithms:
                if algo.replace(' ', '').replace('-', '') in text_lower.replace(' ', '').replace('-', ''):
                    selected_algorithm = algo
                    break
        
        if selected_algorithm:
            # Direct algorithm choice explanation
            return self._explain_algorithm_choice(selected_algorithm, user_message, context)
        else:
            # If no specific algorithm found, still try to be helpful
            return {
                "response": "ğŸ¤– Hangi algoritma kullanmak istediÄŸinizi tam anlayamadÄ±m. Daha spesifik olabilir misiniz?\n\nÃ–rneÄŸin:\nâ€¢ K-means\nâ€¢ Random Forest\nâ€¢ XGBoost\nâ€¢ SVM\n\nHangisini tercih ediyorsunuz?",
                "suggestions": [
                    "K-means kullanmak istiyorum",
                    "Random Forest tercih ediyorum", 
                    "XGBoost seÃ§mek istiyorum",
                    "SVM kullanayÄ±m"
                ],
                "success": True
            }
    
    def _handle_recommendation_response(self, user_message: str, context: Dict) -> Dict:
        """Handle user's response to recommendations"""
        text_lower = user_message.lower()
        
        # Get last recommendations from context
        conversation_context = context.get('conversation_context', {})
        last_recs = conversation_context.get('last_recommendations', [])
        
        # Special handling for alternative requests - even without previous recommendations
        if any(word in text_lower for word in ['baÅŸka', 'alternatif', 'farklÄ±']) and any(word in text_lower for word in ['algoritma', 'Ã¶ner', 'Ã¶neri', 'tavsiye']):
            # User wants alternative recommendations
            return self._provide_alternative_recommendations(user_message, context, last_recs)
        elif 'hayÄ±r' in text_lower or 'farklÄ±' in text_lower:
            # User rejected recommendations, provide alternatives
            return self._provide_alternative_recommendations(user_message, context, last_recs)
        elif 'neden' in text_lower or 'avantaj' in text_lower:
            # User wants explanation
            return self._explain_recommendations(user_message, context, last_recs)
        else:
            # General response to recommendations
            return self._respond_to_recommendation_feedback(user_message, context, last_recs)
    
    def _explain_algorithm_choice(self, algorithm: str, user_message: str, context: Dict) -> Dict:
        """Explain why user's algorithm choice is good/bad"""
        text_lower = user_message.lower()
        
        # Algorithm explanations based on context
        explanations = {
            'xgboost': {
                'pros': [
                    "MÃ¼kemmel seÃ§im! XGBoost gerÃ§ekten gÃ¼Ã§lÃ¼ bir algoritma",
                    "YÃ¼ksek doÄŸruluk oranlarÄ± saÄŸlar",
                    "Overfitting'e karÅŸÄ± dayanÄ±klÄ±",
                    "Ã–zellik Ã¶nemini gÃ¶sterir",
                    "HÄ±zlÄ± eÄŸitim ve tahmin"
                ],
                'cons': [
                    "Hiperparametre ayarlamasÄ± gerekebilir",
                    "KÃ¼Ã§Ã¼k veri setlerinde overkill olabilir",
                    "Bellek kullanÄ±mÄ± yÃ¼ksek olabilir"
                ],
                'when_good': "Orta/bÃ¼yÃ¼k veri setlerinde, yÃ¼ksek doÄŸruluk istediÄŸinizde",
                'when_bad': "Ã‡ok kÃ¼Ã§Ã¼k veri setlerinde, basit problemlerde"
            },
            'random forest': {
                'pros': [
                    "Harika bir seÃ§im! Random Forest Ã§ok gÃ¼venilir",
                    "Overfitting riski dÃ¼ÅŸÃ¼k",
                    "Yorumlanabilir sonuÃ§lar",
                    "Hiperparametre ayarÄ± minimal"
                ],
                'cons': [
                    "Ã‡ok bÃ¼yÃ¼k veri setlerinde yavaÅŸ olabilir",
                    "Bellek kullanÄ±mÄ± yÃ¼ksek"
                ],
                'when_good': "Dengeli doÄŸruluk ve hÄ±z istediÄŸinizde",
                'when_bad': "Ã‡ok bÃ¼yÃ¼k veri setlerinde, hÄ±z kritikse"
            },
            'k-means': {
                'pros': [
                    "MÃ¼kemmel seÃ§im! K-means clustering iÃ§in ideal",
                    "Basit ve anlaÅŸÄ±lÄ±r algoritma",
                    "HÄ±zlÄ± Ã§alÄ±ÅŸÄ±r, bÃ¼yÃ¼k verilerle baÅŸa Ã§Ä±kar",
                    "GÃ¶rselleÅŸtirme imkanlarÄ± mÃ¼kemmel",
                    "MÃ¼ÅŸteri segmentasyonu iÃ§in Ã§ok uygun"
                ],
                'cons': [
                    "K deÄŸerini (kÃ¼me sayÄ±sÄ±nÄ±) Ã¶nceden belirlemek gerekir",
                    "KÃ¼resel olmayan kÃ¼melerde zorlanabilir",
                    "Outlier'lara (aykÄ±rÄ± deÄŸer) hassas"
                ],
                'when_good': "MÃ¼ÅŸteri segmentasyonu, pazar analizi, veri gruplama",
                'when_bad': "Ã‡ok karmaÅŸÄ±k ÅŸekilli kÃ¼meler, belirsiz kÃ¼me sayÄ±sÄ±"
            },
            'kmeans': {
                'pros': [
                    "MÃ¼kemmel seÃ§im! K-means clustering iÃ§in ideal",
                    "Basit ve anlaÅŸÄ±lÄ±r algoritma",
                    "HÄ±zlÄ± Ã§alÄ±ÅŸÄ±r, bÃ¼yÃ¼k verilerle baÅŸa Ã§Ä±kar",
                    "GÃ¶rselleÅŸtirme imkanlarÄ± mÃ¼kemmel",
                    "MÃ¼ÅŸteri segmentasyonu iÃ§in Ã§ok uygun"
                ],
                'cons': [
                    "K deÄŸerini (kÃ¼me sayÄ±sÄ±nÄ±) Ã¶nceden belirlemek gerekir",
                    "KÃ¼resel olmayan kÃ¼melerde zorlanabilir",
                    "Outlier'lara (aykÄ±rÄ± deÄŸer) hassas"
                ],
                'when_good': "MÃ¼ÅŸteri segmentasyonu, pazar analizi, veri gruplama",
                'when_bad': "Ã‡ok karmaÅŸÄ±k ÅŸekilli kÃ¼meler, belirsiz kÃ¼me sayÄ±sÄ±"
            }
        }
        
        algo_info = explanations.get(algorithm, {})
        
        # Determine if choice is good based on context
        project_type = context.get('project_type', '')
        data_size = context.get('data_size', '')
        
        is_good_choice = True  # Default positive
        
        if algorithm == 'xgboost' and data_size == 'small':
            is_good_choice = False
        
        # Generate response
        if is_good_choice:
            response = f"ğŸ¯ **Harika seÃ§im!** {algorithm.title()} sizin projeniz iÃ§in gerÃ§ekten uygun!\n\n"
            response += f"**Neden mÃ¼kemmel bir seÃ§im:**\n"
            for pro in algo_info.get('pros', [])[:3]:
                response += f"âœ… {pro}\n"
            
            response += f"\n**Sizin durumunuzda Ã¶zellikle iyi Ã§Ã¼nkÃ¼:** {algo_info.get('when_good', 'genel olarak gÃ¼Ã§lÃ¼ bir algoritma')}\n\n"
            
            if algo_info.get('cons'):
                response += f"**Dikkat edilmesi gerekenler:**\n"
                for con in algo_info.get('cons', [])[:2]:
                    response += f"âš ï¸ {con}\n"
        else:
            response = f"ğŸ¤” **{algorithm.title()} seÃ§imi hakkÄ±nda dÃ¼ÅŸÃ¼nelim...**\n\n"
            response += f"Bu algoritma gÃ¼Ã§lÃ¼ ama sizin durumunuzda belki daha basit bir seÃ§enek daha uygun olabilir.\n\n"
            response += f"**Neden farklÄ± dÃ¼ÅŸÃ¼nÃ¼yorum:**\n"
            for con in algo_info.get('cons', [])[:2]:
                response += f"âš ï¸ {con}\n"
            
            response += f"\n**Alternatif Ã¶nerim:** Random Forest veya Logistic Regression daha uygun olabilir."
        
        suggestions = [
            f"{algorithm} nasÄ±l implement edilir?",
            "Alternatif algoritma Ã¶ner",
            "Performans karÅŸÄ±laÅŸtÄ±rmasÄ± yap",
            "Kod Ã¶rneÄŸi gÃ¶ster"
        ]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True,
                         "algorithm_discussed": algorithm
         }
    
    def _provide_alternative_recommendations(self, user_message: str, context: Dict, last_recs: List) -> Dict:
        """Provide alternative recommendations when user rejects previous ones"""
        response = "ğŸ”„ **Tamam, farklÄ± seÃ§enekler Ã¶nereyim!**\n\n"
        
        # Add context awareness
        conversation_context = context.get('conversation_context', {})
        user_selections = conversation_context.get('user_selections', [])
        
        if user_selections:
            last_selection = user_selections[-1]
            response += f"Sizin **{last_selection['algorithm']}** tercihinizi de gÃ¶z Ã¶nÃ¼nde bulundurarak, "
            response += f"farklÄ± yaklaÅŸÄ±mlar Ã¶nereyim:\n\n"
        
        # Get alternative algorithms
        alternative_algorithms = [
            "Support Vector Machine (SVM)",
            "Naive Bayes", 
            "K-Nearest Neighbors (KNN)",
            "Decision Tree",
            "Linear Regression"
        ]
        
        # Filter out previously recommended ones
        if last_recs:
            recommended_names = [rec.get('algorithm', rec.get('name', '')).lower() for rec in last_recs]
            alternative_algorithms = [algo for algo in alternative_algorithms 
                                    if not any(rec_name in algo.lower() for rec_name in recommended_names)]
        
        response += "**Alternatif algoritma Ã¶nerilerim:**\n\n"
        for i, algo in enumerate(alternative_algorithms[:3], 1):
            response += f"{i}. **{algo}**\n"
            response += f"   â€¢ FarklÄ± bir yaklaÅŸÄ±m sunar\n"
            response += f"   â€¢ Sizin durumunuz iÃ§in de uygun olabilir\n\n"
        
        # Reference previous conversation
        if last_recs:
            response += f"**Not:** Daha Ã¶nce {len(last_recs)} algoritma Ã¶nermiÅŸtim. "
            response += f"Bu sefer tamamen farklÄ± yaklaÅŸÄ±mlar deneyebiliriz.\n\n"
        
        response += "Hangi alternatif sizi daha Ã§ok ilgilendiriyor?"
        
        return {
            "response": response,
            "suggestions": ["Ä°lk alternatifi seÃ§", "Ä°kinci alternatifi seÃ§", "ÃœÃ§Ã¼ncÃ¼ alternatifi seÃ§"],
            "success": True
        }
    
    def _explain_recommendations(self, user_message: str, context: Dict, last_recs: List) -> Dict:
        """Explain why previous recommendations were made"""
        if not last_recs:
            return self._generate_natural_consultation(user_message, context)
        
        response = "ğŸ’¡ **Ã–nerilerimin nedenlerini aÃ§Ä±klayayÄ±m:**\n\n"
        
        # Add context awareness
        conversation_context = context.get('conversation_context', {})
        user_selections = conversation_context.get('user_selections', [])
        
        if user_selections:
            last_selection = user_selections[-1]
            response += f"Daha Ã¶nce **{last_selection['algorithm']}** algoritmasÄ±nÄ± tercih ettiÄŸinizi belirtmiÅŸtiniz. "
            response += f"Åimdi size neden baÅŸka algoritmalarÄ± Ã¶nerdiÄŸimi aÃ§Ä±klayayÄ±m:\n\n"
        
        for i, rec in enumerate(last_recs[:3], 1):
            algo_name = rec.get('algorithm', rec.get('name', 'Algoritma'))
            confidence = rec.get('confidence_score', rec.get('confidence', 0.8))
            
            response += f"**{i}. {algo_name}** (Uygunluk: {confidence:.0%})\n"
            
            # Context-based explanations
            project_type = context.get('project_type', '')
            data_size = context.get('data_size', '')
            
            if 'xgboost' in algo_name.lower():
                response += f"   ğŸ¯ **Neden Ã¶nerdiÄŸim:** YÃ¼ksek performans, {project_type} problemlerinde Ã§ok baÅŸarÄ±lÄ±\n"
                response += f"   âš¡ **AvantajlarÄ±:** HÄ±zlÄ±, doÄŸru, overfitting'e dayanÄ±klÄ±\n"
            elif 'random forest' in algo_name.lower():
                response += f"   ğŸ¯ **Neden Ã¶nerdiÄŸim:** GÃ¼venilir, yorumlanabilir, {data_size} veri iÃ§in ideal\n"
                response += f"   âš¡ **AvantajlarÄ±:** Stabil sonuÃ§lar, az hiperparametre\n"
            elif 'svm' in algo_name.lower():
                response += f"   ğŸ¯ **Neden Ã¶nerdiÄŸim:** Matematiksel olarak gÃ¼Ã§lÃ¼, {project_type} iÃ§in etkili\n"
                response += f"   âš¡ **AvantajlarÄ±:** YÃ¼ksek boyutlu veriler iÃ§in iyi\n"
            elif 'mlp' in algo_name.lower() or 'algÄ±layÄ±cÄ±' in algo_name.lower():
                response += f"   ğŸ¯ **Neden Ã¶nerdiÄŸim:** Ã‡ok katmanlÄ± yapÄ±, {project_type} iÃ§in gÃ¼Ã§lÃ¼\n"
                response += f"   âš¡ **AvantajlarÄ±:** Esnek yapÄ±, kompleks kalÄ±plarÄ± Ã¶ÄŸrenir\n"
            elif 'ensemble' in algo_name.lower():
                response += f"   ğŸ¯ **Neden Ã¶nerdiÄŸim:** Birden fazla modeli birleÅŸtir, {project_type} iÃ§in stabil\n"
                response += f"   âš¡ **AvantajlarÄ±:** YÃ¼ksek doÄŸruluk, overfitting'e dayanÄ±klÄ±\n"
            else:
                response += f"   ğŸ¯ **Neden Ã¶nerdiÄŸim:** {project_type} projeniz iÃ§in optimize edilmiÅŸ\n"
                response += f"   âš¡ **AvantajlarÄ±:** Sizin veri tipinize uygun\n"
            
            response += f"\n"
        
        # Reference user's selection if they made one
        if user_selections:
            last_selection = user_selections[-1]
            response += f"**Sizin tercihiniz olan {last_selection['algorithm']} hakkÄ±nda:** "
            response += f"Bu da mÃ¼kemmel bir seÃ§im! YukarÄ±daki Ã¶nerilerimle karÅŸÄ±laÅŸtÄ±rabilirsiniz.\n\n"
        
        response += "Bu aÃ§Ä±klamalar yardÄ±mcÄ± oldu mu? BaÅŸka bir ÅŸey merak ediyorsanÄ±z sorabilirsiniz!"
        
        return {
            "response": response,
            "suggestions": ["Kod Ã¶rneÄŸi gÃ¶ster", "Performans karÅŸÄ±laÅŸtÄ±r", "FarklÄ± algoritma Ã¶ner"],
            "success": True
        }
    
    def _respond_to_recommendation_feedback(self, user_message: str, context: Dict, last_recs: List) -> Dict:
        """Respond to general feedback about recommendations"""
        text_lower = user_message.lower()
        
        if any(word in text_lower for word in ['evet', 'tamam', 'iyi', 'gÃ¼zel']):
            response = "ğŸ‰ **Harika! SeÃ§iminizi beÄŸendiÄŸinize sevindim.**\n\n"
            response += "Åimdi implementasyon aÅŸamasÄ±na geÃ§elim. Size yardÄ±mcÄ± olabileceÄŸim konular:\n\n"
            response += "â€¢ **Kod Ã¶rnekleri** - AlgoritmayÄ± nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± gÃ¶sterebilirim\n"
            response += "â€¢ **Hiperparametre ayarlarÄ±** - En iyi performans iÃ§in optimizasyon\n"
            response += "â€¢ **Veri hazÄ±rlama** - Algoritma iÃ§in veriyi nasÄ±l hazÄ±rlayacaÄŸÄ±nÄ±z\n"
            response += "â€¢ **Performans deÄŸerlendirme** - SonuÃ§larÄ± nasÄ±l analiz edeceÄŸiniz\n\n"
            response += "Hangi konuda yardÄ±m istiyorsunuz?"
            
            suggestions = ["Kod Ã¶rneÄŸi gÃ¶ster", "Hiperparametre ayarlarÄ±", "Veri hazÄ±rlama", "Performans deÄŸerlendirme"]
        else:
            response = "ğŸ¤” **AnlÄ±yorum, daha fazla bilgi istiyorsunuz.**\n\n"
            response += "Size nasÄ±l yardÄ±mcÄ± olabilirim?\n\n"
            response += "â€¢ AlgoritmalarÄ± daha detaylÄ± aÃ§Ä±klayayÄ±m\n"
            response += "â€¢ FarklÄ± seÃ§enekler Ã¶nereyim\n"
            response += "â€¢ Performans karÅŸÄ±laÅŸtÄ±rmasÄ± yapayÄ±m\n"
            response += "â€¢ Spesifik sorularÄ±nÄ±zÄ± yanÄ±tlayayÄ±m\n\n"
            response += "Ne yapmamÄ± istersiniz?"
            
            suggestions = ["DetaylÄ± aÃ§Ä±klama", "FarklÄ± seÃ§enekler", "Performans karÅŸÄ±laÅŸtÄ±rmasÄ±", "Spesifik soru sor"]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
 
    def _generate_natural_consultation(self, user_message: str, context: Dict) -> Dict:
        """Generate natural, conversational consultation response"""
        if self.openai_enabled:
            return self._generate_gpt4_natural_consultation(user_message, context)
        else:
            return self._generate_template_natural_consultation(user_message, context)

    def _generate_gpt4_natural_consultation(self, user_message: str, context: Dict) -> Dict:
        """Generate natural consultation using GPT-4"""
        # Prepare rich context for GPT-4
        conversation_summary = self._summarize_conversation()
        user_profile_summary = self._summarize_user_profile()
        
        context_prompt = f"""
KonuÅŸma Ã–zeti: {conversation_summary}

KullanÄ±cÄ± Profili: {user_profile_summary}

Mevcut Proje Bilgileri:
- Proje tÃ¼rÃ¼: {context.get('project_type', 'HenÃ¼z belirlenmedi')}
- Veri boyutu: {context.get('data_size', 'HenÃ¼z belirlenmedi')}
- Veri tÃ¼rÃ¼: {context.get('data_type', 'HenÃ¼z belirlenmedi')}
- KullanÄ±m alanÄ±: {context.get('use_case', 'HenÃ¼z belirlenmedi')}
- KÄ±sÄ±tlamalar: {', '.join(context.get('constraints', [])) if context.get('constraints') else 'Yok'}

KullanÄ±cÄ±nÄ±n Son MesajÄ±: "{user_message}"

GÃ¶revin:
1. KullanÄ±cÄ±nÄ±n mesajÄ±na samimi ve doÄŸal bir ÅŸekilde cevap ver
2. Eksik bilgileri Ã¶ÄŸrenmek iÃ§in yaratÄ±cÄ± sorular sor
3. KiÅŸisel deneyimlerini paylaÅŸ
4. Cesaretlendirici ve destekleyici ol
5. Teknik terimleri gÃ¼nlÃ¼k dille aÃ§Ä±kla
6. 2-3 paragraf halinde akÄ±cÄ± bir konuÅŸma yap

Robotik cevaplar verme, gerÃ§ek bir mentor gibi konuÅŸ!
"""
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": self.consultation_prompt},
                    {"role": "user", "content": context_prompt}
                ],
                max_tokens=500,
                temperature=0.9,  # Higher temperature for more creative responses
                presence_penalty=0.3,  # Encourage diverse vocabulary
                frequency_penalty=0.3   # Reduce repetition
            )
            
            gpt_response = response.choices[0].message.content
            
            # Generate contextual suggestions
            suggestions = self._generate_natural_suggestions(context, user_message)
            
            return {
                "response": gpt_response,
                "suggestions": suggestions,
                "success": True,
                "ai_powered": True,
                "conversation_stage": self._get_conversation_stage(context)
            }
                
        except Exception as e:
            logger.error(f"GPT-4 consultation failed: {e}")
            return self._generate_template_natural_consultation(user_message, context)

    def _generate_template_natural_consultation(self, user_message: str, context: Dict) -> Dict:
        """Generate natural consultation using enhanced templates"""
        text_lower = user_message.lower()
        
        # Check for diversity instruction
        diversity_mode = context.get('diversity_instruction') is not None
        conversation_turn = context.get('conversation_turn', 1)
        
        # Greeting responses with enhanced diversity and context awareness
        if any(word in text_lower for word in ['merhaba', 'selam', 'hello', 'hi']):
            # Check conversation history for context
            conversation_context = context.get('conversation_context', {})
            discussed_algorithms = conversation_context.get('discussed_algorithms', [])
            user_selections = conversation_context.get('user_selections', [])
            
            # Check if we have diversity instruction
            if diversity_mode:
                responses = [
                    "Tekrar hoÅŸ geldiniz! Bu sefer hangi algoritma macerasÄ±na Ã§Ä±kacaÄŸÄ±z? Her konuÅŸmada farklÄ± hikayeler keÅŸfediyoruz ve bu gerÃ§ekten keyifli! \n\nBu kez hangi tÃ¼r bir proje Ã¼zerinde kafa yoruyorsunuz? Belki daha Ã¶nce hiÃ§ dÃ¼ÅŸÃ¼nmediÄŸiniz bir yaklaÅŸÄ±m bulabiliriz.",
                    
                    "Yine buradayÄ±z! Makine Ã¶ÄŸrenmesi dÃ¼nyasÄ±nda yeni bir keÅŸif yapmaya hazÄ±r mÄ±sÄ±nÄ±z? Her seferinde farklÄ± aÃ§Ä±lardan bakÄ±yoruz ve bu Ã§ok eÄŸlenceli! \n\nBu sefer hangi veri bilimi problemini Ã§Ã¶zmek istiyorsunuz? Belki bambaÅŸka bir algoritma ailesi keÅŸfederiz!",
                    
                    "Geri dÃ¶ndÃ¼ÄŸÃ¼nÃ¼z iÃ§in mutluyum! Bu kez hangi algoritma yolculuÄŸuna Ã§Ä±kacaÄŸÄ±z? Her konuÅŸma yeni perspektifler getiriyor. \n\nBu sefer hangi tÃ¼r bir analiz yapmayÄ± planlÄ±yorsunuz? FarklÄ± bir yaklaÅŸÄ±m denemek iÃ§in sabÄ±rsÄ±zlanÄ±yorum!"
                ]
            else:
                base_responses = [
                    "Merhaba! Ben AlgoMentor, makine Ã¶ÄŸrenmesi algoritmalarÄ±nda size yardÄ±mcÄ± olmak iÃ§in buradayÄ±m. GerÃ§ekten heyecan verici bir alanda Ã§alÄ±ÅŸÄ±yorsunuz! \n\nBenim deneyimime gÃ¶re, doÄŸru algoritma seÃ§imi projenin baÅŸarÄ±sÄ±nÄ±n %80'ini belirliyor. Peki, hangi tÃ¼r bir proje Ã¼zerinde Ã§alÄ±ÅŸÄ±yorsunuz? Merak ettim Ã§Ã¼nkÃ¼ her projenin kendine Ã¶zgÃ¼ gÃ¼zellikleri var.",
                    
                    "Selam! HoÅŸ geldiniz! Ben makine Ã¶ÄŸrenmesi dÃ¼nyasÄ±nda size rehberlik edecek AlgoMentor'unuz. YÄ±llardÄ±r bu alanda Ã§alÄ±ÅŸÄ±yorum ve her yeni proje beni hala heyecanlandÄ±rÄ±yor.\n\nÅÃ¶yle ki, algoritma seÃ§imi biraz mÃ¼zik enstrÃ¼manÄ± seÃ§meye benziyor - her biri farklÄ± melodiler Ã§Ä±karÄ±yor. Sizin projeniz hangi tÃ¼r bir 'melodi' Ã§Ä±karmak istiyor? AnlatsanÄ±z, size en uygun 'enstrÃ¼manÄ±' bulalÄ±m!"
                ]
                
                # Add context awareness if there's conversation history
                if discussed_algorithms or user_selections:
                    context_addition = "\n\n**KonuÅŸma geÃ§miÅŸimizden:** "
                    if discussed_algorithms:
                        context_addition += f"Daha Ã¶nce {', '.join(discussed_algorithms)} algoritmalarÄ±nÄ± konuÅŸmuÅŸtuk. "
                    if user_selections:
                        last_selection = user_selections[-1]
                        context_addition += f"Ã–zellikle {last_selection['algorithm']} algoritmasÄ±nÄ± tercih ettiÄŸinizi hatÄ±rlÄ±yorum. "
                    context_addition += "Bu bilgileri gÃ¶z Ã¶nÃ¼nde bulundurarak size yardÄ±mcÄ± olabilirim!"
                    
                    responses = [resp + context_addition for resp in base_responses]
                else:
                    responses = base_responses
            
            response = random.choice(responses)
            suggestions = [
                "Veri sÄ±nÄ±flandÄ±rmasÄ± yapmak istiyorum",
                "Tahmin modeli geliÅŸtiriyorum",
                "Veri analizi yapacaÄŸÄ±m",
                "HenÃ¼z ne yapacaÄŸÄ±mÄ± bilmiyorum"
            ]
        
        # Project type discovery with diversity
        elif not context.get('project_type'):
            if diversity_mode:
                responses = [
                    "Bu kez farklÄ± bir aÃ§Ä±dan bakalÄ±m! Proje hedeflerinizi daha detaylÄ± anlayabilir miyim? Her projenin kendine Ã¶zgÃ¼ bir hikayesi var ve sizinkini merak ediyorum. \n\nBu sefer hangi tÃ¼r bir veri macerasÄ±na atÄ±lÄ±yorsunuz? Belki hiÃ§ dÃ¼ÅŸÃ¼nmediÄŸiniz bir yaklaÅŸÄ±m keÅŸfederiz!",
                    
                    "Yeni bir perspektifle yaklaÅŸalÄ±m! Verilerinizle nasÄ±l bir sonuca ulaÅŸmak istiyorsunuz? Bu kez farklÄ± algoritma ailelerini keÅŸfetmek iÃ§in sabÄ±rsÄ±zlanÄ±yorum. \n\nProjenizin ana amacÄ± nedir? Hangi tÃ¼r Ã§Ä±ktÄ± elde etmeyi hedefliyorsunuz?",
                    
                    "Bu sefer bambaÅŸka bir yoldan gidelim! Projenizin Ã¶zÃ¼nÃ¼ anlayabilir miyim? Her seferinde farklÄ± Ã§Ã¶zÃ¼m yollarÄ± keÅŸfediyoruz. \n\nBu kez hangi tÃ¼r analiz yapmayÄ± planlÄ±yorsunuz? Belki daha Ã¶nce hiÃ§ dÃ¼ÅŸÃ¼nmediÄŸiniz bir algoritma kategorisi bulabiliriz!"
                ]
            else:
                responses = [
                    "Vay, bu gerÃ§ekten ilginÃ§ geliyor! Benim deneyimime gÃ¶re, projenin hedefini net anlamak algoritma seÃ§iminin yarÄ±sÄ± demek. \n\nMesela, geÃ§en ay bir e-ticaret ÅŸirketi ile Ã§alÄ±ÅŸtÄ±m - onlar mÃ¼ÅŸteri davranÄ±ÅŸlarÄ±nÄ± tahmin etmek istiyordu. Sizin durumunuz nasÄ±l? Hangi tÃ¼r bir sonuÃ§ elde etmeyi hedefliyorsunuz? Verilerinizle ne yapmak istiyorsunuz?",
                    
                    "ÅÃ¶yle dÃ¼ÅŸÃ¼nelim: Makine Ã¶ÄŸrenmesi biraz dedektiflik gibi - verilerden ipuÃ§larÄ± toplayÄ±p bir sonuca varÄ±yoruz. Peki sizin 'gizeminiz' nedir? \n\nVerilerinizle ÅŸunlardan hangisini yapmak istiyorsunuz: Bir ÅŸeyleri kategorilere ayÄ±rmak mÄ±, gelecekteki deÄŸerleri tahmin etmek mi, yoksa veriler arasÄ±ndaki gizli kalÄ±plarÄ± keÅŸfetmek mi?"
                ]
            
            response = random.choice(responses)
            suggestions = [
                "Verileri kategorilere ayÄ±rmak istiyorum",
                "Gelecekteki deÄŸerleri tahmin etmek istiyorum",
                "Veri gruplarÄ±nÄ± keÅŸfetmek istiyorum",
                "Anormal durumlarÄ± tespit etmek istiyorum"
            ]
        
        # Data size discovery with context awareness
        elif not context.get('data_size'):
            project_type = context.get('project_type', 'proje')
            
            # Check conversation history for previous mentions
            conversation_context = self._get_conversation_context()
            
            if diversity_mode:
                responses = [
                    f"Åimdi {project_type} projeniz iÃ§in veri boyutunu konuÅŸalÄ±m! Bu kez farklÄ± bir aÃ§Ä±dan yaklaÅŸmak istiyorum. Veri boyutu algoritma performansÄ±nÄ± doÄŸrudan etkiler. \n\nBu sefer veri setinizin boyutu hakkÄ±nda ne sÃ¶yleyebilirsiniz? KaÃ§ kayÄ±t var yaklaÅŸÄ±k olarak?",
                    
                    f"Bu kez {project_type} projenizin veri boyutunu keÅŸfedelim! Her algoritmanÄ±n farklÄ± veri boyutlarÄ±nda farklÄ± performans gÃ¶sterdiÄŸini biliyorsunuz. \n\nBu sefer veri setinizin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ nasÄ±l? Hangi aralÄ±kta?"
                ]
            else:
                responses = [
                    f"Harika! {project_type} gerÃ§ekten gÃ¼zel bir alan. Benim deneyimime gÃ¶re, veri boyutu algoritma seÃ§iminde kritik rol oynuyor. \n\nMesela, kÃ¼Ã§Ã¼k veri setlerinde basit algoritmalar mucizeler yaratabilirken, bÃ¼yÃ¼k verilerde daha sofistike yaklaÅŸÄ±mlar gerekiyor. Sizin veri setiniz hangi boyutta? KaÃ§ kayÄ±t var yaklaÅŸÄ±k olarak?",
                    
                    f"ÅÃ¶yle ki, {project_type} projesi iÃ§in veri boyutu biraz yemeÄŸin porsiyon miktarÄ± gibi - az olursa farklÄ± piÅŸirme teknikleri, Ã§ok olursa farklÄ± yaklaÅŸÄ±mlar gerekiyor. \n\nVerilerinizin boyutu nasÄ±l? Bu bilgi sayesinde size en verimli algoritmalarÄ± Ã¶nerebilirim."
                ]
            
            response = random.choice(responses)
            suggestions = [
                "KÃ¼Ã§Ã¼k veri setim var (1000'den az)",
                "Orta boyut veri setim var (1000-10000)",
                "BÃ¼yÃ¼k veri setim var (10000+)",
                "Ã‡ok bÃ¼yÃ¼k veri setim var (100000+)"
            ]
        
        # Data type discovery
        elif not context.get('data_type'):
            responses = [
                "MÃ¼kemmel! Veri boyutunu bilmek Ã§ok yardÄ±mcÄ± oldu. Åimdi veri tÃ¼rÃ¼nÃ¼ Ã¶ÄŸrenmek istiyorum Ã§Ã¼nkÃ¼ bu da algoritma seÃ§imini doÄŸrudan etkiliyor.\n\nBenim deneyimime gÃ¶re, sayÄ±sal veriler farklÄ±, metin verileri farklÄ± yaklaÅŸÄ±mlar istiyor. TÄ±pkÄ± farklÄ± dilleri konuÅŸmak gibi - her biri kendine Ã¶zgÃ¼ kurallarÄ± var. Sizin verileriniz hangi tÃ¼rde?",
                
                "ÅÃ¶yle dÃ¼ÅŸÃ¼nelim: Veriler biraz farklÄ± dillerde yazÄ±lmÄ±ÅŸ kitaplar gibi. SayÄ±sal veriler matematik dili, metin verileri edebiyat dili, gÃ¶rÃ¼ntÃ¼ler ise sanat dili konuÅŸuyor. \n\nSizin verileriniz hangi 'dilde' konuÅŸuyor? Bu bilgi ile size en uygun 'Ã§evirmen' algoritmayÄ± bulabilirim."
            ]
            
            response = random.choice(responses)
            suggestions = [
                "SayÄ±sal verilerle Ã§alÄ±ÅŸÄ±yorum",
                "Metin verileri iÅŸliyorum",
                "Kategorik verilerim var",
                "GÃ¶rÃ¼ntÃ¼ verileri kullanÄ±yorum"
            ]
        
        # Ready for recommendations
        else:
            response = "Harika! ArtÄ±k projeniz hakkÄ±nda yeterli bilgiye sahibim. Veri setinizin Ã¶zelliklerini ve hedeflerinizi anlayarak size Ã¶zel algoritma Ã¶nerilerimi hazÄ±rlÄ±yorum. \n\nBenim deneyimime gÃ¶re, sizin durumunuz iÃ§in birkaÃ§ mÃ¼kemmel seÃ§enek var. Hemen en uygun algoritmalarÄ± analiz edeyim!"
            suggestions = ["Algoritma Ã¶nerilerini gÃ¶ster"]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True,
            "conversation_stage": self._get_conversation_stage(context)
        }

    def _summarize_conversation(self) -> str:
        """Summarize recent conversation for context"""
        if not self.conversation_memory:
            return "Yeni konuÅŸma baÅŸlÄ±yor"
        
        recent_topics = []
        for msg in self.conversation_memory[-5:]:
            if 'sÄ±nÄ±flandÄ±rma' in msg['content'].lower():
                recent_topics.append('sÄ±nÄ±flandÄ±rma')
            elif 'regresyon' in msg['content'].lower():
                recent_topics.append('regresyon')
            elif 'kÃ¼meleme' in msg['content'].lower():
                recent_topics.append('kÃ¼meleme')
        
        if recent_topics:
            return f"Son konuÅŸulan konular: {', '.join(set(recent_topics))}"
        return "Genel algoritma danÄ±ÅŸmanlÄ±ÄŸÄ±"

    def _summarize_user_profile(self) -> str:
        """Summarize user profile for context"""
        profile_parts = []
        
        if self.user_profile['experience_level'] != 'unknown':
            profile_parts.append(f"Deneyim: {self.user_profile['experience_level']}")
        
        if self.user_profile['preferred_style'] != 'unknown':
            profile_parts.append(f"Tercih: {self.user_profile['preferred_style']}")
        
        return ', '.join(profile_parts) if profile_parts else "Profil henÃ¼z belirlenmedi"

    def _generate_natural_suggestions(self, context: Dict, user_message: str) -> List[str]:
        """Generate natural, contextual suggestions"""
        if not context.get('project_type'):
            return [
                "MÃ¼ÅŸteri davranÄ±ÅŸlarÄ±nÄ± tahmin etmek istiyorum",
                "E-posta spam tespiti yapacaÄŸÄ±m",
                "SatÄ±ÅŸ tahminleri yapmak istiyorum",
                "GÃ¶rÃ¼ntÃ¼ tanÄ±ma projesi geliÅŸtiriyorum"
            ]
        elif not context.get('data_size'):
            return [
                "BirkaÃ§ yÃ¼z kayÄ±t var",
                "Binlerce kayÄ±t var",
                "On binlerce kayÄ±t var",
                "Milyonlarca kayÄ±t var"
            ]
        elif not context.get('data_type'):
            return [
                "Excel tablosunda sayÄ±sal veriler",
                "MÃ¼ÅŸteri yorumlarÄ± ve metinler",
                "ÃœrÃ¼n kategorileri ve etiketler",
                "FotoÄŸraf ve gÃ¶rÃ¼ntÃ¼ dosyalarÄ±"
            ]
        else:
            return [
                "En iyi algoritmalarÄ± Ã¶ner",
                "Performans karÅŸÄ±laÅŸtÄ±rmasÄ± yap",
                "Kod Ã¶rnekleri ver",
                "Hangi metriÄŸi kullanmalÄ±yÄ±m?"
            ]

    def _get_conversation_context(self) -> str:
        """Get conversation context from memory"""
        if not self.conversation_memory:
            return "Yeni konuÅŸma"
        
        # Build context from conversation memory
        context_parts = []
        
        # Check for discussed algorithms
        if self.conversation_context['discussed_algorithms']:
            context_parts.append(f"Daha Ã¶nce {', '.join(self.conversation_context['discussed_algorithms'])} algoritmalarÄ±nÄ± konuÅŸtuk.")
        
        # Check for user selections
        if self.conversation_context['user_selections']:
            last_selection = self.conversation_context['user_selections'][-1]
            context_parts.append(f"Ã–zellikle {last_selection['algorithm']} algoritmasÄ±nÄ± tercih ettiÄŸinizi belirttiniz.")
        
        # Check for recent feedback
        if self.conversation_context['user_feedback']:
            recent_feedback = self.conversation_context['user_feedback'][-1]
            if recent_feedback['type'] == 'positive':
                context_parts.append("Son Ã¶nerilerimizi beÄŸendiÄŸinizi sÃ¶ylemiÅŸtiniz.")
            elif recent_feedback['type'] == 'negative':
                context_parts.append("Son Ã¶nerilerimden memnun olmadÄ±ÄŸÄ±nÄ±zÄ± belirttiniz.")
        
        # Check for last recommendations
        if self.conversation_context['last_recommendations']:
            rec_count = len(self.conversation_context['last_recommendations'])
            context_parts.append(f"Size {rec_count} algoritma Ã¶nerisi sunmuÅŸtum.")
        
        return " ".join(context_parts) if context_parts else "KonuÅŸmamÄ±z devam ediyor."
        
        # Analyze recent conversation
        recent_topics = []
        for msg in self.conversation_memory[-5:]:
            content = msg.get('content', '').lower()
            if 'sÄ±nÄ±flandÄ±rma' in content or 'classification' in content:
                recent_topics.append('sÄ±nÄ±flandÄ±rma')
            elif 'regresyon' in content or 'regression' in content:
                recent_topics.append('regresyon')
            elif 'kÃ¼meleme' in content or 'clustering' in content:
                recent_topics.append('kÃ¼meleme')
            elif 'algoritma' in content:
                recent_topics.append('algoritma')
        
        if recent_topics:
            return f"Ã–nceki konuÅŸma: {', '.join(set(recent_topics))}"
        return "Genel makine Ã¶ÄŸrenmesi"

    def _get_conversation_stage(self, context: Dict) -> str:
        """Determine current conversation stage"""
        if not context.get('project_type'):
            return 'project_discovery'
        elif not context.get('data_size'):
            return 'data_sizing'
        elif not context.get('data_type'):
            return 'data_typing'
        else:
            return 'recommendation_ready'

    def _generate_enhanced_recommendations(self, user_message: str, context: Dict) -> Dict:
        """Generate enhanced algorithm recommendations with natural language"""
        if self.openai_enabled:
            return self._generate_gpt4_enhanced_recommendations(user_message, context)
        else:
            return self._generate_template_enhanced_recommendations(user_message, context)

    def _generate_gpt4_enhanced_recommendations(self, user_message: str, context: Dict) -> Dict:
        """Generate recommendations using GPT-4 with natural storytelling"""
        # Get algorithm recommendations from our model
        recommendations = self.algorithm_recommender.get_recommendations(
            project_type=context.get('project_type'),
            data_size=context.get('data_size'),
            data_type=context.get('data_type'),
            complexity_preference='medium',
            top_n=3
        )
        
        # Prepare context for GPT-4
        recommendations_summary = []
        for rec in recommendations:
            confidence = rec.get('confidence_score', rec.get('confidence', 0.8))
            explanation = rec.get('explanation', rec.get('description', ''))
            recommendations_summary.append(f"- {rec['algorithm']} (GÃ¼ven: {confidence:.1f}): {explanation}")
        
        context_prompt = f"""
KullanÄ±cÄ±nÄ±n Proje Bilgileri:
- Proje tÃ¼rÃ¼: {context.get('project_type')}
- Veri boyutu: {context.get('data_size')}
- Veri tÃ¼rÃ¼: {context.get('data_type')}

Ã–nerilen Algoritmalar:
{chr(10).join(recommendations_summary)}

KullanÄ±cÄ±nÄ±n Son MesajÄ±: "{user_message}"

GÃ¶revin:
1. AlgoritmalarÄ± hikaye anlatÄ±r gibi tanÄ±t
2. Her algoritmanÄ±n "karakterini" ve "kiÅŸiliÄŸini" aÃ§Ä±kla
3. GerÃ§ek dÃ¼nya Ã¶rnekleri ver
4. Hangi durumda hangisini seÃ§eceÄŸini aÃ§Ä±kla
5. KiÅŸisel deneyimlerini paylaÅŸ
6. Cesaretlendirici ve destekleyici ol
7. 3-4 paragraf halinde akÄ±cÄ± bir anlatÄ±m yap

Robotik listeler yerine hikaye anlatÄ±r gibi konuÅŸ!
"""
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": self.algorithm_expert_prompt},
                    {"role": "user", "content": context_prompt}
                ],
                max_tokens=800,
                temperature=0.8,
                presence_penalty=0.2,
                frequency_penalty=0.2
            )
            
            gpt_response = response.choices[0].message.content
            
            # Generate follow-up suggestions
            suggestions = [
                f"{recommendations[0]['algorithm']} hakkÄ±nda daha fazla bilgi",
                "Kod Ã¶rnekleri gÃ¶ster",
                "Performans karÅŸÄ±laÅŸtÄ±rmasÄ± yap",
                "Hangi metriÄŸi kullanmalÄ±yÄ±m?"
            ]
            
            return {
                "response": gpt_response,
                "suggestions": suggestions,
                "recommendations": recommendations,
                "success": True,
                "ai_powered": True
            }
            
        except Exception as e:
            logger.error(f"GPT-4 recommendations failed: {e}")
            return self._generate_template_enhanced_recommendations(user_message, context)

    def _generate_template_enhanced_recommendations(self, user_message: str, context: Dict) -> Dict:
        """Generate enhanced recommendations using creative templates"""
        # Get algorithm recommendations
        recommendations = self.algorithm_recommender.get_recommendations(
            project_type=context.get('project_type'),
            data_size=context.get('data_size'),
            data_type=context.get('data_type'),
            complexity_preference='medium',
            top_n=3
        )
        
        if not recommendations:
            return self._get_emergency_fallback()
    
        # Create storytelling response
        project_type = context.get('project_type', 'proje')
        top_algo = recommendations[0]
        
        storytelling_intros = [
            f"Harika! {project_type} projeniz iÃ§in analiz yaptÄ±m ve gerÃ§ekten heyecan verici sonuÃ§lar Ã§Ä±ktÄ±. Benim deneyimime gÃ¶re, sizin durumunuz iÃ§in birkaÃ§ 'sÃ¼per kahraman' algoritma var.",
            
            f"Vay canÄ±na! {project_type} projesi iÃ§in mÃ¼kemmel bir kombinasyon buldum. ÅÃ¶yle ki, her algoritmanÄ±n kendine Ã¶zgÃ¼ bir 'kiÅŸiliÄŸi' var ve sizin verilerinizle harika bir uyum saÄŸlayacak olanlarÄ± seÃ§tim.",
            
            f"MÃ¼jde! {project_type} alanÄ±nda Ã§ok baÅŸarÄ±lÄ± sonuÃ§lar veren algoritmalar var ve sizin veri setiniz iÃ§in Ã¶zel olarak en uygun olanlarÄ± analiz ettim."
        ]
        
        response = random.choice(storytelling_intros) + "\n\n"
        
        # Describe top algorithm with personality
        algo_personalities = {
            'Random Forest': "Random Forest gerÃ§ek bir 'takÄ±m oyuncusu' - yÃ¼zlerce kÃ¼Ã§Ã¼k karar aÄŸacÄ±ndan oluÅŸan bir orkestra gibi Ã§alÄ±ÅŸÄ±yor. Benim deneyimime gÃ¶re, Ã§ok gÃ¼venilir ve hatalarÄ±nÄ± kendi kendine dÃ¼zelten nadir algoritmalardan biri.",
            
            'XGBoost': "XGBoost ise 'mÃ¼kemmeliyetÃ§i' bir karakter - her hatadan Ã¶ÄŸrenen ve sÃ¼rekli kendini geliÅŸtiren bir algoritma. Kaggle yarÄ±ÅŸmalarÄ±nÄ±n kralÄ± diye boÅŸuna demiyorlar!",
            
            'Logistic Regression': "Logistic Regression 'sade ve etkili' bir yaklaÅŸÄ±m - bazen en basit Ã§Ã¶zÃ¼mler en gÃ¼Ã§lÃ¼ olanlar oluyor. HÄ±zlÄ±, anlaÅŸÄ±lÄ±r ve gÃ¼venilir.",
            
            'K-Means': "K-Means 'organizatÃ¶r' bir algoritma - karmaÅŸÄ±k veri yÄ±ÄŸÄ±nlarÄ±nÄ± dÃ¼zenli gruplara ayÄ±rmada uzman. Basit ama Ã§ok etkili.",
            
            'SVM': "SVM 'mÃ¼kemmel sÄ±nÄ±r Ã§izici' - veriler arasÄ±nda en optimal sÄ±nÄ±rlarÄ± bulan, matematiksel olarak Ã§ok zarif bir algoritma."
        }
        
        top_algo_name = top_algo['algorithm']
        if top_algo_name in algo_personalities:
            response += algo_personalities[top_algo_name]
        else:
            explanation = top_algo.get('explanation', top_algo.get('description', 'Ã§ok uygun bir seÃ§im'))
            response += f"{top_algo_name} sizin projeniz iÃ§in mÃ¼kemmel bir seÃ§im Ã§Ã¼nkÃ¼ {explanation.lower()}"
        
        confidence = top_algo.get('confidence_score', top_algo.get('confidence', 0.8))
        response += f" GÃ¼ven oranÄ± %{confidence * 100:.0f} - bu gerÃ§ekten yÃ¼ksek bir skor!\n\n"
        
        # Add practical advice
        practical_advice = [
            "Benim tavsiyem, Ã¶nce bu algoritmayla baÅŸlayÄ±n ve sonuÃ§larÄ± gÃ¶zlemleyin. Genellikle ilk denemede Ã§ok iyi sonuÃ§lar alÄ±yorsunuz.",
            
            "ÅÃ¶yle bir strateji Ã¶neriyorum: Bu algoritmayla temel modelinizi kurun, sonra diÄŸer seÃ§enekleri de deneyin ve karÅŸÄ±laÅŸtÄ±rÄ±n.",
            
            "Pratik aÃ§Ä±dan bakarsak, bu algoritma sizin veri setinizle harika Ã§alÄ±ÅŸacak. Ä°sterseniz adÄ±m adÄ±m nasÄ±l uygulayacaÄŸÄ±nÄ±zÄ± da anlatabilirim."
        ]
        
        response += random.choice(practical_advice)
        
        # Generate contextual suggestions
        suggestions = [
            f"{top_algo_name} nasÄ±l Ã§alÄ±ÅŸÄ±r?",
            "Kod Ã¶rneÄŸi ver",
            "DiÄŸer algoritmalarÄ± da gÃ¶ster",
            "Performans karÅŸÄ±laÅŸtÄ±rmasÄ± yap"
        ]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "recommendations": recommendations,
            "success": True
        }
    
    def _extract_enhanced_project_context(self, current_message: str, conversation_history: Optional[List[Dict]] = None) -> Dict:
        """
        Extract project context using AI analysis
        """
        # Handle None or empty messages
        if current_message is None:
            current_message = ""
            
        context = {
            'project_type': None,
            'data_size': None,
            'data_type': None,
            'class_count': None,
            'use_case': None,
            'constraints': [],
            'mentioned_algorithms': [],
            'conversation_stage': 'information_gathering'
        }
        
        # Combine all conversation content
        full_conversation = ""
        if conversation_history:
            for msg in conversation_history[-10:]:  # Last 10 messages
                if isinstance(msg, dict):
                    role = msg.get('role', '')
                    content = msg.get('content', '')
                    full_conversation += f"{role}: {content}\n"
        
        full_conversation += f"user: {current_message}"
        
        # Enhanced pattern matching with AI-like context understanding
        text_lower = full_conversation.lower()
        
        # Project type detection (more sophisticated)
        if any(word in text_lower for word in ['sÄ±nÄ±flandÄ±rma', 'classification', 'kategorilere ayÄ±r', 'sÄ±nÄ±flama', 'tahmin et', 'predict class']):
            context['project_type'] = 'classification'
        elif any(word in text_lower for word in ['kÃ¼meleme', 'clustering', 'segmentasyon', 'gruplama', 'segment']):
            context['project_type'] = 'clustering'
        elif any(word in text_lower for word in ['regresyon', 'regression', 'deÄŸer tahmin', 'fiyat tahmin', 'forecast']):
            context['project_type'] = 'regression'
        elif any(word in text_lower for word in ['anomali', 'outlier', 'anormal', 'dolandÄ±rÄ±cÄ±lÄ±k', 'fraud']):
            context['project_type'] = 'anomaly_detection'
        elif any(word in text_lower for word in ['Ã¶neri', 'recommendation', 'tavsiye', 'suggest']):
            context['project_type'] = 'recommendation'
        
        # Data type detection (more intelligent defaults)
        if any(word in text_lower for word in ['sayÄ±sal', 'numerical', 'numeric', 'number', 'regresyon', 'regression']):
            context['data_type'] = 'numerical'
        elif any(word in text_lower for word in ['kategorik', 'categorical', 'category']):
            context['data_type'] = 'categorical'
        elif any(word in text_lower for word in ['metin', 'text', 'kelime', 'word']):
            context['data_type'] = 'text'
        elif any(word in text_lower for word in ['gÃ¶rÃ¼ntÃ¼', 'image', 'resim', 'photo']):
            context['data_type'] = 'image'
        elif context.get('project_type'):
            # Default to numerical if project type is known but data type isn't specified
            context['data_type'] = 'numerical'
            
        # Data size defaults (more intelligent guessing)
        import re
        numbers = re.findall(r'\d+', text_lower)
        size_detected = False
        for num in numbers:
            num_val = int(num)
            if num_val < 1000:
                context['data_size'] = 'small'
                size_detected = True
                break
            elif num_val < 10000:
                context['data_size'] = 'medium'
                size_detected = True
                break
            else:
                context['data_size'] = 'large'
                size_detected = True
                break
        
        # Default data size if not detected but project type is known        
        if not size_detected and context.get('project_type'):
            context['data_size'] = 'medium'  # Safe default
                
        # Class count for classification
        if context['project_type'] == 'classification':
            if any(word in text_lower for word in ['2 sÄ±nÄ±f', 'binary', 'ikili', 'two class']):
                context['class_count'] = 'binary'
            elif any(word in text_lower for word in ['3', '4', '5', 'few', 'az sÄ±nÄ±f']):
                context['class_count'] = 'multiclass'
            elif any(word in text_lower for word in ['Ã§ok sÄ±nÄ±f', 'many class', 'multiple']):
                context['class_count'] = 'multilabel'
            else:
                # Default to multiclass if classification is detected but no specific count given
                context['class_count'] = 'multiclass'
        
        # Extract mentioned algorithms
        algorithms = ['xgboost', 'random forest', 'svm', 'neural network', 'logistic regression', 'naive bayes', 'knn', 'decision tree']
        for algo in algorithms:
            if algo in text_lower:
                context['mentioned_algorithms'].append(algo)
        
        return context
    
    def _is_algorithm_specific_question(self, user_message: str, context: Dict) -> bool:
        """
        Check if user is asking specific questions about algorithms
        """
        user_msg_lower = user_message.lower()
        
        # Specific algorithm names that should always be handled regardless of context
        specific_algorithms = [
            'xgboost', 'random forest', 'svm', 'neural network', 'logistic regression',
            'holt-winters', 'linear regression', 'decision tree', 'naive bayes',
            'k-means', 'dbscan', 'pca', 'lstm', 'cnn', 'bert', 'transformer'
        ]
        
        # Algorithm-specific keywords that should bypass consultation
        algorithm_keywords = [
            'nasÄ±l uygulanÄ±r', 'karÅŸÄ±laÅŸtÄ±r', 'kod Ã¶rneÄŸi', 'performans', 
            'implementasyon', 'hangi algoritma', 'detay', 'aÃ§Ä±kla',
            'Ã¶rnek gÃ¶ster', 'nasÄ±l yapÄ±lÄ±r', 'kÄ±yasla', 'comparison', 'compare',
            'nasÄ±l Ã§alÄ±ÅŸÄ±r', 'avantaj', 'dezavantaj', 'ne zaman kullan',
            'performans karÅŸÄ±laÅŸtÄ±r', 'algoritma karÅŸÄ±laÅŸtÄ±r', 'hangisi daha iyi'
        ]
        
        # Check for specific algorithm names (these are handled regardless of context)
        contains_specific_algo = any(algo in user_msg_lower for algo in specific_algorithms)
        
        # Check for algorithm-specific keywords
        contains_algo_keyword = any(keyword in user_msg_lower for keyword in algorithm_keywords)
        
        # If user mentions specific algorithm, handle immediately
        if contains_specific_algo:
            return True
            
        # For general algorithm questions, we're more flexible now
        # Performance comparison and code examples should always be handled
        if contains_algo_keyword:
            # These specific types should always be handled
            if any(word in user_msg_lower for word in ['performans', 'karÅŸÄ±laÅŸtÄ±r', 'kod Ã¶rneÄŸi', 'nasÄ±l uygulanÄ±r']):
                return True
            # For other algorithm keywords, require some context
            has_minimum_info = context.get('project_type') is not None
            return has_minimum_info
        
        return False
    
    def _handle_algorithm_question(self, user_message: str, context: Dict) -> Dict:
        """
        Handle specific algorithm questions without restarting consultation
        """
        user_msg_lower = user_message.lower()
        
        # Code example requests
        if 'kod Ã¶rneÄŸi' in user_msg_lower or 'nasÄ±l uygulanÄ±r' in user_msg_lower:
            return self._generate_code_example(user_message, context)
        
        # Performance comparison requests
        elif 'performans' in user_msg_lower or 'karÅŸÄ±laÅŸtÄ±r' in user_msg_lower:
            return self._generate_performance_comparison(context)
        
        # Algorithm explanation requests - expanded keywords
        elif any(word in user_msg_lower for word in ['detay', 'aÃ§Ä±kla', 'nedir', 'nasÄ±l Ã§alÄ±ÅŸÄ±r', 'ne yapar', 'avantaj', 'dezavantaj', 'ne zaman kullan', 'bilgi', 'hakkÄ±nda', 'anlat', 'Ã¶ÄŸren']):
            return self._generate_algorithm_explanation(user_message, context)
        
        # Default: ask for clarification
        else:
            return {
                "response": "ğŸ¤” Hangi algoritma hakkÄ±nda bilgi almak istiyorsunuz?\n\nPopÃ¼ler seÃ§enekler:\nâ€¢ K-means\nâ€¢ Random Forest\nâ€¢ XGBoost\nâ€¢ SVM\nâ€¢ Neural Networks\n\nHangisi hakkÄ±nda detay istiyorsunuz?",
                "suggestions": [
                    "K-means hakkÄ±nda bilgi ver",
                    "Random Forest nasÄ±l Ã§alÄ±ÅŸÄ±r?",
                    "XGBoost algoritmasÄ± nedir?",
                    "SVM aÃ§Ä±kla"
                ],
                "success": True
            }
    
    def _generate_code_example(self, user_message: str, context: Dict) -> Dict:
        """
        Generate code examples using GPT-4 or enhanced fallback system
        """
        # Try GPT-4 first for personalized code examples
        if self.openai_enabled and self.openai_client:
            try:
                return self._generate_gpt4_code_example(user_message, context)
            except Exception as e:
                print(f"âš ï¸ GPT-4 code generation failed, using template: {e}")
        
        # Fallback to template system
        return self._generate_template_code_example(user_message, context)
    
    def _generate_gpt4_code_example(self, user_message: str, context: Dict) -> Dict:
        """
        Generate personalized code examples using GPT-4
        """
        project_type = context.get('project_type', 'classification')
        data_size = context.get('data_size', 'medium')
        
        # Detect which algorithm user is asking about
        user_msg_lower = user_message.lower()
        algorithm = "genel"
        
        for algo in ['xgboost', 'random forest', 'svm', 'neural network', 'logistic regression', 'holt-winters', 'linear regression']:
            if algo in user_msg_lower:
                algorithm = algo
                break
        
        context_info = f"""
Proje tÃ¼rÃ¼: {project_type}
Veri boyutu: {data_size}
Veri tÃ¼rÃ¼: {context.get('data_type', 'numerical')}
Ä°stenilen algoritma: {algorithm}
KullanÄ±cÄ± sorusu: "{user_message}"
"""
        
        prompt = f"""
Sen senior-level bir makine Ã¶ÄŸrenmesi uzmanÄ± ve Python geliÅŸtiricisisin. KullanÄ±cÄ±ya industry-standard, production-ready kod Ã¶rnekleri sunuyorsun.

{context_info}

LÃ¼tfen profesyonel bir danÄ±ÅŸman gibi:

ğŸ“‹ **Kod Kalitesi:**
- Clean, readable ve well-documented Python kodu yaz
- Best practices ve design patterns kullan
- Error handling ve edge case'leri dahil et
- Type hints ve docstring'ler ekle

ğŸ¯ **Algoritma SeÃ§imi:**
- Projenin gereksinimlerine gÃ¶re en optimal algoritmalarÄ± Ã¶ner
- Hyperparameter tuning stratejileri sun
- Performance optimization ipuÃ§larÄ± ver
- Cross-validation ve model evaluation detaylarÄ± ekle

ğŸ’¡ **AÃ§Ä±klamalar:**
- Teknik detaylarÄ± paragraf halinde aÃ§Ä±kla
- AlgoritmanÄ±n Ã§alÄ±ÅŸma prensiplerini anlat
- Ne zaman hangi algoritmanÄ±n kullanÄ±lacaÄŸÄ±nÄ± belirt
- Production environment iÃ§in deployment ipuÃ§larÄ± ver

ğŸš€ **Professional Touch:**
- Industry best practices dahil et
- Scalability ve maintainability dikkate al
- Memory ve computational efficiency Ã¶nerileri sun
- Real-world kullanÄ±m senaryolarÄ±nÄ± anlat

YanÄ±tÄ±n hem teknik derinlikte hem de kolayca uygulanabilir olsun. Senior developer seviyesinde kod ve aÃ§Ä±klama bekliyorum.
"""
        
        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": f"Bu proje iÃ§in {algorithm} algoritmasÄ±nÄ±n Python implementasyonunu ve aÃ§Ä±klamasÄ±nÄ± verir misin?"}
        ]
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o",  # Use the latest GPT-4 Omni model for best quality
            messages=messages,
            max_tokens=1500,  # Increased for more detailed responses
            temperature=0.2   # Lower temperature for more consistent professional responses
        )
        
        gpt_response = response.choices[0].message.content
        
        suggestions = [
            "Hiperparametre optimizasyonu",
            "Cross-validation ekleme",
            "Feature engineering ipuÃ§larÄ±",
            "BaÅŸka algoritma kodu"
        ]
        
        return {
            "response": gpt_response,
            "suggestions": suggestions,
            "success": True,
            "ai_powered": True
        }
    
    def _generate_template_code_example(self, user_message: str, context: Dict) -> Dict:
        """
        Enhanced template-based code examples with detailed explanations
        """
        project_type = context.get('project_type', 'classification')
        
        if 'xgboost' in user_message.lower() or 'random forest' in user_message.lower():
            algo_name = 'XGBoost' if 'xgboost' in user_message.lower() else 'Random Forest'
            
            if project_type == 'classification':
                code_example = f"""**{algo_name} ile SÄ±nÄ±flandÄ±rma - DetaylÄ± Uygulama:**

Bu algoritma {context.get('data_size', 'orta')} boyuttaki veri setiniz iÃ§in mÃ¼kemmel bir seÃ§im. Hem yÃ¼ksek performans hem de gÃ¼venilirlik sunar.

```python
# Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleme
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt

# Veri yÃ¼kleme ve ilk inceleme
df = pd.read_csv('your_data.csv')
print(f"Veri seti boyutu: {{df.shape}}")
print(f"Eksik deÄŸer sayÄ±sÄ±: {{df.isnull().sum().sum()}}")

# Ã–zellik ve hedef deÄŸiÅŸkenleri ayÄ±rma
X = df.drop('target_column', axis=1)  # Hedef sÃ¼tununuzun adÄ±nÄ± yazÄ±n
y = df['target_column']

# Veriyi eÄŸitim ve test olarak bÃ¶lme
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Random Forest modelini oluÅŸturma ve eÄŸitme
# n_estimators: AÄŸaÃ§ sayÄ±sÄ± (daha fazla = daha iyi performans ama yavaÅŸ)
# max_depth: AÄŸaÃ§larÄ±n maksimum derinliÄŸi (overfitting'i kontrol eder)
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42,
    n_jobs=-1  # TÃ¼m CPU'larÄ± kullan
)

# Modeli eÄŸitme
print("Model eÄŸitiliyor...")
rf_model.fit(X_train, y_train)

# Tahmin yapma
y_pred = rf_model.predict(X_test)
y_pred_proba = rf_model.predict_proba(X_test)

# Performans deÄŸerlendirme
accuracy = accuracy_score(y_test, y_pred)
print(f"DoÄŸruluk oranÄ±: {{accuracy:.3f}}")

# DetaylÄ± performans raporu
print("\\nDetaylÄ± Performans Raporu:")
print(classification_report(y_test, y_pred))

# Cross-validation ile daha gÃ¼venilir performans Ã¶lÃ§Ã¼mÃ¼
cv_scores = cross_val_score(rf_model, X, y, cv=5)
print(f"\\n5-Fold CV Ortalama DoÄŸruluk: {{cv_scores.mean():.3f}} (+/- {{cv_scores.std()*2:.3f}})")

# Ã–zellik Ã¶nemlerini gÃ¶rÃ¼ntÃ¼leme
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\\nEn Ã¶nemli Ã¶zellikler:")
print(feature_importance.head(10))
```

**Ã–nemli Ä°puÃ§larÄ±:**

Veri setinizin boyutuna gÃ¶re parametreleri ayarlayÄ±n. KÃ¼Ã§Ã¼k veri setlerde n_estimators=50-100 yeterli, bÃ¼yÃ¼k veri setlerde 200-500 arasÄ± deneyebilirsiniz. max_depth parametresi overfitting'i kontrol eder - baÅŸlangÄ±Ã§ iÃ§in 10-15 arasÄ±nda deneyin.

Model eÄŸitildikten sonra feature_importance deÄŸerleriyle hangi Ã¶zelliklerin en Ã§ok etkili olduÄŸunu gÃ¶rebilirsiniz. Bu size veri anlama konusunda bÃ¼yÃ¼k insight verir."""
            else:
                code_example = f"""**{algo_name} ile Regresyon - KapsamlÄ± Uygulama:**

SayÄ±sal tahmin problemleriniz iÃ§in {algo_name} mÃ¼kemmel bir seÃ§im. Ã–zellikle {context.get('data_size', 'orta')} boyuttaki veri setlerde Ã§ok baÅŸarÄ±lÄ±.

```python
# Gerekli kÃ¼tÃ¼phaneler
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt

# Veri hazÄ±rlama
df = pd.read_csv('your_regression_data.csv')
X = df.drop('target_column', axis=1)
y = df['target_column']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Model oluÅŸturma - regresyon iÃ§in optimize edilmiÅŸ parametreler
rf_regressor = RandomForestRegressor(
    n_estimators=100,
    max_depth=15,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)

# Model eÄŸitimi
rf_regressor.fit(X_train, y_train)

# Tahminler
y_pred = rf_regressor.predict(X_test)

# Performans metrikleri
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)

print(f"Model PerformansÄ±:")
print(f"RÂ² Score: {{r2:.3f}}")
print(f"RMSE: {{rmse:.3f}}")
print(f"MAE: {{mae:.3f}}")

# Tahmin vs GerÃ§ek deÄŸerler grafiÄŸi
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('GerÃ§ek DeÄŸerler')
plt.ylabel('Tahmin Edilen DeÄŸerler')
plt.title('Tahmin vs GerÃ§ek DeÄŸerler')
plt.show()
```

Bu kod size hem model performansÄ±nÄ± hem de tahminlerin gÃ¶rsel analizini saÄŸlar. RÂ² deÄŸeri 0.8'in Ã¼stÃ¼ndeyse modeliniz Ã§ok baÅŸarÄ±lÄ± demektir."""
        else:
            code_example = f"""**Genel Machine Learning Pipeline - {project_type.title()} iÃ§in:**

Projeniz iÃ§in kapsamlÄ± bir baÅŸlangÄ±Ã§ ÅŸablonu hazÄ±rladÄ±m. Bu kod yapÄ±sÄ±nÄ± temel alarak istediÄŸiniz algoritmalarÄ± deneyebilirsiniz.

```python
# Temel kÃ¼tÃ¼phaneler
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Veri YÃ¼kleme ve Ä°nceleme
print("=== VERÄ° ANALÄ°ZÄ° ===")
df = pd.read_csv('your_data.csv')
print(f"Veri boyutu: {{df.shape}}")
print(f"SÃ¼tunlar: {{list(df.columns)}}")
print(f"\\nVeri tipleri:\\n{{df.dtypes}}")
print(f"\\nEksik deÄŸerler:\\n{{df.isnull().sum()}}")

# 2. Veri Ã–n Ä°ÅŸleme
print("\\n=== VERÄ° Ã–N Ä°ÅLEME ===")

# Kategorik deÄŸiÅŸkenleri encode etme
categorical_columns = df.select_dtypes(include=['object']).columns
for col in categorical_columns:
    if col != 'target_column':  # Hedef deÄŸiÅŸken deÄŸilse
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))

# Ã–zellik ve hedef ayÄ±rma
X = df.drop('target_column', axis=1)
y = df['target_column']

# Verileri normalize etme (Ã¶nemli!)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. Model SeÃ§imi ve EÄŸitimi
print("\\n=== MODEL EÄÄ°TÄ°MÄ° ===")
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# Buraya istediÄŸiniz algoritmanÄ±n kodunu ekleyebilirsiniz
# Ã–rnek: RandomForestClassifier, SVM, XGBoost vb.

print("Model baÅŸarÄ±yla eÄŸitildi!")
print("Åimdi istediÄŸiniz algoritma kodunu ekleyebilirsiniz.")
```

Bu temel yapÄ±yÄ± kullanarak istediÄŸiniz algoritmanÄ±n detaylÄ± kodunu sorabilirsiniz. Hangi algoritma ile devam etmek istersiniz?"""
        
        return {
            "response": code_example,
            "suggestions": [
                "XGBoost kodu",
                "SVM implementasyonu",
                "Hiperparametre optimizasyonu",
                "Cross-validation ekleme"
            ],
            "success": True
        }
    
    def _generate_performance_comparison(self, context: Dict) -> Dict:
        """
        Generate performance comparison between algorithms
        """
        project_type = context.get('project_type', 'classification')
        data_size = context.get('data_size', 'medium')
        
        if project_type == 'classification':
            comparison = """SÄ±nÄ±flandÄ±rma AlgoritmalarÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±:

1. Logistic Regression
   - DoÄŸruluk: Orta
   - HÄ±z: Ã‡ok hÄ±zlÄ±
   - AnlaÅŸÄ±labilirlik: Ã‡ok kolay
   - En iyi: KÃ¼Ã§Ã¼k veri setleri

2. Random Forest
   - DoÄŸruluk: Ä°yi
   - HÄ±z: Orta
   - AnlaÅŸÄ±labilirlik: Kolay
   - En iyi: Genel kullanÄ±m

3. XGBoost
   - DoÄŸruluk: Ã‡ok iyi
   - HÄ±z: Orta
   - AnlaÅŸÄ±labilirlik: Zor
   - En iyi: BÃ¼yÃ¼k veri setleri

4. SVM
   - DoÄŸruluk: Ä°yi
   - HÄ±z: YavaÅŸ
   - AnlaÅŸÄ±labilirlik: Zor
   - En iyi: KÃ¼Ã§Ã¼k, karmaÅŸÄ±k veriler

"""
            if data_size == 'small':
                comparison += "KÃ¼Ã§Ã¼k veri setiniz iÃ§in: Logistic Regression veya SVM Ã¶nerilir."
            elif data_size == 'large':
                comparison += "BÃ¼yÃ¼k veri setiniz iÃ§in: XGBoost veya Random Forest Ã¶nerilir."
            else:
                comparison += "Genel kullanÄ±m iÃ§in: Random Forest ile baÅŸlayÄ±n."
        else:
            comparison = """Regresyon AlgoritmalarÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±:

1. Linear Regression
   - DoÄŸruluk: Orta
   - HÄ±z: Ã‡ok hÄ±zlÄ±
   - AnlaÅŸÄ±labilirlik: Ã‡ok kolay

2. Random Forest
   - DoÄŸruluk: Ä°yi
   - HÄ±z: Orta
   - AnlaÅŸÄ±labilirlik: Kolay

3. XGBoost
   - DoÄŸruluk: Ã‡ok iyi
   - HÄ±z: Orta
   - AnlaÅŸÄ±labilirlik: Zor

En iyi seÃ§im veri setinizin boyutuna baÄŸlÄ±dÄ±r."""
        
        return {
            "response": comparison,
            "suggestions": [
                "Hangi metrik kullanmalÄ±yÄ±m?",
                "Cross-validation nasÄ±l yapÄ±lÄ±r?",
                "Hiperparametre optimizasyonu"
            ],
            "success": True
        }
    
    def _generate_algorithm_explanation(self, user_message: str, context: Dict) -> Dict:
        """
        Generate detailed explanation about specific algorithms
        """
        explanations = {
            'xgboost': """
ğŸ† **XGBoost (Extreme Gradient Boosting):**

**Ne yapar?**
ZayÄ±f Ã¶ÄŸrenicileri (karar aÄŸaÃ§larÄ±) sÄ±ralÄ± olarak birleÅŸtirerek gÃ¼Ã§lÃ¼ bir model oluÅŸturur.

**AvantajlarÄ±:**
âœ… Ã‡ok yÃ¼ksek doÄŸruluk
âœ… Eksik verilerle baÅŸa Ã§Ä±kabilir
âœ… Ã–zellik Ã¶nemini gÃ¶sterir
âœ… BÃ¼yÃ¼k veri setlerinde hÄ±zlÄ±

**DezavantajlarÄ±:**
âŒ KarmaÅŸÄ±k hiperparametre ayarÄ±
âŒ Overfitting eÄŸilimi
âŒ YorumlanmasÄ± zor

**Ne zaman kullanmalÄ±?**
â€¢ Maksimum performans istediÄŸinizde
â€¢ YarÄ±ÅŸmalarda (Kaggle'da Ã§ok popÃ¼ler)
â€¢ BÃ¼yÃ¼k ve karmaÅŸÄ±k veri setlerinde
""",
            'random forest': """
ğŸŒ³ **Random Forest:**

**Ne yapar?**
BirÃ§ok karar aÄŸacÄ±nÄ± aynÄ± anda eÄŸitir ve sonuÃ§larÄ±nÄ± birleÅŸtirir.

**AvantajlarÄ±:**
âœ… Overfitting'e direnÃ§li
âœ… DeÄŸiÅŸken Ã¶nemini gÃ¶sterir
âœ… Eksik verilerle Ã§alÄ±ÅŸabilir
âœ… Hem classification hem regression

**DezavantajlarÄ±:**
âŒ BÃ¼yÃ¼k model boyutu
âŒ GerÃ§ek zamanlÄ± tahminlerde yavaÅŸ olabilir

**Ne zaman kullanmalÄ±?**
â€¢ GÃ¼venilir bir baÅŸlangÄ±Ã§ algoritmasÄ± olarak
â€¢ Ã–zellik Ã¶nemini anlamak iÃ§in
â€¢ Hem hÄ±z hem doÄŸruluk istediÄŸinizde
""",
            'k-means': """
ğŸ¯ **K-Means Clustering:**

**Ne yapar?**
Verileri Ã¶nceden belirlenen sayÄ±da (k) gruba bÃ¶ler. Her grup bir merkez etrafÄ±nda toplanÄ±r.

**AvantajlarÄ±:**
âœ… Basit ve hÄ±zlÄ±
âœ… BÃ¼yÃ¼k veri setlerinde etkili
âœ… YorumlanmasÄ± kolay
âœ… Bellek kullanÄ±mÄ± dÃ¼ÅŸÃ¼k

**DezavantajlarÄ±:**
âŒ K sayÄ±sÄ±nÄ± Ã¶nceden belirlemelisiniz
âŒ KÃ¼resel olmayan ÅŸekillerde zayÄ±f
âŒ AykÄ±rÄ± deÄŸerlere hassas
âŒ FarklÄ± boyutlardaki gruplarÄ± ayÄ±rmada zor

**Ne zaman kullanmalÄ±?**
â€¢ MÃ¼ÅŸteri segmentasyonu
â€¢ Veri Ã¶n iÅŸleme iÃ§in
â€¢ GÃ¶rÃ¼ntÃ¼ iÅŸlemede renk azaltma
â€¢ Pazarlama analizi

**Python Ã–rneÄŸi:**
```python
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Model oluÅŸturma
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(data)

# SonuÃ§larÄ± gÃ¶rselleÅŸtirme
plt.scatter(data[:, 0], data[:, 1], c=clusters)
plt.scatter(kmeans.cluster_centers_[:, 0], 
           kmeans.cluster_centers_[:, 1], 
           marker='x', s=200, c='red')
plt.show()
```
""",
            'svm': """
âš¡ **Support Vector Machine (SVM):**

**Ne yapar?**
SÄ±nÄ±flar arasÄ±nda en geniÅŸ marjinli ayÄ±rÄ±cÄ± Ã§izgiyi/dÃ¼zlemi bulur.

**AvantajlarÄ±:**
âœ… YÃ¼ksek boyutlu verilerde etkili
âœ… Bellek kullanÄ±mÄ± verimli
âœ… Ã‡ok Ã§eÅŸitli kernel fonksiyonlarÄ±
âœ… Overfitting'e direnÃ§li

**DezavantajlarÄ±:**
âŒ BÃ¼yÃ¼k veri setlerinde yavaÅŸ
âŒ Hiperparametre ayarÄ± kritik
âŒ OlasÄ±lÄ±k tahmini yapmaz
âŒ Noise'a hassas

**Ne zaman kullanmalÄ±?**
â€¢ Metin sÄ±nÄ±flandÄ±rma
â€¢ GÃ¶rÃ¼ntÃ¼ tanÄ±ma
â€¢ YÃ¼ksek boyutlu veriler
â€¢ KÃ¼Ã§Ã¼k-orta boyutlu veri setleri

**Python Ã–rneÄŸi:**
```python
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

# Model oluÅŸturma
svm = SVC(kernel='rbf', random_state=42)

# Hiperparametre optimizasyonu
param_grid = {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}
grid_search = GridSearchCV(svm, param_grid, cv=5)
grid_search.fit(X_train, y_train)

# En iyi model
best_svm = grid_search.best_estimator_
```
""",
            'holt-winters': """
ğŸ“ˆ **Holt-Winters (Triple Exponential Smoothing):**

**Ne yapar?**
Zaman serisi verilerindeki trend, sezonluk ve seviye bileÅŸenlerini ayrÄ± ayrÄ± modelleyerek gelecek tahminleri yapar.

**AvantajlarÄ±:**
âœ… Sezonsal verilerde Ã§ok baÅŸarÄ±lÄ±
âœ… Trend ve mevsimsellik yakalar
âœ… Yorumlanabilir sonuÃ§lar
âœ… Hesaplama aÃ§Ä±sÄ±ndan hÄ±zlÄ±

**DezavantajlarÄ±:**
âŒ Sadece zaman serisi verileri iÃ§in
âŒ Ani deÄŸiÅŸimlere karÅŸÄ± hassas
âŒ Parametrelerin doÄŸru ayarlanmasÄ± gerekli

**Ne zaman kullanmalÄ±?**
â€¢ Mevsimsel satÄ±ÅŸ tahminleri
â€¢ Enerji tÃ¼ketim projeksiyonlarÄ±
â€¢ DÃ¼zenli dÃ¶ngÃ¼sel veriler
â€¢ KÄ±sa-orta vadeli tahminler

**Python Ã–rneÄŸi:**
```python
from statsmodels.tsa.holtwinters import ExponentialSmoothing

# Model oluÅŸturma
model = ExponentialSmoothing(data, trend='add', seasonal='add')
fitted_model = model.fit()

# Tahmin yapma
forecast = fitted_model.forecast(steps=12)
```
"""
        }
        
        user_msg_lower = user_message.lower()
        
        # Check for algorithm mentions with better matching
        for algo, explanation in explanations.items():
            algo_variants = [algo, algo.replace('-', ''), algo.replace(' ', '')]
            if any(variant in user_msg_lower for variant in algo_variants):
                return {
                    "response": explanation,
                    "suggestions": [
                        f"{algo.title()} kod Ã¶rneÄŸi",
                        "Hiperparametre ayarlarÄ±",
                        "DiÄŸer algoritmalarla karÅŸÄ±laÅŸtÄ±r"
                    ],
                    "success": True
                }
        
        # Generic algorithm explanation - check if any algorithm mentioned in message
        mentioned_algorithms = []
        for algo in ['xgboost', 'random forest', 'svm', 'neural network', 'logistic regression', 'k-means', 'kmeans', 'dbscan', 'optics']:
            if algo in user_msg_lower or algo.replace('-', '').replace(' ', '') in user_msg_lower.replace('-', '').replace(' ', ''):
                mentioned_algorithms.append(algo)
        
        if mentioned_algorithms:
            algo = mentioned_algorithms[0]
            return {
                "response": f"ğŸ¤– {algo.title()} hakkÄ±nda bilgi istiyorsunuz. Size bu algoritmanÄ±n detaylarÄ±nÄ± aÃ§Ä±klayabilirim. Hangi konuda daha fazla bilgi istiyorsunuz?",
                "suggestions": [
                    f"{algo.title()} nasÄ±l Ã§alÄ±ÅŸÄ±r?",
                    f"{algo.title()} avantajlarÄ± neler?",
                    f"{algo.title()} kod Ã¶rneÄŸi",
                    "DiÄŸer algoritmalarla karÅŸÄ±laÅŸtÄ±r"
                ],
                "success": True
            }
        else:
            return {
                "response": "ğŸ¤– Hangi algoritma hakkÄ±nda bilgi almak istiyorsunuz? Size detaylarÄ±nÄ± aÃ§Ä±klayabilirim.",
                "suggestions": [
                    "XGBoost nedir?",
                    "Random Forest aÃ§Ä±kla",
                    "SVM nasÄ±l Ã§alÄ±ÅŸÄ±r?",
                    "K-means hakkÄ±nda bilgi ver"
                ],
                "success": True
            }
    
    def _should_recommend_algorithms(self, context: Dict) -> bool:
        """
        Determine if we have enough information to make algorithm recommendations
        """
        required_info = ['project_type', 'data_size', 'data_type']
        
        # For classification, we're more flexible about class_count
        # We can still give recommendations without it
        
        gathered_info = [key for key in required_info if context.get(key) is not None]
        
        print(f"ğŸ“‹ Required: {required_info}")
        print(f"ğŸ“‹ Gathered: {gathered_info}")
        
        # If we have project_type, we can give basic recommendations
        # Even more flexible: just 1 piece of info is enough for basic suggestions
        return len(gathered_info) >= 1
    
    def _generate_algorithm_recommendations(self, user_message: str, context: Dict) -> Dict:
        """
        Generate algorithm recommendations using our custom model + advanced AI explanation
        """
        try:
            # Use our algorithm recommender
            recommendations = self.algorithm_recommender.get_recommendations(
                project_type=context.get('project_type', 'classification'),
                data_size=context.get('data_size', 'medium'),
                data_type=context.get('data_type', 'numerical'),
                complexity_preference='medium'
            )
            
            # Always use our advanced AI system for better explanations
            return self._advanced_ai_recommendations(user_message, context, recommendations)
                
        except Exception as e:
            print(f"âŒ Error in recommendations: {e}")
            return self._get_emergency_fallback()
    
    def _advanced_ai_recommendations(self, user_message: str, context: Dict, recommendations: List[Dict]) -> Dict:
        """
        Hybrid AI system: GPT-4 + Custom Algorithm Model for personalized recommendations
        """
        try:
            if not recommendations:
                return self._get_emergency_fallback()
            
            # Get top 3 recommendations
            top_algos = recommendations[:3]
            
            # Try GPT-4 first for detailed paragraph responses
            if self.openai_enabled and self.openai_client:
                try:
                    return self._generate_gpt4_recommendations(user_message, context, top_algos)
                except Exception as e:
                    print(f"âš ï¸ GPT-4 failed, using advanced fallback: {e}")
            
            # Fallback to enhanced template system
            return self._generate_enhanced_template_recommendations(user_message, context, top_algos)
                
        except Exception as e:
            print(f"âŒ Advanced AI recommendation error: {e}")
            return self._template_recommendations(context, recommendations)
    
    def _generate_gpt4_recommendations(self, user_message: str, context: Dict, recommendations: List[Dict]) -> Dict:
        """
        Generate detailed paragraph recommendations using GPT-4
        """
        try:
            # Prepare algorithm details for GPT-4
            algo_details = []
            for algo in recommendations:
                algo_details.append(f"- {algo['algorithm']}: GÃ¼ven skoru {algo['confidence_score']:.1f}/5.0")
            
            # Create context string
            project_info = f"""
Proje tÃ¼rÃ¼: {context.get('project_type', 'Belirsiz')}
Veri boyutu: {context.get('data_size', 'Belirsiz')}
Veri tÃ¼rÃ¼: {context.get('data_type', 'Belirsiz')}
SÄ±nÄ±f sayÄ±sÄ±: {context.get('class_count', 'Belirsiz')}

Ã–nerilen algoritmalar:
{chr(10).join(algo_details)}

KullanÄ±cÄ± mesajÄ±: "{user_message}"
"""
            
            # GPT-4 prompt
            messages = [
                {"role": "system", "content": self.algorithm_expert_prompt},
                {"role": "user", "content": f"""
YukarÄ±daki proje bilgilerine dayanarak algoritma Ã¶nerilerimi paragraf halinde detaylÄ± aÃ§Ä±kla.

{project_info}

LÃ¼tfen:
1. Her algoritmayÄ± neden Ã¶nerdiÄŸimi paragraf halinde aÃ§Ä±kla
2. Projenin Ã¶zelliklerine gÃ¶re avantajlarÄ± belirt
3. Pratik uygulama ipuÃ§larÄ± ver
4. Hangi algoritma ile baÅŸlanmasÄ±nÄ± Ã¶neriyorsan belirt
5. Samimi ve anlaÅŸÄ±lÄ±r bir dille yaz

KÄ±sa maddeler yerine akÄ±cÄ± paragraflar halinde cevap ver.
"""}
            ]
            
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",  # Use GPT-4 Omni for superior algorithmic advice and detailed explanations
                messages=messages,
                max_tokens=800,
                temperature=0.7
            )
            
            gpt_response = response.choices[0].message.content
            
            # Generate smart suggestions
            suggestions = []
            if recommendations:
                suggestions.append(f"{recommendations[0]['algorithm']} kod Ã¶rneÄŸi")
                suggestions.append("Performans karÅŸÄ±laÅŸtÄ±rmasÄ± yap")
                suggestions.append("Hiperparametre optimizasyonu")
                if len(recommendations) > 1:
                    suggestions.append(f"{recommendations[1]['algorithm']} detaylarÄ±")
            
            return {
                "response": gpt_response,
                "suggestions": suggestions,
                "success": True,
                "ai_powered": True
            }
            
        except Exception as e:
            print(f"âŒ GPT-4 recommendation error: {e}")
            raise e
    
    def _generate_enhanced_template_recommendations(self, user_message: str, context: Dict, recommendations: List[Dict]) -> Dict:
        """
        Enhanced fallback system with paragraph-style responses
        """
        project_type = context.get('project_type') or 'machine learning'
        data_size = context.get('data_size') or 'medium' 
        data_type = context.get('data_type') or 'numerical'
        
        # Create paragraph-style introduction
        if project_type == 'classification':
            intro = f"SÄ±nÄ±flandÄ±rma projeniz iÃ§in detaylÄ± analiz yaptÄ±m ve size en uygun algoritmalarÄ± seÃ§tim. {data_size.title()} boyuttaki {data_type} veriniz iÃ§in Ã¶zellikle etkili olacak Ã§Ã¶zÃ¼mler buldum."
        elif project_type == 'regression':
            intro = f"Regresyon analiziniz iÃ§in algoritma seÃ§iminde dikkat ettiÄŸim temel faktÃ¶rler veri boyutunuz ({data_size}) ve veri tipinizdir ({data_type}). Bu Ã¶zelliklere gÃ¶re en baÅŸarÄ±lÄ± sonuÃ§larÄ± verecek algoritmalarÄ± Ã¶nceledim."
        else:
            intro = f"Projeniz iÃ§in uygun algoritma seÃ§iminde veri karakteristiklerinizi gÃ¶z Ã¶nÃ¼nde bulundurdum. {data_size.title()} boyuttaki {data_type} verileriniz iÃ§in optimize edilmiÅŸ Ã¶nerilerimi paylaÅŸÄ±yorum."
        
        response = intro + "\n\n"
        
        # Detailed algorithm explanations in paragraph form
        for i, algo in enumerate(recommendations[:3], 1):
            algo_name = algo['algorithm']
            confidence = algo['confidence_score']
            
            if i == 1:
                response += f"**{algo_name}** algoritmasÄ±nÄ± ilk sÄ±rada Ã¶neriyorum Ã§Ã¼nkÃ¼ {confidence:.1f}/5.0 gÃ¼ven skoru ile projenize en uygun seÃ§enek. "
            else:
                response += f"**{algo_name}** da {confidence:.1f}/5.0 gÃ¼ven skoru ile gÃ¼Ã§lÃ¼ bir alternatif. "
            
            # Get detailed explanation
            explanation = self._get_enhanced_explanation(algo_name, context)
            response += explanation + "\n\n"
        
        # Contextual advice paragraph
        if data_size == 'small':
            response += "KÃ¼Ã§Ã¼k veri setiniz gÃ¶z Ã¶nÃ¼nde bulundurulduÄŸunda, overfitting riskini minimize etmek iÃ§in daha basit modelleri tercih etmenizi Ã¶neriyorum. BaÅŸlangÄ±Ã§ iÃ§in ilk Ã¶nerdiÄŸim algoritmayÄ± deneyip sonuÃ§larÄ± deÄŸerlendirdikten sonra diÄŸer seÃ§eneklere geÃ§ebilirsiniz."
        elif data_size == 'large':
            response += "BÃ¼yÃ¼k veri setinizin avantajÄ±nÄ± kullanarak daha karmaÅŸÄ±k modelleri gÃ¼venle deneyebilirsiniz. Bu durumda ensemble metotlarÄ± ve derin Ã¶ÄŸrenme yaklaÅŸÄ±mlarÄ± Ã¶zellikle etkili sonuÃ§lar verebilir."
        else:
            response += "Orta boyuttaki veri setiniz iÃ§in dengeli bir yaklaÅŸÄ±m Ã¶neriyorum. Ä°lk etapta daha basit algoritmalarla baÅŸlayÄ±p performans sonuÃ§larÄ±na gÃ¶re karmaÅŸÄ±klÄ±ÄŸÄ± artÄ±rabilirsiniz."
        
        # Generate suggestions
        suggestions = [
            f"{recommendations[0]['algorithm']} nasÄ±l uygulanÄ±r?",
            "Performans karÅŸÄ±laÅŸtÄ±rmasÄ±",
            "Kod Ã¶rnekleri ver",
            "Hangi metriÄŸi kullanmalÄ±yÄ±m?"
        ]
        
        if len(recommendations) > 1:
            suggestions.append(f"{recommendations[1]['algorithm']} detaylarÄ±")
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
    
    def _get_simple_explanation(self, algorithm: str, context: Dict) -> str:
        """
        Get simple, clean explanation for each algorithm
        """
        explanations = {
            'XGBoost': "YÃ¼ksek doÄŸruluk oranÄ±na sahip, gÃ¼Ã§lÃ¼ bir algoritma. Ã‡oÄŸu durumda Ã§ok iyi sonuÃ§lar verir.",
            'Random Forest': "GÃ¼venilir ve dengeli bir seÃ§im. Overfitting yapmaz, sonuÃ§larÄ± yorumlamasÄ± kolay.",
            'Logistic Regression': "Basit ve hÄ±zlÄ±. BaÅŸlangÄ±Ã§ iÃ§in ideal, sonuÃ§larÄ± anlaÅŸÄ±lÄ±r.",
            'SVM': "KarmaÅŸÄ±k veri iliÅŸkilerini iyi yakalar. KÃ¼Ã§Ã¼k veri setlerinde baÅŸarÄ±lÄ±.",
            'Neural Network': "KarmaÅŸÄ±k problemleri Ã§Ã¶zebilir. BÃ¼yÃ¼k veri setleri gerektir.",
            'Linear Regression': "Basit ve hÄ±zlÄ± regresyon algoritmasÄ±. YorumlamasÄ± kolay.",
            'Decision Tree': "AnlaÅŸÄ±lmasÄ± kolay kural tabanlÄ± algoritma.",
            'Naive Bayes': "HÄ±zlÄ± ve basit sÄ±nÄ±flandÄ±rma algoritmasÄ±.",
            'K-Means': "Veri gruplarÄ±nÄ± otomatik olarak bulur.",
            'DBSCAN': "GÃ¼rÃ¼ltÃ¼lÃ¼ verilerde grup bulma algoritmasÄ±.",
        }
        
        return explanations.get(algorithm, "GÃ¼venilir bir makine Ã¶ÄŸrenmesi algoritmasÄ±.")
    
    def _get_algorithm_explanation(self, algorithm: str, context: Dict, confidence: float) -> str:
        """
        Get intelligent, contextual explanation for each algorithm
        """
        explanations = {
            'XGBoost': {
                'classification': "ğŸ† Gradient boosting'in ÅŸampiyonu! KarmaÅŸÄ±k iliÅŸkileri yakalama konusunda uzman. Kaggle yarÄ±ÅŸmalarÄ±nÄ±n favorisi.",
                'regression': "ğŸ“ˆ SayÄ±sal tahminlerde Ã§ok gÃ¼Ã§lÃ¼! Eksik verilerle bile baÅŸarÄ±lÄ± Ã§alÄ±ÅŸÄ±r.",
                'general': "âš¡ HÄ±zlÄ±, gÃ¼Ã§lÃ¼ ve esnek. Ã‡oÄŸu problemde harika sonuÃ§lar verir."
            },
            'Random Forest': {
                'classification': "ğŸŒ³ Karar aÄŸaÃ§larÄ±nÄ±n gÃ¼cÃ¼nÃ¼ birleÅŸtirir. Overfitting'e karÅŸÄ± direnÃ§li ve yorumlanabilir.",
                'regression': "ğŸŒ² Stabil tahminler yapar. Ã–zellik Ã¶nemini gÃ¶sterir.",
                'general': "ğŸ”’ GÃ¼venilir ve robust. Hemen hemen her veri tÃ¼rÃ¼yle Ã§alÄ±ÅŸÄ±r."
            },
            'Logistic Regression': {
                'classification': "ğŸ“Š Basit ama etkili! Ä°kili sÄ±nÄ±flandÄ±rmada mÃ¼kemmel. SonuÃ§larÄ± anlamak kolay.",
                'general': "âœ¨ HÄ±zlÄ± ve yorumlanabilir. BaÅŸlangÄ±Ã§ iÃ§in ideal seÃ§im."
            },
            'SVM': {
                'classification': "ğŸ¯ KarmaÅŸÄ±k veri sÄ±nÄ±rlarÄ±nÄ± Ã§izer. YÃ¼ksek boyutlu verilerde baÅŸarÄ±lÄ±.",
                'general': "ğŸ’ª GÃ¼Ã§lÃ¼ matematik temeli. Kernel trick ile sihir yapar."
            },
            'Neural Network': {
                'classification': "ğŸ§  Beyin yapÄ±sÄ±nÄ± taklit eder. Ã‡ok karmaÅŸÄ±k pattern'leri Ã¶ÄŸrenebilir.",
                'general': "ğŸš€ Derin Ã¶ÄŸrenmenin kapÄ±sÄ±. BÃ¼yÃ¼k verilerle ÅŸaha kalkar."
            }
        }
        
        project_type = context.get('project_type', 'general')
        
        if algorithm in explanations:
            if project_type in explanations[algorithm]:
                base_explanation = explanations[algorithm][project_type]
            else:
                base_explanation = explanations[algorithm]['general']
        else:
            base_explanation = "ğŸ”§ GÃ¼venilir bir algoritma. Projenizde iyi sonuÃ§lar verebilir."
        
        # Add confidence-based comment
        if confidence >= 4.5:
            confidence_note = "âœ… Size Ã¶zel olarak optimize edilmiÅŸ!"
        elif confidence >= 4.0:
            confidence_note = "ğŸ‘ Verilerinizle uyumlu!"
        elif confidence >= 3.5:
            confidence_note = "ğŸ“ Denemeye deÄŸer!"
        else:
            confidence_note = "ğŸ¤” Alternatif seÃ§enek olabilir."
            
        return f"{base_explanation} {confidence_note}"
    
    def _generate_consultation_response(self, user_message: str, context: Dict) -> Dict:
        """
        Generate consultation questions using advanced AI to gather more information
        """
        # Always use our advanced AI system for better user experience
        return self._advanced_ai_consultation_response(user_message, context)
    
    def _advanced_ai_consultation_response(self, user_message: str, context: Dict) -> Dict:
        """
        Hybrid AI consultation: GPT-4 + template fallback for gathering project information
        """
        try:
            # Handle None or empty messages
            if user_message is None:
                user_message = ""
            
            # Try GPT-4 first for personalized consultation
            if self.openai_enabled and self.openai_client:
                try:
                    return self._generate_gpt4_consultation(user_message, context)
                except Exception as e:
                    print(f"âš ï¸ GPT-4 consultation failed, using template: {e}")
            
            # Fallback to enhanced template consultation
            return self._generate_template_consultation(user_message, context)
            
        except Exception as e:
            print(f"âŒ Advanced AI consultation error: {e}")
            return self._template_consultation_response(context)
    
    def _generate_gpt4_consultation(self, user_message: str, context: Dict) -> Dict:
        """
        Generate personalized consultation using GPT-4
        """
        # Determine what information we still need
        missing_info = []
        if not context.get('project_type'):
            missing_info.append('proje tÃ¼rÃ¼')
        if not context.get('data_size'):
            missing_info.append('veri boyutu')
        if not context.get('data_type'):
            missing_info.append('veri tÃ¼rÃ¼')
        if context.get('project_type') == 'classification' and not context.get('class_count'):
            missing_info.append('sÄ±nÄ±f sayÄ±sÄ±')
        
        # Prepare context for GPT-4
        context_info = f"""
Mevcut proje bilgileri:
- Proje tÃ¼rÃ¼: {context.get('project_type', 'HenÃ¼z belirlenmedi')}
- Veri boyutu: {context.get('data_size', 'HenÃ¼z belirlenmedi')}
- Veri tÃ¼rÃ¼: {context.get('data_type', 'HenÃ¼z belirlenmedi')}
- SÄ±nÄ±f sayÄ±sÄ±: {context.get('class_count', 'HenÃ¼z belirlenmedi')}

Eksik bilgiler: {', '.join(missing_info) if missing_info else 'Yok'}

KullanÄ±cÄ± mesajÄ±: "{user_message}"
"""
        
        messages = [
            {"role": "system", "content": self.consultation_prompt},
            {"role": "user", "content": f"""
Bir kullanÄ±cÄ± algoritma danÄ±ÅŸmanlÄ±ÄŸÄ± iÃ§in geldi. AÅŸaÄŸÄ±daki bilgileri gÃ¶z Ã¶nÃ¼nde bulundurarak ona yardÄ±m et:

{context_info}

LÃ¼tfen:
1. KullanÄ±cÄ±nÄ±n mesajÄ±na samimi ve paragraf halinde cevap ver
2. Eksik bilgileri nazikÃ§e sor ama zorlama
3. Projenin hedefini net anlayÄ±p doÄŸru yÃ¶nlendir
4. Teknik terimlerden kaÃ§Ä±n, sade konuÅŸ
5. 2-3 paragraf halinde cevap ver

KÄ±sa listeler yerine akÄ±cÄ± konuÅŸma yap.
"""}
        ]
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o",  # Premium GPT-4 for consultation responses
            messages=messages,
            max_tokens=400,
            temperature=0.8
        )
        
        gpt_response = response.choices[0].message.content
        
        # Generate contextual suggestions
        suggestions = self._generate_consultation_suggestions(missing_info, context)
        
        return {
            "response": gpt_response,
            "suggestions": suggestions,
            "success": True,
            "ai_powered": True
        }
    
    def _generate_template_consultation(self, user_message: str, context: Dict) -> Dict:
        """
        Enhanced template-based consultation with paragraph responses
        """
        # Determine what information we still need
        missing_info = []
        if not context.get('project_type'):
            missing_info.append('project_type')
        if not context.get('data_size'):
            missing_info.append('data_size')
        if not context.get('data_type'):
            missing_info.append('data_type')
        if context.get('project_type') == 'classification' and not context.get('class_count'):
            missing_info.append('class_count')
        
        # Analyze user's message sentiment and content
        user_msg_lower = user_message.lower()
        
        # Generate paragraph-style responses
        if any(word in user_msg_lower for word in ['merhaba', 'selam', 'hello', 'hi']):
            if not context.get('project_type'):
                response = "Merhaba! Size en uygun makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ± bulmaya yardÄ±mcÄ± olmaktan memnuniyet duyarÄ±m. Projenizin detaylarÄ±nÄ± anlayarak size Ã¶zel Ã¶neriler geliÅŸtirebilirim.\n\nHangi tÃ¼r bir problem Ã§Ã¶zmek istediÄŸinizi paylaÅŸabilir misiniz? Bu ÅŸekilde size en uygun algoritmalarÄ± Ã¶nerebilirim."
                suggestions = [
                    "Veri sÄ±nÄ±flandÄ±rmasÄ± yapacaÄŸÄ±m",
                    "SayÄ±sal deÄŸer tahmini yapmak istiyorum", 
                    "Veri kÃ¼melerini gruplamaya ihtiyacÄ±m var"
                ]
            else:
                response = f"Merhaba! {context['project_type']} projesi Ã¼zerinde Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ±zÄ± gÃ¶rÃ¼yorum, bu gerÃ§ekten ilginÃ§ bir alan. Size en uygun algoritmalarÄ± Ã¶nerebilmek iÃ§in birkaÃ§ detay daha Ã¶ÄŸrenmem gerekiyor."
                suggestions = self._generate_consultation_suggestions(missing_info, context)
        
        elif not context.get('project_type'):
            response = "Projenizin amacÄ±nÄ± biraz daha detayÄ±na inmek istiyorum. Makine Ã¶ÄŸrenmesinde farklÄ± problem tÃ¼rleri iÃ§in farklÄ± yaklaÅŸÄ±mlar gerekiyor ve size en uygun Ã§Ã¶zÃ¼mÃ¼ sunabilmek iÃ§in projenizin hedefini anlamam Ã¶nemli.\n\nHangi tÃ¼r bir sonuÃ§ elde etmeyi hedefliyorsunuz?"
            suggestions = [
                "Verileri kategorilere ayÄ±rma (sÄ±nÄ±flandÄ±rma)",
                "SayÄ±sal deÄŸer tahmin etme (regresyon)",
                "Veri gruplarÄ±nÄ± keÅŸfetme (kÃ¼meleme)"
            ]
        
        elif not context.get('data_size'):
            response = f"{context['project_type'].title()} projesi harika bir seÃ§im! Bu alandaki deneyimime dayanarak size Ã§ok etkili algoritmalar Ã¶nerebilirim. Ancak veri setinizin boyutu algoritma seÃ§iminde kritik bir faktÃ¶r.\n\nKaÃ§ tane veri kaydÄ±nÄ±z var? Bu bilgi sayesinde performans ve hÄ±z aÃ§Ä±sÄ±ndan en uygun algoritmalarÄ± seÃ§ebilirim."
            suggestions = [
                "1000'den az kayÄ±t (kÃ¼Ã§Ã¼k veri)",
                "1000-10000 arasÄ± (orta boyut)",
                "10000'den fazla (bÃ¼yÃ¼k veri)"
            ]
        
        elif not context.get('data_type'):
            response = "Veri boyutunu Ã¶ÄŸrendiÄŸim iÃ§in teÅŸekkÃ¼rler! Åimdi veri tÃ¼rÃ¼nÃ¼ anlamam gerekiyor Ã§Ã¼nkÃ¼ farklÄ± veri tÃ¼rleri iÃ§in optimize edilmiÅŸ algoritmalar var. Bu bilgi ile size en uygun ve verimli Ã§Ã¶zÃ¼mÃ¼ Ã¶nerebilirim.\n\nVerileriniz hangi tÃ¼rde? Bu detay algoritma performansÄ±nÄ± doÄŸrudan etkiliyor."
            suggestions = [
                "SayÄ±sal veriler (rakamlar, Ã¶lÃ§Ã¼mler)",
                "Kategorik veriler (gruplar, etiketler)",
                "Metin verileri (yazÄ±lar, yorumlar)",
                "GÃ¶rÃ¼ntÃ¼ verileri (fotoÄŸraflar, resimler)"
            ]
        
        elif context.get('project_type') == 'classification' and not context.get('class_count'):
            response = "SÄ±nÄ±flandÄ±rma projesi iÃ§in son bir Ã¶nemli detay kaldÄ±! KaÃ§ farklÄ± kategori veya sÄ±nÄ±fÄ±nÄ±z olduÄŸu algoritma seÃ§imini etkileyecek. Ä°kili sÄ±nÄ±flandÄ±rma ile Ã§ok sÄ±nÄ±flÄ± problemler farklÄ± yaklaÅŸÄ±mlar gerektiriyor.\n\nVerilerinizi kaÃ§ kategoriye ayÄ±rmayÄ± planlÄ±yorsunuz?"
            suggestions = [
                "2 kategori (ikili sÄ±nÄ±flandÄ±rma)",
                "3-10 kategori arasÄ± (Ã§oklu sÄ±nÄ±f)",
                "10'dan fazla kategori (karmaÅŸÄ±k sÄ±nÄ±flandÄ±rma)"
            ]
        
        else:
            # We have enough info, this shouldn't happen
            response = "Harika! Proje detaylarÄ±nÄ±zÄ± topladÄ±m ve size Ã¶zel algoritma Ã¶nerilerini hazÄ±rlÄ±yorum. Bir an iÃ§inde en uygun seÃ§enekleri sunacaÄŸÄ±m."
            suggestions = ["Algoritma Ã¶nerilerini gÃ¶ster"]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
    
    def _generate_consultation_suggestions(self, missing_info: List[str], context: Dict) -> List[str]:
        """
        Generate contextual suggestions based on missing information and context
        """
        if 'proje tÃ¼rÃ¼' in missing_info or 'project_type' in missing_info:
            return [
                "SÄ±nÄ±flandÄ±rma projesi yapÄ±yorum",
                "Regresyon analizi yapmak istiyorum",
                "Veri kÃ¼meleme yapacaÄŸÄ±m"
            ]
        elif 'veri boyutu' in missing_info or 'data_size' in missing_info:
            return [
                "KÃ¼Ã§Ã¼k veri setim var (1000<)",
                "Orta boyut veri (1000-10000)",
                "BÃ¼yÃ¼k veri setim var (10000+)"
            ]
        elif 'veri tÃ¼rÃ¼' in missing_info or 'data_type' in missing_info:
            return [
                "SayÄ±sal verilerle Ã§alÄ±ÅŸÄ±yorum",
                "Kategorik verilerim var",
                "Metin verileri iÅŸliyorum"
            ]
        else:
            return [
                "Algoritma Ã¶nerilerini ver",
                "Performans karÅŸÄ±laÅŸtÄ±rmasÄ± yap",
                "Hangi metrik kullanmalÄ±yÄ±m?"
            ]
    
    def _ai_consultation_response(self, user_message: str, context: Dict) -> Dict:
        """
        Fallback to advanced AI when OpenAI fails
        """
        return self._advanced_ai_consultation_response(user_message, context)
    
    def _template_consultation_response(self, context: Dict) -> Dict:
        """
        Template-based consultation when AI is not available
        """
        if not context.get('project_type'):
            return {
                "response": "Merhaba! Projeniz iÃ§in en uygun algoritmalarÄ± Ã¶nerebilmek iÃ§in biraz daha bilgiye ihtiyacÄ±m var. Hangi tÃ¼r bir makine Ã¶ÄŸrenmesi problemi Ã§Ã¶zmek istiyorsunuz?",
                "suggestions": [
                    "Veri sÄ±nÄ±flandÄ±rmasÄ± yapacaÄŸÄ±m",
                    "SayÄ±sal deÄŸer tahmini (regresyon)",
                    "Veri kÃ¼meleme iÅŸlemi"
                ],
                "success": True
            }
        elif not context.get('data_size'):
            return {
                "response": f"Harika! {context['project_type']} projesi iÃ§in size yardÄ±mcÄ± olabilirim. Veri setinizin boyutu nasÄ±l?",
                "suggestions": [
                    "1000'den az veri",
                    "1000-10000 arasÄ± veri",
                    "10000+ bÃ¼yÃ¼k veri seti"
                ],
                "success": True
            }
        else:
            return self._get_emergency_fallback()
    
    def _template_recommendations(self, context: Dict, recommendations: List[Dict]) -> Dict:
        """
        Template-based recommendations when AI is not available
        """
        response = f"ğŸ¯ **{context.get('project_type', 'ML').title()} Projesi iÃ§in Ã–nerilerim:**\n\n"
        
        for i, rec in enumerate(recommendations[:3], 1):
            response += f"**{i}. {rec['algorithm']}**\n"
            response += f"   â€¢ GÃ¼ven Skoru: {rec['confidence_score']:.2f}\n"
            response += f"   â€¢ {rec.get('description', 'GÃ¼venilir algoritma')}\n\n"
        
        response += "Bu algoritmalarÄ±n hangisi hakkÄ±nda daha fazla bilgi almak istersiniz?"
        
        suggestions = [rec['algorithm'] for rec in recommendations[:3]]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
    
    def _generate_smart_suggestions(self, context: Dict, recommendations: List[Dict]) -> List[str]:
        """
        Generate contextual suggestions based on recommendations
        """
        suggestions = []
        
        if recommendations:
            suggestions.append(f"{recommendations[0]['algorithm']} hakkÄ±nda detay")
            suggestions.append("Implementasyon Ã¶rneÄŸi")
            suggestions.append("Performans karÅŸÄ±laÅŸtÄ±rmasÄ±")
        
        return suggestions[:3]
    
    def _generate_context_suggestions(self, missing_info: List[str]) -> List[str]:
        """
        Generate suggestions based on missing information
        """
        if 'proje tÃ¼rÃ¼' in str(missing_info):
            return [
                "SÄ±nÄ±flandÄ±rma projesi yapÄ±yorum",
                "Regresyon analizi yapacaÄŸÄ±m",
                "Veri kÃ¼meleme yapacaÄŸÄ±m"
            ]
        elif 'veri boyutu' in str(missing_info):
            return [
                "KÃ¼Ã§Ã¼k veri setim var (1000<)",
                "Orta boyut veri (1000-10000)",
                "BÃ¼yÃ¼k veri setim var (10000+)"
            ]
        else:
            return [
                "Daha fazla detay ver",
                "Ã–rnek gÃ¶ster",
                "BaÅŸka yaklaÅŸÄ±m"
            ]
    
    def _get_enhanced_explanation(self, algorithm: str, context: Dict) -> str:
        """
        Get enhanced paragraph-style explanation for each algorithm
        """
        project_type = context.get('project_type', 'general')
        data_size = context.get('data_size', 'medium')
        
        explanations = {
            'XGBoost': {
                'classification': f"Bu gradient boosting algoritmasÄ±, sÄ±nÄ±flandÄ±rma problemlerinde Ã§ok yÃ¼ksek doÄŸruluk oranlarÄ± saÄŸlar. Ã–zellikle {data_size} boyuttaki veri setlerde mÃ¼kemmel sonuÃ§lar verir Ã§Ã¼nkÃ¼ birÃ§ok zayÄ±f Ã¶ÄŸreniciyi birleÅŸtirerek gÃ¼Ã§lÃ¼ bir model oluÅŸturur. Eksik verilerle bile baÅŸarÄ±lÄ± Ã§alÄ±ÅŸmasÄ± ve Ã¶zellik Ã¶nemini gÃ¶stermesi bÃ¼yÃ¼k avantajlarÄ±.",
                'regression': f"SayÄ±sal tahminlerde Ã¼stÃ¼n performans gÃ¶steren bu algoritma, karmaÅŸÄ±k veri iliÅŸkilerini yakalama konusunda uzman. {data_size.title()} veri setinizde trend analizi ve pattern recognition konularÄ±nda Ã§ok baÅŸarÄ±lÄ± olacak.",
                'general': "Hemen hemen her machine learning probleminde gÃ¼venle kullanabileceÄŸiniz, endÃ¼stri standardÄ± bir algoritma. Kaggle yarÄ±ÅŸmalarÄ±nÄ±n favorisi olmasÄ±nÄ±n sebebi yÃ¼ksek performansÄ± ve esnekliÄŸi."
            },
            'Random Forest': {
                'classification': f"Karar aÄŸaÃ§larÄ±nÄ±n kollektif gÃ¼cÃ¼nÃ¼ kullanarak overfitting problemini Ã§Ã¶zen akÄ±llÄ± bir yaklaÅŸÄ±m. {data_size.title()} veri setinizde hem hÄ±zlÄ± Ã§alÄ±ÅŸacak hem de yorumlanabilir sonuÃ§lar verecek. Ã–zellik Ã¶nemini gÃ¶rmek iÃ§in ideal.",
                'regression': f"Tahmin problemlerinde gÃ¼venilirlik arÄ±yorsanÄ±z mÃ¼kemmel bir seÃ§im. BirÃ§ok karar aÄŸacÄ±nÄ±n oybirliÄŸi ile tahmin yaptÄ±ÄŸÄ± iÃ§in tek bir aÄŸaca gÃ¶re Ã§ok daha stabil sonuÃ§lar verir.",
                'general': "BaÅŸlangÄ±Ã§ iÃ§in ideal Ã§Ã¼nkÃ¼ hiperparametre ayarlamaya Ã§ok ihtiyaÃ§ duymaz ve neredeyse her durumda makul sonuÃ§lar verir. GÃ¼venilir bir algoritma."
            },
            'Logistic Regression': {
                'classification': f"BasitliÄŸi ve etkinliÄŸi ile Ã¶ne Ã§Ä±kan bu algoritma, {data_size} veri setlerde hÄ±zlÄ± sonuÃ§lar verir. Ä°kili sÄ±nÄ±flandÄ±rmada Ã¶zellikle baÅŸarÄ±lÄ± ve sonuÃ§larÄ± anlamak Ã§ok kolay. DoÄŸrusal iliÅŸkileri Ã§ok iyi yakalar.",
                'general': "Machine learning'e yeni baÅŸlayanlar iÃ§in mÃ¼kemmel bir baÅŸlangÄ±Ã§ noktasÄ±. Hem hÄ±zlÄ± hem de yorumlanabilir sonuÃ§lar verir."
            },
            'SVM': {
                'classification': f"KarmaÅŸÄ±k sÄ±nÄ±r Ã§izgilerini Ã§izme konusunda uzman bu algoritma, Ã¶zellikle doÄŸrusal olmayan iliÅŸkilerin olduÄŸu durumlarda Ã§ok baÅŸarÄ±lÄ±. {data_size} veri setlerde kernel trick sayesinde yÃ¼ksek boyutlu problemleri Ã§Ã¶zebilir.",
                'general': "GÃ¼Ã§lÃ¼ matematik temeli olan, teorik olarak saÄŸlam bir algoritma. Ã–zellikle yÃ¼ksek boyutlu verilerde etkili."
            },
            'Neural Network': {
                'classification': f"Ä°nsan beyninden ilham alan bu algoritma, Ã§ok karmaÅŸÄ±k pattern'leri Ã¶ÄŸrenebilir. {data_size} veri setiniz bÃ¼yÃ¼kse harika sonuÃ§lar verecek, ancak parametre ayarlamasÄ± biraz sabÄ±r gerektirir.",
                'general': "Derin Ã¶ÄŸrenmenin kapÄ±sÄ±nÄ± aÃ§an temel algoritma. KarmaÅŸÄ±k problemlerde Ã§ok gÃ¼Ã§lÃ¼ ama yeterli veri gerektir."
            }
        }
        
        if algorithm in explanations:
            if project_type in explanations[algorithm]:
                return explanations[algorithm][project_type]
            else:
                return explanations[algorithm]['general']
        else:
            return f"Bu algoritma {project_type} problemlerde gÃ¼venilir sonuÃ§lar verir ve veri setinizin karakteristikleriyle uyumlu Ã§alÄ±ÅŸacaktÄ±r."
    
    def _get_emergency_fallback(self) -> Dict:
        """
        Emergency response when everything fails - should be used sparingly
        """
        # Generate diverse fallback responses
        fallback_responses = [
            "Hmm, bu sorunuzu tam anlayamadÄ±m. Makine Ã¶ÄŸrenmesi projeniz hakkÄ±nda daha detaylÄ± bilgi verebilir misiniz? Hangi tÃ¼r bir analiz yapmak istiyorsunuz?",
            
            "Biraz daha aÃ§Ä±klayabilir misiniz? Projenizin hedefini anlamak iÃ§in daha fazla bilgiye ihtiyacÄ±m var. Ne tÃ¼r verilerle Ã§alÄ±ÅŸÄ±yorsunuz?",
            
            "Sorunuzu daha iyi anlayabilmek iÃ§in biraz daha detay verebilir misiniz? Hangi alanda Ã§alÄ±ÅŸÄ±yorsunuz ve ne yapmaya Ã§alÄ±ÅŸÄ±yorsunuz?",
            
            "Bu konuda size daha iyi yardÄ±m edebilmek iÃ§in projenizin detaylarÄ±nÄ± Ã¶ÄŸrenmek istiyorum. Hangi tÃ¼r bir makine Ã¶ÄŸrenmesi problemi Ã§Ã¶zmeye Ã§alÄ±ÅŸÄ±yorsunuz?"
        ]
        
        return {
            "response": random.choice(fallback_responses),
            "suggestions": [
                "Veri sÄ±nÄ±flandÄ±rmasÄ± yapacaÄŸÄ±m",
                "Tahmin modeli geliÅŸtiriyorum",
                "Veri analizi yapmak istiyorum",
                "Hangi algoritma kullanmalÄ±yÄ±m?"
            ],
            "success": True
        } 