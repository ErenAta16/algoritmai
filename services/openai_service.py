import os
from openai import OpenAI
from typing import Dict, List, Optional
from services.algorithm_recommender import AlgorithmRecommender
from dotenv import load_dotenv
import random
import time
import json
from functools import lru_cache
import logging
import asyncio
import aiohttp
from concurrent.futures import ThreadPoolExecutor

# Load environment variables from .env file
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OpenAIService:
    def __init__(self):
        """
        Advanced Hybrid AI-powered algorithm consultant with intelligent fallback - ASYNC OPTIMIZED
        """
        self.algorithm_recommender = AlgorithmRecommender()
        self.request_count = 0
        self.last_request_time = 0
        self.rate_limit_delay = 1.0  # 1 second between requests
        
        # Thread pool for CPU-intensive tasks
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # Initialize OpenAI with modern client - SECURITY ENHANCED
        api_key = os.getenv('OPENAI_API_KEY')
        
        # Validate API key format
        if api_key and api_key != 'your_openai_api_key_here':
            # Basic API key format validation
            if not api_key.startswith('sk-') or len(api_key) < 20:
                logger.error("‚ùå Invalid OpenAI API key format")
                self.openai_enabled = False
                self.openai_client = None
            else:
                try:
                    self.openai_client = OpenAI(api_key=api_key)
                    # Test the connection
                    self.openai_client.models.list()
                    self.openai_enabled = True
                    # Log without exposing the key
                    logger.info(f"‚úÖ OpenAI API successfully initialized (key: sk-...{api_key[-4:]})")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è OpenAI API issue (quota/connection): {str(e)[:100]}...")
                    self.openai_enabled = False
                    self.openai_client = None
        else:
            self.openai_enabled = False
            self.openai_client = None
            logger.warning("‚ö†Ô∏è OpenAI API key not found, using advanced fallback system")
        
        # Clear the API key from memory after use
        if 'api_key' in locals():
            del api_key
        
        # Always use our advanced AI system regardless of OpenAI status
        self.use_advanced_ai = True
        logger.info("ü§ñ Advanced AI Algorithm Consultant initialized with intelligent conversation engine")
        
        # Enhanced conversation-focused system prompts
        self.algorithm_expert_prompt = """Sen deneyimli, samimi ve yardƒ±msever bir makine √∂ƒürenmesi uzmanƒ±sƒ±n. Adƒ±n "AlgoMentor" ve kullanƒ±cƒ±larla ger√ßek bir arkada≈ü gibi konu≈üuyorsun.

Ki≈üiliƒüin:
- Meraklƒ± ve √∂ƒüretmeyi seven
- Teknik bilgiyi basit √∂rneklerle anlatan
- Sabƒ±rlƒ± ve destekleyici
- Ger√ßek d√ºnya deneyimlerini payla≈üan
- Yaratƒ±cƒ± √ß√∂z√ºmler √∂neren

Konu≈üma tarzƒ±n:
- Doƒüal, akƒ±cƒ± paragraflar halinde konu≈ü
- "≈û√∂yle ki", "Mesela", "Aslƒ±nda" gibi g√ºnl√ºk ifadeler kullan
- Ki≈üisel deneyimlerini payla≈ü ("Benim deneyimime g√∂re...")
- Merak uyandƒ±rƒ±cƒ± sorular sor
- Cesaretlendirici ve pozitif ol

Algoritma bilgilerini ≈üu ≈üekilde sun:
- √ñnce hikayesini anlat (nasƒ±l ortaya √ßƒ±ktƒ±, neden √∂nemli)
- Ger√ßek d√ºnya √∂rnekleri ver
- Avantaj/dezavantajlarƒ± dengeli ≈üekilde a√ßƒ±kla
- Uygulama ipu√ßlarƒ± ve p√ºf noktalarƒ± payla≈ü
- Hangi durumda kullanƒ±lacaƒüƒ±nƒ± net belirt

Her zaman T√ºrk√ße konu≈ü ve dostane, samimi bir ton kullan. Robotik cevaplar verme!"""

        self.consultation_prompt = """Sen "AlgoMentor" adƒ±nda deneyimli bir makine √∂ƒürenmesi danƒ±≈ümanƒ±sƒ±n. Kullanƒ±cƒ±larla ger√ßek bir ment√∂r gibi konu≈üuyorsun.

G√∂revin:
- Kullanƒ±cƒ±nƒ±n projesini samimi bir ≈üekilde dinle ve anla
- Meraklƒ± sorular sor ama sorgulama gibi yapma
- Hikayeler ve √∂rneklerle a√ßƒ±kla
- Ki≈üisel deneyimlerini payla≈ü
- Cesaretlendirici ve destekleyici ol
- Yaratƒ±cƒ± √ß√∂z√ºmler √∂ner

Konu≈üma yakla≈üƒ±mƒ±n:
- "Vay, bu √ßok ilgin√ß bir proje!" gibi doƒüal tepkiler ver
- "Benim de benzer bir projede √ßalƒ±≈ümƒ±≈ütƒ±m..." diye deneyim payla≈ü
- "≈û√∂yle bir yakla≈üƒ±m deneyebiliriz..." diye √∂neriler sun
- Teknik terimleri g√ºnl√ºk dille a√ßƒ±kla
- Kƒ±sa listeler yerine akƒ±cƒ± paragraflar kullan

Bilgi toplarken:
- Doƒüal soru akƒ±≈üƒ± olu≈ütur
- Kullanƒ±cƒ±nƒ±n motivasyonunu anla
- Proje hedeflerini ke≈üfet
- Kƒ±sƒ±tlamalarƒ± √∂ƒüren
- Deneyim seviyesini kavra

Her zaman samimi, yardƒ±msever ve konu≈ükan ol!"""

        # Conversation memory for context
        self.conversation_memory = []
        self.user_profile = {
            'experience_level': 'unknown',
            'preferred_style': 'unknown',
            'project_domain': 'unknown',
            'technical_comfort': 'unknown'
        }
        
        # Response diversity tracking
        self.response_cache = {}
        self.response_variations = {}
        self.conversation_turn = 0
        
        # Recommendation memory and context tracking
        self.recommendation_history = []
        self.user_preferences = {}
        self.conversation_context = {
            'last_recommendations': [],
            'user_selections': [],
            'discussed_algorithms': [],
            'user_feedback': []
        }

    async def get_chat_response_async(self, user_message: str, conversation_history: Optional[List[Dict]] = None) -> Dict:
        """
        Async version of get_chat_response for better performance
        """
        loop = asyncio.get_event_loop()
        
        # Run CPU-intensive operations in thread pool
        result = await loop.run_in_executor(
            self.executor,
            self.get_chat_response,
            user_message,
            conversation_history
        )
        
        return result

    def get_chat_response(self, user_message: str, conversation_history: Optional[List[Dict]] = None) -> Dict:
        """
        Enhanced conversational AI response with natural dialogue flow and response diversity - PERFORMANCE OPTIMIZED
        """
        try:
            # Handle None or empty messages
            if user_message is None:
                user_message = ""
            
            print(f"\nüîç Processing: '{user_message}'")
            
            # Increment conversation turn for diversity tracking
            self.conversation_turn += 1
            
            # Update conversation memory
            self._update_conversation_memory(user_message, conversation_history)
            
            # Analyze user profile and adapt response style
            self._analyze_user_profile(user_message)
            
            # Extract project context with conversation awareness
            project_context = self._extract_enhanced_project_context(user_message, conversation_history)
            project_context['conversation_turn'] = self.conversation_turn
            project_context['conversation_length'] = len(self.conversation_memory)
            
            # Add conversation context for memory awareness
            project_context['conversation_context'] = self.conversation_context
            project_context['conversation_memory'] = self.conversation_memory
            
            print(f"üìä Enhanced Context: {project_context}")
            print(f"üß† Memory: {len(self.conversation_memory)} messages, {len(self.conversation_context['discussed_algorithms'])} algorithms discussed")
            
            # Determine response type based on conversation flow
            response_type = self._determine_response_type(user_message, project_context)
            print(f"üéØ Response Type: {response_type}")
            
            # Generate contextual response with diversity check
            response = self._generate_diverse_response(user_message, project_context, response_type)
            
            # Store response for diversity tracking
            self._store_response_for_diversity(user_message, response['response'])
            
            # Store recommendations if present
            if 'recommendations' in response:
                self.conversation_context['last_recommendations'] = response['recommendations']
            
            return response
            
        except Exception as e:
            logger.error(f"‚ùå Error in get_chat_response: {str(e)}")
            return self._get_emergency_fallback()

    def _rate_limit_check(self):
        """Rate limiting implementation"""
        current_time = time.time()
        if current_time - self.last_request_time < self.rate_limit_delay:
            time.sleep(self.rate_limit_delay - (current_time - self.last_request_time))
        self.last_request_time = time.time()
        self.request_count += 1

    @lru_cache(maxsize=100)
    def _cached_gpt_request(self, prompt_hash: str, content: str) -> str:
        """Cache GPT responses to avoid repeated API calls"""
        try:
            self._rate_limit_check()
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": self.algorithm_expert_prompt},
                    {"role": "user", "content": content}
                ],
                max_tokens=1000,
                temperature=0.3,
                timeout=30
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"GPT request failed: {e}")
            raise e
    
    def _generate_diverse_response(self, user_message: str, project_context: Dict, response_type: str) -> Dict:
        """Generate diverse responses based on conversation history"""
        # Check if we've seen similar messages before
        similar_responses = self._find_similar_responses(user_message)
        
        # Add diversity instruction to context
        if similar_responses:
            project_context['diversity_instruction'] = f"Bu soruya daha √∂nce benzer cevap verdin. ≈ûimdi farklƒ± bir yakla≈üƒ±m, farklƒ± √∂rnekler ve farklƒ± ifadeler kullan. √ñnceki cevaplarƒ±nƒ± tekrar etme."
            project_context['previous_responses'] = similar_responses[:3]  # Last 3 similar responses
        
        # Generate response based on type
        if response_type == 'algorithm_selection':
            return self._handle_algorithm_selection(user_message, project_context)
        elif response_type == 'recommendation_response':
            return self._handle_recommendation_response(user_message, project_context)
        elif response_type == 'algorithm_question':
                return self._handle_algorithm_question(user_message, project_context)
        elif response_type == 'code_request':
            return self._generate_code_example(user_message, project_context)
        elif response_type == 'comparison_request':
            return self._generate_performance_comparison(project_context)
        elif response_type == 'recommendation_ready':
            return self._generate_enhanced_recommendations(user_message, project_context)
        else:
            return self._generate_natural_consultation(user_message, project_context)
    
    def _find_similar_responses(self, user_message: str) -> List[str]:
        """Find similar previous responses to avoid repetition"""
        similar_responses = []
        user_words = set(user_message.lower().split())
        
        for cached_message, cached_response in self.response_cache.items():
            cached_words = set(cached_message.lower().split())
            
            # Calculate similarity
            if user_words and cached_words:
                intersection = user_words.intersection(cached_words)
                similarity = len(intersection) / len(user_words.union(cached_words))
                
                if similarity > 0.5:  # 50% similarity threshold
                    similar_responses.append(cached_response)
        
        return similar_responses
    
    def _store_response_for_diversity(self, user_message: str, response: str):
        """Store response for future diversity checking"""
        # Keep only last 20 responses to prevent memory bloat
        if len(self.response_cache) >= 20:
            # Remove oldest entry
            oldest_key = next(iter(self.response_cache))
            del self.response_cache[oldest_key]
        
        self.response_cache[user_message] = response
    
    def _track_algorithm_mentions(self, user_message: str):
        """Track mentioned algorithms in conversation"""
        text_lower = user_message.lower()
        
        # Algorithm names to track - expanded list
        algorithms = {
            'xgboost': ['xgboost', 'xgb'],
            'random forest': ['random forest', 'rf'],
            'svm': ['svm', 'support vector'],
            'neural network': ['neural network', 'nn', 'deep learning', 'mlp'],
            'logistic regression': ['logistic regression', 'logistic'],
            'naive bayes': ['naive bayes', 'nb'],
            'knn': ['knn', 'k-nearest'],
            'decision tree': ['decision tree', 'dt'],
            'linear regression': ['linear regression'],
            'k-means': ['kmeans', 'k-means'],
            'dbscan': ['dbscan'],
            'optics': ['optics'],
            'mean shift': ['mean shift'],
            'ensemble': ['ensemble'],
            'gradient boosting': ['gradient boosting', 'gbm'],
            'ada boost': ['ada boost', 'adaboost'],
            'lightgbm': ['lightgbm', 'lgb', 'ts features'],
            'prophet': ['prophet', 'facebook'],
            'catboost': ['catboost']
        }
        
        for algo_name, keywords in algorithms.items():
            if any(keyword in text_lower for keyword in keywords):
                if algo_name not in self.conversation_context['discussed_algorithms']:
                    self.conversation_context['discussed_algorithms'].append(algo_name)
                
                # Track user selection/preference
                if any(word in text_lower for word in ['se√ßmek', 'istiyorum', 'tercih', 'daha iyi', 'kullanmak']):
                    self.conversation_context['user_selections'].append({
                        'algorithm': algo_name,
                        'message': user_message,
                        'timestamp': time.time()
                    })
    
    def _track_user_preferences(self, user_message: str):
        """Track user feedback and preferences"""
        text_lower = user_message.lower()
        
        # Positive feedback
        if any(word in text_lower for word in ['iyi', 'g√ºzel', 'm√ºkemmel', 'harika', 'beƒüendim', 'evet']):
            self.conversation_context['user_feedback'].append({
                'type': 'positive',
                'message': user_message,
                'timestamp': time.time()
            })
        
        # Negative feedback
        elif any(word in text_lower for word in ['hayƒ±r', 'k√∂t√º', 'beƒüenmedim', 'istemiyorum', 'farklƒ±']):
            self.conversation_context['user_feedback'].append({
                'type': 'negative',
                'message': user_message,
                'timestamp': time.time()
            })
        
        # Questions about algorithms
        elif any(word in text_lower for word in ['neden', 'avantaj', 'dezavantaj', 'niye', 'hangisi']):
            self.conversation_context['user_feedback'].append({
                'type': 'question',
                'message': user_message,
                'timestamp': time.time()
            })
    
    def _update_conversation_memory(self, user_message: str, conversation_history: Optional[List[Dict]] = None):
        """Update conversation memory for better context awareness - MEMORY LEAK FIXED"""
        MAX_MEMORY_SIZE = 20  # Maximum number of messages to keep
        MAX_MEMORY_AGE = 3600  # Maximum age in seconds (1 hour)
        
        current_time = time.time()
        
        # Clean old messages from memory
        self.conversation_memory = [
            msg for msg in self.conversation_memory 
            if current_time - msg.get('timestamp', 0) < MAX_MEMORY_AGE
        ]
        
        if conversation_history:
            # Keep only last 10 messages from history
            recent_history = conversation_history[-10:]
            self.conversation_memory = recent_history
        
        # Add current message
        self.conversation_memory.append({
            'role': 'user',
            'content': user_message,
            'timestamp': current_time
        })
        
        # Keep only the most recent messages
        if len(self.conversation_memory) > MAX_MEMORY_SIZE:
            self.conversation_memory = self.conversation_memory[-MAX_MEMORY_SIZE:]
        
        # Clean response cache periodically
        if len(self.response_cache) > 100:
            # Keep only the most recent 50 responses
            cache_items = list(self.response_cache.items())
            self.response_cache = dict(cache_items[-50:])
        
        # Track algorithm mentions and user preferences
        self._track_algorithm_mentions(user_message)
        self._track_user_preferences(user_message)
        
        # Clean old conversation context
        self._clean_conversation_context()
    
    def _clean_conversation_context(self):
        """Clean old data from conversation context to prevent memory leaks"""
        current_time = time.time()
        MAX_FEEDBACK_AGE = 1800  # 30 minutes
        
        # Clean old feedback
        self.conversation_context['user_feedback'] = [
            feedback for feedback in self.conversation_context['user_feedback']
            if current_time - feedback.get('timestamp', 0) < MAX_FEEDBACK_AGE
        ]
        
        # Keep only last 10 user selections
        if len(self.conversation_context['user_selections']) > 10:
            self.conversation_context['user_selections'] = self.conversation_context['user_selections'][-10:]
        
        # Keep only last 20 discussed algorithms
        if len(self.conversation_context['discussed_algorithms']) > 20:
            self.conversation_context['discussed_algorithms'] = self.conversation_context['discussed_algorithms'][-20:]

    def _analyze_user_profile(self, user_message: str):
        """Analyze user's communication style and technical level"""
        text_lower = user_message.lower()
        
        # Detect experience level
        if any(word in text_lower for word in ['yeni ba≈ülƒ±yorum', 'ba≈ülangƒ±√ß', 'bilmiyorum', '√∂ƒüreniyorum']):
            self.user_profile['experience_level'] = 'beginner'
        elif any(word in text_lower for word in ['deneyimli', 'uzman', 'profesyonel', '√ßalƒ±≈üƒ±yorum']):
            self.user_profile['experience_level'] = 'advanced'
        elif any(word in text_lower for word in ['orta', 'biraz', 'temel']):
            self.user_profile['experience_level'] = 'intermediate'
        
        # Detect communication style preference
        if any(word in text_lower for word in ['detaylƒ±', 'a√ßƒ±kla', 'nasƒ±l', 'neden']):
            self.user_profile['preferred_style'] = 'detailed'
        elif any(word in text_lower for word in ['hƒ±zlƒ±', 'kƒ±sa', '√∂zet', 'direkt']):
            self.user_profile['preferred_style'] = 'concise'

    def _determine_response_type(self, user_message: str, context: Dict) -> str:
        """Determine the most appropriate response type"""
        text_lower = user_message.lower()
        
        # Check if user is responding to previous recommendations
        if self._is_responding_to_recommendations(user_message):
            return 'recommendation_response'
        
        # Algorithm selection/preference - expanded algorithm list
        if any(word in text_lower for word in ['se√ßmek', 'istiyorum', 'tercih', 'daha iyi olur', 'kullanmak']):
            algorithms_to_check = [
                'xgboost', 'random forest', 'svm', 'neural', 'logistic',
                'k-means', 'kmeans', 'dbscan', 'optics', 'mean shift',
                'naive bayes', 'decision tree', 'knn', 'linear regression',
                'ensemble', 'gradient boosting', 'ada boost'
            ]
            if any(algo in text_lower for algo in algorithms_to_check):
                return 'algorithm_selection'
        
        # Check if user is asking about previously discussed algorithms
        if self.conversation_context['discussed_algorithms']:
            for algo in self.conversation_context['discussed_algorithms']:
                if algo in text_lower:
                    if any(word in text_lower for word in ['neden', 'avantaj', 'dezavantaj', 'nasƒ±l']):
                        return 'algorithm_question'
        
        # Algorithm-specific questions - check if any algorithm mentioned
        algorithms_to_check = [
            'xgboost', 'random forest', 'svm', 'neural', 'logistic',
            'k-means', 'kmeans', 'dbscan', 'optics', 'mean shift',
            'naive bayes', 'decision tree', 'knn', 'linear regression',
            'ensemble', 'gradient boosting', 'ada boost', 'algoritma'
        ]
        
        if any(algo in text_lower for algo in algorithms_to_check):
            if any(word in text_lower for word in ['nasƒ±l √ßalƒ±≈üƒ±r', 'nedir', 'a√ßƒ±kla', 'anlat', 'avantaj', 'dezavantaj', 'bilgi', 'hakkƒ±nda']):
                return 'algorithm_question'
        
        # Code requests
        if any(word in text_lower for word in ['kod', '√∂rnek', 'implement', 'uygula', 'python']):
            return 'code_request'
        
        # Alternative/comparison requests
        if any(word in text_lower for word in ['kar≈üƒ±la≈ütƒ±r', 'hangisi', 'fark', 'vs', 'compare', 'ba≈üka', 'alternatif', 'farklƒ±']):
            if any(word in text_lower for word in ['algoritma', '√∂ner', '√∂neri', 'tavsiye']):
                return 'recommendation_response'
        
        # Comparison requests
        if any(word in text_lower for word in ['kar≈üƒ±la≈ütƒ±r', 'hangisi', 'fark', 'vs', 'compare']):
            return 'comparison_request'
        
        # Ready for recommendations
        if self._is_ready_for_recommendations(context):
            return 'recommendation_ready'
        
        # Default to consultation
        return 'consultation'

    def _is_ready_for_recommendations(self, context: Dict) -> bool:
        """Check if we have enough context for recommendations"""
        required_fields = ['project_type', 'data_size', 'data_type']
        return all(context.get(field) for field in required_fields)
    
    def _is_responding_to_recommendations(self, user_message: str) -> bool:
        """Check if user is responding to previous recommendations"""
        text_lower = user_message.lower()
        
        # Special case: Alternative requests should always be handled as recommendation responses
        if any(word in text_lower for word in ['ba≈üka', 'alternatif']) and any(word in text_lower for word in ['algoritma', '√∂ner', '√∂neri', 'tavsiye']):
            return True
        
        # Check if there were recent recommendations
        if not self.conversation_context['last_recommendations']:
            return False
        
        # Response indicators
        response_indicators = [
            'hayƒ±r', 'evet', 'daha iyi', 'tercih', 'se√ßmek', 'istiyorum',
            'farklƒ±', 'ba≈üka', 'alternatif', 'neden', 'avantaj', 'dezavantaj'
        ]
        
        return any(indicator in text_lower for indicator in response_indicators)
    
    def _handle_algorithm_selection(self, user_message: str, context: Dict) -> Dict:
        """Handle when user selects a specific algorithm"""
        text_lower = user_message.lower()
        
        # Find selected algorithm
        selected_algorithm = None
        conversation_context = context.get('conversation_context', {})
        user_selections = conversation_context.get('user_selections', [])
        
        # Check if this algorithm was mentioned before
        for selection in user_selections:
            if selection['algorithm'] in text_lower:
                selected_algorithm = selection['algorithm']
                break
        
        if not selected_algorithm:
            # Try to extract from current message - expanded algorithm list
            algorithms = [
                'xgboost', 'random forest', 'svm', 'neural network', 'logistic regression',
                'k-means', 'kmeans', 'dbscan', 'optics', 'mean shift',
                'naive bayes', 'decision tree', 'knn', 'linear regression',
                'ensemble', 'gradient boosting', 'ada boost'
            ]
            for algo in algorithms:
                if algo.replace(' ', '').replace('-', '') in text_lower.replace(' ', '').replace('-', ''):
                    selected_algorithm = algo
                    break
        
        if selected_algorithm:
            # Direct algorithm choice explanation
            return self._explain_algorithm_choice(selected_algorithm, user_message, context)
        else:
            # If no specific algorithm found, still try to be helpful
            return {
                "response": "ü§ñ Hangi algoritma kullanmak istediƒüinizi tam anlayamadƒ±m. Daha spesifik olabilir misiniz?\n\n√ñrneƒüin:\n‚Ä¢ K-means\n‚Ä¢ Random Forest\n‚Ä¢ XGBoost\n‚Ä¢ SVM\n\nHangisini tercih ediyorsunuz?",
                "suggestions": [
                    "K-means kullanmak istiyorum",
                    "Random Forest tercih ediyorum", 
                    "XGBoost se√ßmek istiyorum",
                    "SVM kullanayƒ±m"
                ],
                "success": True
            }
    
    def _handle_recommendation_response(self, user_message: str, context: Dict) -> Dict:
        """Handle user's response to recommendations"""
        text_lower = user_message.lower()
        
        # Get last recommendations from context
        conversation_context = context.get('conversation_context', {})
        last_recs = conversation_context.get('last_recommendations', [])
        
        # Special handling for alternative requests - even without previous recommendations
        if any(word in text_lower for word in ['ba≈üka', 'alternatif', 'farklƒ±']) and any(word in text_lower for word in ['algoritma', '√∂ner', '√∂neri', 'tavsiye']):
            # User wants alternative recommendations
            return self._provide_alternative_recommendations(user_message, context, last_recs)
        elif 'hayƒ±r' in text_lower or 'farklƒ±' in text_lower:
            # User rejected recommendations, provide alternatives
            return self._provide_alternative_recommendations(user_message, context, last_recs)
        elif 'neden' in text_lower or 'avantaj' in text_lower:
            # User wants explanation
            return self._explain_recommendations(user_message, context, last_recs)
        else:
            # General response to recommendations
            return self._respond_to_recommendation_feedback(user_message, context, last_recs)
    
    def _explain_algorithm_choice(self, algorithm: str, user_message: str, context: Dict) -> Dict:
        """Explain why user's algorithm choice is good/bad"""
        text_lower = user_message.lower()
        
        # Algorithm explanations based on context
        explanations = {
            'xgboost': {
                'pros': [
                    "M√ºkemmel se√ßim! XGBoost ger√ßekten g√º√ßl√º bir algoritma",
                    "Y√ºksek doƒüruluk oranlarƒ± saƒülar",
                    "Overfitting'e kar≈üƒ± dayanƒ±klƒ±",
                    "√ñzellik √∂nemini g√∂sterir",
                    "Hƒ±zlƒ± eƒüitim ve tahmin"
                ],
                'cons': [
                    "Hiperparametre ayarlamasƒ± gerekebilir",
                    "K√º√ß√ºk veri setlerinde overkill olabilir",
                    "Bellek kullanƒ±mƒ± y√ºksek olabilir"
                ],
                'when_good': "Orta/b√ºy√ºk veri setlerinde, y√ºksek doƒüruluk istediƒüinizde",
                'when_bad': "√áok k√º√ß√ºk veri setlerinde, basit problemlerde"
            },
            'random forest': {
                'pros': [
                    "Harika bir se√ßim! Random Forest √ßok g√ºvenilir",
                    "Overfitting riski d√º≈ü√ºk",
                    "Yorumlanabilir sonu√ßlar",
                    "Hiperparametre ayarƒ± minimal"
                ],
                'cons': [
                    "√áok b√ºy√ºk veri setlerinde yava≈ü olabilir",
                    "Bellek kullanƒ±mƒ± y√ºksek"
                ],
                'when_good': "Dengeli doƒüruluk ve hƒ±z istediƒüinizde",
                'when_bad': "√áok b√ºy√ºk veri setlerinde, hƒ±z kritikse"
            },
            'k-means': {
                'pros': [
                    "M√ºkemmel se√ßim! K-means clustering i√ßin ideal",
                    "Basit ve anla≈üƒ±lƒ±r algoritma",
                    "Hƒ±zlƒ± √ßalƒ±≈üƒ±r, b√ºy√ºk verilerle ba≈üa √ßƒ±kar",
                    "G√∂rselle≈ütirme imkanlarƒ± m√ºkemmel",
                    "M√º≈üteri segmentasyonu i√ßin √ßok uygun"
                ],
                'cons': [
                    "K deƒüerini (k√ºme sayƒ±sƒ±nƒ±) √∂nceden belirlemek gerekir",
                    "K√ºresel olmayan k√ºmelerde zorlanabilir",
                    "Outlier'lara (aykƒ±rƒ± deƒüer) hassas"
                ],
                'when_good': "M√º≈üteri segmentasyonu, pazar analizi, veri gruplama",
                'when_bad': "√áok karma≈üƒ±k ≈üekilli k√ºmeler, belirsiz k√ºme sayƒ±sƒ±"
            },
            'kmeans': {
                'pros': [
                    "M√ºkemmel se√ßim! K-means clustering i√ßin ideal",
                    "Basit ve anla≈üƒ±lƒ±r algoritma",
                    "Hƒ±zlƒ± √ßalƒ±≈üƒ±r, b√ºy√ºk verilerle ba≈üa √ßƒ±kar",
                    "G√∂rselle≈ütirme imkanlarƒ± m√ºkemmel",
                    "M√º≈üteri segmentasyonu i√ßin √ßok uygun"
                ],
                'cons': [
                    "K deƒüerini (k√ºme sayƒ±sƒ±nƒ±) √∂nceden belirlemek gerekir",
                    "K√ºresel olmayan k√ºmelerde zorlanabilir",
                    "Outlier'lara (aykƒ±rƒ± deƒüer) hassas"
                ],
                'when_good': "M√º≈üteri segmentasyonu, pazar analizi, veri gruplama",
                'when_bad': "√áok karma≈üƒ±k ≈üekilli k√ºmeler, belirsiz k√ºme sayƒ±sƒ±"
            }
        }
        
        algo_info = explanations.get(algorithm, {})
        
        # Determine if choice is good based on context
        project_type = context.get('project_type', '')
        data_size = context.get('data_size', '')
        
        is_good_choice = True  # Default positive
        
        if algorithm == 'xgboost' and data_size == 'small':
            is_good_choice = False
        
        # Generate response
        if is_good_choice:
            response = f"üéØ **Harika se√ßim!** {algorithm.title()} sizin projeniz i√ßin ger√ßekten uygun!\n\n"
            response += f"**Neden m√ºkemmel bir se√ßim:**\n"
            for pro in algo_info.get('pros', [])[:3]:
                response += f"‚úÖ {pro}\n"
            
            response += f"\n**Sizin durumunuzda √∂zellikle iyi √ß√ºnk√º:** {algo_info.get('when_good', 'genel olarak g√º√ßl√º bir algoritma')}\n\n"
            
            if algo_info.get('cons'):
                response += f"**Dikkat edilmesi gerekenler:**\n"
                for con in algo_info.get('cons', [])[:2]:
                    response += f"‚ö†Ô∏è {con}\n"
        else:
            response = f"ü§î **{algorithm.title()} se√ßimi hakkƒ±nda d√º≈ü√ºnelim...**\n\n"
            response += f"Bu algoritma g√º√ßl√º ama sizin durumunuzda belki daha basit bir se√ßenek daha uygun olabilir.\n\n"
            response += f"**Neden farklƒ± d√º≈ü√ºn√ºyorum:**\n"
            for con in algo_info.get('cons', [])[:2]:
                response += f"‚ö†Ô∏è {con}\n"
            
            response += f"\n**Alternatif √∂nerim:** Random Forest veya Logistic Regression daha uygun olabilir."
        
        suggestions = [
            f"{algorithm} nasƒ±l implement edilir?",
            "Alternatif algoritma √∂ner",
            "Performans kar≈üƒ±la≈ütƒ±rmasƒ± yap",
            "Kod √∂rneƒüi g√∂ster"
        ]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True,
                         "algorithm_discussed": algorithm
         }
    
    def _provide_alternative_recommendations(self, user_message: str, context: Dict, last_recs: List) -> Dict:
        """Provide alternative recommendations when user rejects previous ones"""
        response = "üîÑ **Tamam, farklƒ± se√ßenekler √∂nereyim!**\n\n"
        
        # Add context awareness
        conversation_context = context.get('conversation_context', {})
        user_selections = conversation_context.get('user_selections', [])
        
        if user_selections:
            last_selection = user_selections[-1]
            response += f"Sizin **{last_selection['algorithm']}** tercihinizi de g√∂z √∂n√ºnde bulundurarak, "
            response += f"farklƒ± yakla≈üƒ±mlar √∂nereyim:\n\n"
        
        # Get alternative algorithms
        alternative_algorithms = [
            "Support Vector Machine (SVM)",
            "Naive Bayes", 
            "K-Nearest Neighbors (KNN)",
            "Decision Tree",
            "Linear Regression"
        ]
        
        # Filter out previously recommended ones
        if last_recs:
            recommended_names = [rec.get('algorithm', rec.get('name', '')).lower() for rec in last_recs]
            alternative_algorithms = [algo for algo in alternative_algorithms 
                                    if not any(rec_name in algo.lower() for rec_name in recommended_names)]
        
        response += "**Alternatif algoritma √∂nerilerim:**\n\n"
        for i, algo in enumerate(alternative_algorithms[:3], 1):
            response += f"{i}. **{algo}**\n"
            response += f"   ‚Ä¢ Farklƒ± bir yakla≈üƒ±m sunar\n"
            response += f"   ‚Ä¢ Sizin durumunuz i√ßin de uygun olabilir\n\n"
        
        # Reference previous conversation
        if last_recs:
            response += f"**Not:** Daha √∂nce {len(last_recs)} algoritma √∂nermi≈ütim. "
            response += f"Bu sefer tamamen farklƒ± yakla≈üƒ±mlar deneyebiliriz.\n\n"
        
        response += "Hangi alternatif sizi daha √ßok ilgilendiriyor?"
        
        return {
            "response": response,
            "suggestions": ["ƒ∞lk alternatifi se√ß", "ƒ∞kinci alternatifi se√ß", "√ú√ß√ºnc√º alternatifi se√ß"],
            "success": True
        }
    
    def _explain_recommendations(self, user_message: str, context: Dict, last_recs: List) -> Dict:
        """Explain why previous recommendations were made"""
        if not last_recs:
            return self._generate_natural_consultation(user_message, context)
        
        response = "üí° **√ñnerilerimin nedenlerini a√ßƒ±klayayƒ±m:**\n\n"
        
        # Add context awareness
        conversation_context = context.get('conversation_context', {})
        user_selections = conversation_context.get('user_selections', [])
        
        if user_selections:
            last_selection = user_selections[-1]
            response += f"Daha √∂nce **{last_selection['algorithm']}** algoritmasƒ±nƒ± tercih ettiƒüinizi belirtmi≈ütiniz. "
            response += f"≈ûimdi size neden ba≈üka algoritmalarƒ± √∂nerdiƒüimi a√ßƒ±klayayƒ±m:\n\n"
        
        for i, rec in enumerate(last_recs[:3], 1):
            algo_name = rec.get('algorithm', rec.get('name', 'Algoritma'))
            confidence = rec.get('confidence_score', rec.get('confidence', 0.8))
            
            response += f"**{i}. {algo_name}** (Uygunluk: {confidence:.0%})\n"
            
            # Context-based explanations
            project_type = context.get('project_type', '')
            data_size = context.get('data_size', '')
            
            if 'xgboost' in algo_name.lower():
                response += f"   üéØ **Neden √∂nerdiƒüim:** Y√ºksek performans, {project_type} problemlerinde √ßok ba≈üarƒ±lƒ±\n"
                response += f"   ‚ö° **Avantajlarƒ±:** Hƒ±zlƒ±, doƒüru, overfitting'e dayanƒ±klƒ±\n"
            elif 'random forest' in algo_name.lower():
                response += f"   üéØ **Neden √∂nerdiƒüim:** G√ºvenilir, yorumlanabilir, {data_size} veri i√ßin ideal\n"
                response += f"   ‚ö° **Avantajlarƒ±:** Stabil sonu√ßlar, az hiperparametre\n"
            elif 'svm' in algo_name.lower():
                response += f"   üéØ **Neden √∂nerdiƒüim:** Matematiksel olarak g√º√ßl√º, {project_type} i√ßin etkili\n"
                response += f"   ‚ö° **Avantajlarƒ±:** Y√ºksek boyutlu veriler i√ßin iyi\n"
            elif 'mlp' in algo_name.lower() or 'algƒ±layƒ±cƒ±' in algo_name.lower():
                response += f"   üéØ **Neden √∂nerdiƒüim:** √áok katmanlƒ± yapƒ±, {project_type} i√ßin g√º√ßl√º\n"
                response += f"   ‚ö° **Avantajlarƒ±:** Esnek yapƒ±, kompleks kalƒ±plarƒ± √∂ƒürenir\n"
            elif 'ensemble' in algo_name.lower():
                response += f"   üéØ **Neden √∂nerdiƒüim:** Birden fazla modeli birle≈ütir, {project_type} i√ßin stabil\n"
                response += f"   ‚ö° **Avantajlarƒ±:** Y√ºksek doƒüruluk, overfitting'e dayanƒ±klƒ±\n"
            else:
                response += f"   üéØ **Neden √∂nerdiƒüim:** {project_type} projeniz i√ßin optimize edilmi≈ü\n"
                response += f"   ‚ö° **Avantajlarƒ±:** Sizin veri tipinize uygun\n"
            
            response += f"\n"
        
        # Reference user's selection if they made one
        if user_selections:
            last_selection = user_selections[-1]
            response += f"**Sizin tercihiniz olan {last_selection['algorithm']} hakkƒ±nda:** "
            response += f"Bu da m√ºkemmel bir se√ßim! Yukarƒ±daki √∂nerilerimle kar≈üƒ±la≈ütƒ±rabilirsiniz.\n\n"
        
        response += "Bu a√ßƒ±klamalar yardƒ±mcƒ± oldu mu? Ba≈üka bir ≈üey merak ediyorsanƒ±z sorabilirsiniz!"
        
        return {
            "response": response,
            "suggestions": ["Kod √∂rneƒüi g√∂ster", "Performans kar≈üƒ±la≈ütƒ±r", "Farklƒ± algoritma √∂ner"],
            "success": True
        }
    
    def _respond_to_recommendation_feedback(self, user_message: str, context: Dict, last_recs: List) -> Dict:
        """Respond to general feedback about recommendations"""
        text_lower = user_message.lower()
        
        # Detect specific user intents
        if any(word in text_lower for word in ['diƒüer', 'ba≈üka', 'farklƒ±', 'alternatif', 'daha fazla']):
            return self._provide_more_alternatives(user_message, context, last_recs)
        
        elif any(word in text_lower for word in ['hepsi', 't√ºm', 'b√ºt√ºn', 'liste', 'g√∂ster']):
            return self._show_comprehensive_list(user_message, context, last_recs)
        
        elif any(word in text_lower for word in ['evet', 'tamam', 'iyi', 'g√ºzel']):
            response = "üéâ **Harika! Se√ßiminizi beƒüendiƒüinize sevindim.**\n\n"
            response += "≈ûimdi implementasyon a≈üamasƒ±na ge√ßelim. Size yardƒ±mcƒ± olabileceƒüim konular:\n\n"
            response += "‚Ä¢ **Kod √∂rnekleri** - Algoritmayƒ± nasƒ±l kullanacaƒüƒ±nƒ±zƒ± g√∂sterebilirim\n"
            response += "‚Ä¢ **Hiperparametre ayarlarƒ±** - En iyi performans i√ßin optimizasyon\n"
            response += "‚Ä¢ **Veri hazƒ±rlama** - Algoritma i√ßin veriyi nasƒ±l hazƒ±rlayacaƒüƒ±nƒ±z\n"
            response += "‚Ä¢ **Performans deƒüerlendirme** - Sonu√ßlarƒ± nasƒ±l analiz edeceƒüiniz\n\n"
            response += "Hangi konuda yardƒ±m istiyorsunuz?"
            
            suggestions = ["Kod √∂rneƒüi g√∂ster", "Hiperparametre ayarlarƒ±", "Veri hazƒ±rlama", "Performans deƒüerlendirme"]
        else:
            response = "ü§î **Anlƒ±yorum, daha fazla bilgi istiyorsunuz.**\n\n"
            response += "Size nasƒ±l yardƒ±mcƒ± olabilirim?\n\n"
            response += "‚Ä¢ Algoritmalarƒ± daha detaylƒ± a√ßƒ±klayayƒ±m\n"
            response += "‚Ä¢ Farklƒ± se√ßenekler √∂nereyim\n"
            response += "‚Ä¢ Performans kar≈üƒ±la≈ütƒ±rmasƒ± yapayƒ±m\n"
            response += "‚Ä¢ Spesifik sorularƒ±nƒ±zƒ± yanƒ±tlayayƒ±m\n\n"
            response += "Ne yapmamƒ± istersiniz?"
            
            suggestions = ["Detaylƒ± a√ßƒ±klama", "Farklƒ± se√ßenekler", "Performans kar≈üƒ±la≈ütƒ±rmasƒ±", "Spesifik soru sor"]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
    
    def _provide_more_alternatives(self, user_message: str, context: Dict, last_recs: List) -> Dict:
        """Provide more alternative algorithms based on user request"""
        response = "üîÑ **Tabii ki! Daha fazla algoritma se√ßeneƒüi sunayƒ±m:**\n\n"
        
        # Get project context
        project_type = context.get('project_type', 'classification')
        data_size = context.get('data_size', 'medium')
        
        # Define comprehensive algorithm lists by category
        classification_algorithms = [
            "XGBoost", "Random Forest", "Support Vector Machine (SVM)", 
            "Naive Bayes", "K-Nearest Neighbors (KNN)", "Decision Tree",
            "Logistic Regression", "Neural Network (MLP)", "AdaBoost",
            "Gradient Boosting", "Extra Trees", "LightGBM", "CatBoost"
        ]
        
        regression_algorithms = [
            "Linear Regression", "Ridge Regression", "Lasso Regression",
            "ElasticNet", "Random Forest Regressor", "XGBoost Regressor",
            "Support Vector Regression", "Neural Network Regressor",
            "Polynomial Regression", "Decision Tree Regressor"
        ]
        
        clustering_algorithms = [
            "K-Means", "Hierarchical Clustering", "DBSCAN", "Gaussian Mixture",
            "Spectral Clustering", "Agglomerative Clustering", "Mean Shift",
            "OPTICS", "Birch", "Mini-Batch K-Means"
        ]
        
        # Select appropriate algorithm list
        if project_type == 'classification':
            algorithms = classification_algorithms
        elif project_type == 'regression':
            algorithms = regression_algorithms
        elif project_type == 'clustering':
            algorithms = clustering_algorithms
        else:
            algorithms = classification_algorithms  # Default
        
        # Filter out already recommended algorithms
        if last_recs:
            recommended_names = [rec.get('algorithm', '').lower() for rec in last_recs]
            algorithms = [algo for algo in algorithms 
                         if not any(rec_name in algo.lower() for rec_name in recommended_names)]
        
        # Show first 5 alternatives
        response += f"**{project_type.title()} i√ßin diƒüer se√ßenekler:**\n\n"
        for i, algo in enumerate(algorithms[:5], 1):
            response += f"{i}. **{algo}**\n"
            
            # Add context-specific benefits
            if 'xgboost' in algo.lower():
                response += f"   ‚Ä¢ Y√ºksek performans, gradient boosting\n"
            elif 'random forest' in algo.lower():
                response += f"   ‚Ä¢ G√ºvenilir, overfitting'e dayanƒ±klƒ±\n"
            elif 'svm' in algo.lower():
                response += f"   ‚Ä¢ Matematiksel olarak g√º√ßl√º\n"
            elif 'naive bayes' in algo.lower():
                response += f"   ‚Ä¢ Hƒ±zlƒ±, basit, etkili\n"
            elif 'knn' in algo.lower():
                response += f"   ‚Ä¢ Basit, yorumlanabilir\n"
            else:
                response += f"   ‚Ä¢ {project_type} problemleri i√ßin optimize\n"
            
            response += f"\n"
        
        response += f"**Toplam {len(algorithms)} farklƒ± algoritma se√ßeneƒüiniz var!**\n\n"
        response += "Hangi algoritma hakkƒ±nda daha fazla bilgi almak istersiniz?"
        
        suggestions = algorithms[:3]  # First 3 as suggestions
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
    
    def _show_comprehensive_list(self, user_message: str, context: Dict, last_recs: List) -> Dict:
        """Show comprehensive algorithm list"""
        response = "üìã **Kapsamlƒ± Algoritma Listesi:**\n\n"
        
        project_type = context.get('project_type', 'classification')
        
        if project_type == 'classification':
            response += "**üéØ Sƒ±nƒ±flandƒ±rma Algoritmalarƒ±:**\n\n"
            
            response += "**Ensemble Methods:**\n"
            response += "‚Ä¢ Random Forest, XGBoost, LightGBM, CatBoost\n"
            response += "‚Ä¢ AdaBoost, Gradient Boosting, Extra Trees\n\n"
            
            response += "**Traditional ML:**\n"
            response += "‚Ä¢ Support Vector Machine (SVM)\n"
            response += "‚Ä¢ Logistic Regression, Naive Bayes\n"
            response += "‚Ä¢ K-Nearest Neighbors (KNN)\n"
            response += "‚Ä¢ Decision Tree\n\n"
            
            response += "**Deep Learning:**\n"
            response += "‚Ä¢ Neural Network (MLP)\n"
            response += "‚Ä¢ Convolutional Neural Network (CNN)\n"
            response += "‚Ä¢ Recurrent Neural Network (RNN)\n\n"
            
        elif project_type == 'regression':
            response += "**üìà Regresyon Algoritmalarƒ±:**\n\n"
            
            response += "**Linear Models:**\n"
            response += "‚Ä¢ Linear Regression, Ridge, Lasso\n"
            response += "‚Ä¢ ElasticNet, Polynomial Regression\n\n"
            
            response += "**Tree-based:**\n"
            response += "‚Ä¢ Random Forest Regressor\n"
            response += "‚Ä¢ XGBoost Regressor, Decision Tree\n\n"
            
            response += "**Advanced:**\n"
            response += "‚Ä¢ Support Vector Regression\n"
            response += "‚Ä¢ Neural Network Regressor\n\n"
            
        else:
            response += "**üîç K√ºmeleme Algoritmalarƒ±:**\n\n"
            
            response += "**Centroid-based:**\n"
            response += "‚Ä¢ K-Means, Mini-Batch K-Means\n\n"
            
            response += "**Hierarchical:**\n"
            response += "‚Ä¢ Agglomerative, Hierarchical\n\n"
            
            response += "**Density-based:**\n"
            response += "‚Ä¢ DBSCAN, OPTICS\n\n"
        
        response += "**Hangi kategori sizi daha √ßok ilgilendiriyor?**"
        
        suggestions = ["Ensemble Methods", "Traditional ML", "Deep Learning", "Performans kar≈üƒ±la≈ütƒ±rmasƒ±"]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
 
    def _generate_natural_consultation(self, user_message: str, context: Dict) -> Dict:
        """Generate natural, conversational consultation response"""
        if self.openai_enabled:
            return self._generate_gpt4_natural_consultation(user_message, context)
        else:
            return self._generate_template_natural_consultation(user_message, context)

    def _generate_gpt4_natural_consultation(self, user_message: str, context: Dict) -> Dict:
        """Generate natural consultation using GPT-4"""
        # Prepare rich context for GPT-4
        conversation_summary = self._summarize_conversation()
        user_profile_summary = self._summarize_user_profile()
        
        context_prompt = f"""
Konu≈üma √ñzeti: {conversation_summary}

Kullanƒ±cƒ± Profili: {user_profile_summary}

Mevcut Proje Bilgileri:
- Proje t√ºr√º: {context.get('project_type', 'Hen√ºz belirlenmedi')}
- Veri boyutu: {context.get('data_size', 'Hen√ºz belirlenmedi')}
- Veri t√ºr√º: {context.get('data_type', 'Hen√ºz belirlenmedi')}
- Kullanƒ±m alanƒ±: {context.get('use_case', 'Hen√ºz belirlenmedi')}
- Kƒ±sƒ±tlamalar: {', '.join(context.get('constraints', [])) if context.get('constraints') else 'Yok'}

Kullanƒ±cƒ±nƒ±n Son Mesajƒ±: "{user_message}"

G√∂revin:
1. Kullanƒ±cƒ±nƒ±n mesajƒ±na samimi ve doƒüal bir ≈üekilde cevap ver
2. Eksik bilgileri √∂ƒürenmek i√ßin yaratƒ±cƒ± sorular sor
3. Ki≈üisel deneyimlerini payla≈ü
4. Cesaretlendirici ve destekleyici ol
5. Teknik terimleri g√ºnl√ºk dille a√ßƒ±kla
6. 2-3 paragraf halinde akƒ±cƒ± bir konu≈üma yap

Robotik cevaplar verme, ger√ßek bir mentor gibi konu≈ü!
"""
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": self.consultation_prompt},
                    {"role": "user", "content": context_prompt}
                ],
                max_tokens=500,
                temperature=0.9,  # Higher temperature for more creative responses
                presence_penalty=0.3,  # Encourage diverse vocabulary
                frequency_penalty=0.3   # Reduce repetition
            )
            
            gpt_response = response.choices[0].message.content
            
            # Generate contextual suggestions
            suggestions = self._generate_natural_suggestions(context, user_message)
            
            return {
                "response": gpt_response,
                "suggestions": suggestions,
                "success": True,
                "ai_powered": True,
                "conversation_stage": self._get_conversation_stage(context)
            }
                
        except Exception as e:
            logger.error(f"GPT-4 consultation failed: {e}")
            return self._generate_template_natural_consultation(user_message, context)

    def _generate_template_natural_consultation(self, user_message: str, context: Dict) -> Dict:
        """Generate natural consultation using enhanced templates"""
        text_lower = user_message.lower()
        
        # Check for diversity instruction
        diversity_mode = context.get('diversity_instruction') is not None
        conversation_turn = context.get('conversation_turn', 1)
        
        # Greeting responses with enhanced diversity and context awareness
        if any(word in text_lower for word in ['merhaba', 'selam', 'hello', 'hi']):
            # Check conversation history for context
            conversation_context = context.get('conversation_context', {})
            discussed_algorithms = conversation_context.get('discussed_algorithms', [])
            user_selections = conversation_context.get('user_selections', [])
            
            # Check if we have diversity instruction
            if diversity_mode:
                responses = [
                    "Tekrar ho≈ü geldiniz! Bu sefer hangi algoritma macerasƒ±na √ßƒ±kacaƒüƒ±z? Her konu≈ümada farklƒ± hikayeler ke≈üfediyoruz ve bu ger√ßekten keyifli! \n\nBu kez hangi t√ºr bir proje √ºzerinde kafa yoruyorsunuz? Belki daha √∂nce hi√ß d√º≈ü√ºnmediƒüiniz bir yakla≈üƒ±m bulabiliriz.",
                    
                    "Yine buradayƒ±z! Makine √∂ƒürenmesi d√ºnyasƒ±nda yeni bir ke≈üif yapmaya hazƒ±r mƒ±sƒ±nƒ±z? Her seferinde farklƒ± a√ßƒ±lardan bakƒ±yoruz ve bu √ßok eƒülenceli! \n\nBu sefer hangi veri bilimi problemini √ß√∂zmek istiyorsunuz? Belki bamba≈üka bir algoritma ailesi ke≈üfederiz!",
                    
                    "Geri d√∂nd√ºƒü√ºn√ºz i√ßin mutluyum! Bu kez hangi algoritma yolculuƒüuna √ßƒ±kacaƒüƒ±z? Her konu≈üma yeni perspektifler getiriyor. \n\nBu sefer hangi t√ºr bir analiz yapmayƒ± planlƒ±yorsunuz? Farklƒ± bir yakla≈üƒ±m denemek i√ßin sabƒ±rsƒ±zlanƒ±yorum!"
                ]
            else:
                base_responses = [
                    "Merhaba! Ben AlgoMentor, makine √∂ƒürenmesi algoritmalarƒ±nda size yardƒ±mcƒ± olmak i√ßin buradayƒ±m. Ger√ßekten heyecan verici bir alanda √ßalƒ±≈üƒ±yorsunuz! \n\nBenim deneyimime g√∂re, doƒüru algoritma se√ßimi projenin ba≈üarƒ±sƒ±nƒ±n %80'ini belirliyor. Peki, hangi t√ºr bir proje √ºzerinde √ßalƒ±≈üƒ±yorsunuz? Merak ettim √ß√ºnk√º her projenin kendine √∂zg√º g√ºzellikleri var.",
                    
                    "Selam! Ho≈ü geldiniz! Ben makine √∂ƒürenmesi d√ºnyasƒ±nda size rehberlik edecek AlgoMentor'unuz. Yƒ±llardƒ±r bu alanda √ßalƒ±≈üƒ±yorum ve her yeni proje beni hala heyecanlandƒ±rƒ±yor.\n\n≈û√∂yle ki, algoritma se√ßimi biraz m√ºzik enstr√ºmanƒ± se√ßmeye benziyor - her biri farklƒ± melodiler √ßƒ±karƒ±yor. Sizin projeniz hangi t√ºr bir 'melodi' √ßƒ±karmak istiyor? Anlatsanƒ±z, size en uygun 'enstr√ºmanƒ±' bulalƒ±m!"
                ]
                
                # Add context awareness if there's conversation history
                if discussed_algorithms or user_selections:
                    context_addition = "\n\n**Konu≈üma ge√ßmi≈üimizden:** "
                    if discussed_algorithms:
                        context_addition += f"Daha √∂nce {', '.join(discussed_algorithms)} algoritmalarƒ±nƒ± konu≈ümu≈ütuk. "
                    if user_selections:
                        last_selection = user_selections[-1]
                        context_addition += f"√ñzellikle {last_selection['algorithm']} algoritmasƒ±nƒ± tercih ettiƒüinizi hatƒ±rlƒ±yorum. "
                    context_addition += "Bu bilgileri g√∂z √∂n√ºnde bulundurarak size yardƒ±mcƒ± olabilirim!"
                    
                    responses = [resp + context_addition for resp in base_responses]
                else:
                    responses = base_responses
            
            response = random.choice(responses)
            suggestions = [
                "Veri sƒ±nƒ±flandƒ±rmasƒ± yapmak istiyorum",
                "Tahmin modeli geli≈ütiriyorum",
                "Veri analizi yapacaƒüƒ±m",
                "Hen√ºz ne yapacaƒüƒ±mƒ± bilmiyorum"
            ]
        
        # Project type discovery with diversity
        elif not context.get('project_type'):
            if diversity_mode:
                responses = [
                    "Bu kez farklƒ± bir a√ßƒ±dan bakalƒ±m! Proje hedeflerinizi daha detaylƒ± anlayabilir miyim? Her projenin kendine √∂zg√º bir hikayesi var ve sizinkini merak ediyorum. \n\nBu sefer hangi t√ºr bir veri macerasƒ±na atƒ±lƒ±yorsunuz? Belki hi√ß d√º≈ü√ºnmediƒüiniz bir yakla≈üƒ±m ke≈üfederiz!",
                    
                    "Yeni bir perspektifle yakla≈üalƒ±m! Verilerinizle nasƒ±l bir sonuca ula≈ümak istiyorsunuz? Bu kez farklƒ± algoritma ailelerini ke≈üfetmek i√ßin sabƒ±rsƒ±zlanƒ±yorum. \n\nProjenizin ana amacƒ± nedir? Hangi t√ºr √ßƒ±ktƒ± elde etmeyi hedefliyorsunuz?",
                    
                    "Bu sefer bamba≈üka bir yoldan gidelim! Projenizin √∂z√ºn√º anlayabilir miyim? Her seferinde farklƒ± √ß√∂z√ºm yollarƒ± ke≈üfediyoruz. \n\nBu kez hangi t√ºr analiz yapmayƒ± planlƒ±yorsunuz? Belki daha √∂nce hi√ß d√º≈ü√ºnmediƒüiniz bir algoritma kategorisi bulabiliriz!"
                ]
            else:
                responses = [
                    "Vay, bu ger√ßekten ilgin√ß geliyor! Benim deneyimime g√∂re, projenin hedefini net anlamak algoritma se√ßiminin yarƒ±sƒ± demek. \n\nMesela, ge√ßen ay bir e-ticaret ≈üirketi ile √ßalƒ±≈ütƒ±m - onlar m√º≈üteri davranƒ±≈ülarƒ±nƒ± tahmin etmek istiyordu. Sizin durumunuz nasƒ±l? Hangi t√ºr bir sonu√ß elde etmeyi hedefliyorsunuz? Verilerinizle ne yapmak istiyorsunuz?",
                    
                    "≈û√∂yle d√º≈ü√ºnelim: Makine √∂ƒürenmesi biraz dedektiflik gibi - verilerden ipu√ßlarƒ± toplayƒ±p bir sonuca varƒ±yoruz. Peki sizin 'gizeminiz' nedir? \n\nVerilerinizle ≈üunlardan hangisini yapmak istiyorsunuz: Bir ≈üeyleri kategorilere ayƒ±rmak mƒ±, gelecekteki deƒüerleri tahmin etmek mi, yoksa veriler arasƒ±ndaki gizli kalƒ±plarƒ± ke≈üfetmek mi?"
                ]
            
            response = random.choice(responses)
            suggestions = [
                "Verileri kategorilere ayƒ±rmak istiyorum",
                "Gelecekteki deƒüerleri tahmin etmek istiyorum",
                "Veri gruplarƒ±nƒ± ke≈üfetmek istiyorum",
                "Anormal durumlarƒ± tespit etmek istiyorum"
            ]
        
        # Data size discovery with context awareness
        elif not context.get('data_size'):
            project_type = context.get('project_type', 'proje')
            
            # Check conversation history for previous mentions
            conversation_context = self._get_conversation_context()
            
            if diversity_mode:
                responses = [
                    f"≈ûimdi {project_type} projeniz i√ßin veri boyutunu konu≈üalƒ±m! Bu kez farklƒ± bir a√ßƒ±dan yakla≈ümak istiyorum. Veri boyutu algoritma performansƒ±nƒ± doƒürudan etkiler. \n\nBu sefer veri setinizin boyutu hakkƒ±nda ne s√∂yleyebilirsiniz? Ka√ß kayƒ±t var yakla≈üƒ±k olarak?",
                    
                    f"Bu kez {project_type} projenizin veri boyutunu ke≈üfedelim! Her algoritmanƒ±n farklƒ± veri boyutlarƒ±nda farklƒ± performans g√∂sterdiƒüini biliyorsunuz. \n\nBu sefer veri setinizin b√ºy√ºkl√ºƒü√º nasƒ±l? Hangi aralƒ±kta?"
                ]
            else:
                responses = [
                    f"Harika! {project_type} ger√ßekten g√ºzel bir alan. Benim deneyimime g√∂re, veri boyutu algoritma se√ßiminde kritik rol oynuyor. \n\nMesela, k√º√ß√ºk veri setlerinde basit algoritmalar mucizeler yaratabilirken, b√ºy√ºk verilerde daha sofistike yakla≈üƒ±mlar gerekiyor. Sizin veri setiniz hangi boyutta? Ka√ß kayƒ±t var yakla≈üƒ±k olarak?",
                    
                    f"≈û√∂yle ki, {project_type} projesi i√ßin veri boyutu biraz yemeƒüin porsiyon miktarƒ± gibi - az olursa farklƒ± pi≈üirme teknikleri, √ßok olursa farklƒ± yakla≈üƒ±mlar gerekiyor. \n\nVerilerinizin boyutu nasƒ±l? Bu bilgi sayesinde size en verimli algoritmalarƒ± √∂nerebilirim."
                ]
            
            response = random.choice(responses)
            suggestions = [
                "K√º√ß√ºk veri setim var (1000'den az)",
                "Orta boyut veri setim var (1000-10000)",
                "B√ºy√ºk veri setim var (10000+)",
                "√áok b√ºy√ºk veri setim var (100000+)"
            ]
        
        # Data type discovery
        elif not context.get('data_type'):
            responses = [
                "M√ºkemmel! Veri boyutunu bilmek √ßok yardƒ±mcƒ± oldu. ≈ûimdi veri t√ºr√ºn√º √∂ƒürenmek istiyorum √ß√ºnk√º bu da algoritma se√ßimini doƒürudan etkiliyor.\n\nBenim deneyimime g√∂re, sayƒ±sal veriler farklƒ±, metin verileri farklƒ± yakla≈üƒ±mlar istiyor. Tƒ±pkƒ± farklƒ± dilleri konu≈ümak gibi - her biri kendine √∂zg√º kurallarƒ± var. Sizin verileriniz hangi t√ºrde?",
                
                "≈û√∂yle d√º≈ü√ºnelim: Veriler biraz farklƒ± dillerde yazƒ±lmƒ±≈ü kitaplar gibi. Sayƒ±sal veriler matematik dili, metin verileri edebiyat dili, g√∂r√ºnt√ºler ise sanat dili konu≈üuyor. \n\nSizin verileriniz hangi 'dilde' konu≈üuyor? Bu bilgi ile size en uygun '√ßevirmen' algoritmayƒ± bulabilirim."
            ]
            
            response = random.choice(responses)
            suggestions = [
                "Sayƒ±sal verilerle √ßalƒ±≈üƒ±yorum",
                "Metin verileri i≈üliyorum",
                "Kategorik verilerim var",
                "G√∂r√ºnt√º verileri kullanƒ±yorum"
            ]
        
        # Ready for recommendations
        else:
            response = "Harika! Artƒ±k projeniz hakkƒ±nda yeterli bilgiye sahibim. Veri setinizin √∂zelliklerini ve hedeflerinizi anlayarak size √∂zel algoritma √∂nerilerimi hazƒ±rlƒ±yorum. \n\nBenim deneyimime g√∂re, sizin durumunuz i√ßin birka√ß m√ºkemmel se√ßenek var. Hemen en uygun algoritmalarƒ± analiz edeyim!"
            suggestions = ["Algoritma √∂nerilerini g√∂ster"]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True,
            "conversation_stage": self._get_conversation_stage(context)
        }

    def _summarize_conversation(self) -> str:
        """Summarize recent conversation for context"""
        if not self.conversation_memory:
            return "Yeni konu≈üma ba≈ülƒ±yor"
        
        recent_topics = []
        for msg in self.conversation_memory[-5:]:
            if 'sƒ±nƒ±flandƒ±rma' in msg['content'].lower():
                recent_topics.append('sƒ±nƒ±flandƒ±rma')
            elif 'regresyon' in msg['content'].lower():
                recent_topics.append('regresyon')
            elif 'k√ºmeleme' in msg['content'].lower():
                recent_topics.append('k√ºmeleme')
        
        if recent_topics:
            return f"Son konu≈üulan konular: {', '.join(set(recent_topics))}"
        return "Genel algoritma danƒ±≈ümanlƒ±ƒüƒ±"

    def _summarize_user_profile(self) -> str:
        """Summarize user profile for context"""
        profile_parts = []
        
        if self.user_profile['experience_level'] != 'unknown':
            profile_parts.append(f"Deneyim: {self.user_profile['experience_level']}")
        
        if self.user_profile['preferred_style'] != 'unknown':
            profile_parts.append(f"Tercih: {self.user_profile['preferred_style']}")
        
        return ', '.join(profile_parts) if profile_parts else "Profil hen√ºz belirlenmedi"

    def _generate_natural_suggestions(self, context: Dict, user_message: str) -> List[str]:
        """Generate natural, contextual suggestions"""
        if not context.get('project_type'):
            return [
                "M√º≈üteri davranƒ±≈ülarƒ±nƒ± tahmin etmek istiyorum",
                "E-posta spam tespiti yapacaƒüƒ±m",
                "Satƒ±≈ü tahminleri yapmak istiyorum",
                "G√∂r√ºnt√º tanƒ±ma projesi geli≈ütiriyorum"
            ]
        elif not context.get('data_size'):
            return [
                "Birka√ß y√ºz kayƒ±t var",
                "Binlerce kayƒ±t var",
                "On binlerce kayƒ±t var",
                "Milyonlarca kayƒ±t var"
            ]
        elif not context.get('data_type'):
            return [
                "Excel tablosunda sayƒ±sal veriler",
                "M√º≈üteri yorumlarƒ± ve metinler",
                "√úr√ºn kategorileri ve etiketler",
                "Fotoƒüraf ve g√∂r√ºnt√º dosyalarƒ±"
            ]
        else:
            return [
                "En iyi algoritmalarƒ± √∂ner",
                "Performans kar≈üƒ±la≈ütƒ±rmasƒ± yap",
                "Kod √∂rnekleri ver",
                "Hangi metriƒüi kullanmalƒ±yƒ±m?"
            ]

    def _get_conversation_context(self) -> str:
        """Get conversation context from memory"""
        if not self.conversation_memory:
            return "Yeni konu≈üma"
        
        # Build context from conversation memory
        context_parts = []
        
        # Check for discussed algorithms
        if self.conversation_context['discussed_algorithms']:
            context_parts.append(f"Daha √∂nce {', '.join(self.conversation_context['discussed_algorithms'])} algoritmalarƒ±nƒ± konu≈ütuk.")
        
        # Check for user selections
        if self.conversation_context['user_selections']:
            last_selection = self.conversation_context['user_selections'][-1]
            context_parts.append(f"√ñzellikle {last_selection['algorithm']} algoritmasƒ±nƒ± tercih ettiƒüinizi belirttiniz.")
        
        # Check for recent feedback
        if self.conversation_context['user_feedback']:
            recent_feedback = self.conversation_context['user_feedback'][-1]
            if recent_feedback['type'] == 'positive':
                context_parts.append("Son √∂nerilerimizi beƒüendiƒüinizi s√∂ylemi≈ütiniz.")
            elif recent_feedback['type'] == 'negative':
                context_parts.append("Son √∂nerilerimden memnun olmadƒ±ƒüƒ±nƒ±zƒ± belirttiniz.")
        
        # Check for last recommendations
        if self.conversation_context['last_recommendations']:
            rec_count = len(self.conversation_context['last_recommendations'])
            context_parts.append(f"Size {rec_count} algoritma √∂nerisi sunmu≈ütum.")
        
        return " ".join(context_parts) if context_parts else "Konu≈ümamƒ±z devam ediyor."
        
        # Analyze recent conversation
        recent_topics = []
        for msg in self.conversation_memory[-5:]:
            content = msg.get('content', '').lower()
            if 'sƒ±nƒ±flandƒ±rma' in content or 'classification' in content:
                recent_topics.append('sƒ±nƒ±flandƒ±rma')
            elif 'regresyon' in content or 'regression' in content:
                recent_topics.append('regresyon')
            elif 'k√ºmeleme' in content or 'clustering' in content:
                recent_topics.append('k√ºmeleme')
            elif 'algoritma' in content:
                recent_topics.append('algoritma')
        
        if recent_topics:
            return f"√ñnceki konu≈üma: {', '.join(set(recent_topics))}"
        return "Genel makine √∂ƒürenmesi"

    def _get_conversation_stage(self, context: Dict) -> str:
        """Determine current conversation stage"""
        if not context.get('project_type'):
            return 'project_discovery'
        elif not context.get('data_size'):
            return 'data_sizing'
        elif not context.get('data_type'):
            return 'data_typing'
        else:
            return 'recommendation_ready'

    def _generate_enhanced_recommendations(self, user_message: str, context: Dict) -> Dict:
        """Generate enhanced algorithm recommendations with natural language"""
        if self.openai_enabled:
            return self._generate_gpt4_enhanced_recommendations(user_message, context)
        else:
            return self._generate_template_enhanced_recommendations(user_message, context)

    def _generate_gpt4_enhanced_recommendations(self, user_message: str, context: Dict) -> Dict:
        """Generate recommendations using GPT-4 with natural storytelling"""
        # Get algorithm recommendations from our model
        recommendations = self.algorithm_recommender.get_recommendations(
            project_type=context.get('project_type'),
            data_size=context.get('data_size'),
            data_type=context.get('data_type'),
            complexity_preference='medium',
            top_n=3
        )
        
        # Prepare context for GPT-4
        recommendations_summary = []
        for rec in recommendations:
            confidence = rec.get('confidence_score', rec.get('confidence', 0.8))
            explanation = rec.get('explanation', rec.get('description', ''))
            recommendations_summary.append(f"- {rec['algorithm']} (G√ºven: {confidence:.1f}): {explanation}")
        
        context_prompt = f"""
Kullanƒ±cƒ±nƒ±n Proje Bilgileri:
- Proje t√ºr√º: {context.get('project_type')}
- Veri boyutu: {context.get('data_size')}
- Veri t√ºr√º: {context.get('data_type')}

√ñnerilen Algoritmalar:
{chr(10).join(recommendations_summary)}

Kullanƒ±cƒ±nƒ±n Son Mesajƒ±: "{user_message}"

G√∂revin:
1. Algoritmalarƒ± hikaye anlatƒ±r gibi tanƒ±t
2. Her algoritmanƒ±n "karakterini" ve "ki≈üiliƒüini" a√ßƒ±kla
3. Ger√ßek d√ºnya √∂rnekleri ver
4. Hangi durumda hangisini se√ßeceƒüini a√ßƒ±kla
5. Ki≈üisel deneyimlerini payla≈ü
6. Cesaretlendirici ve destekleyici ol
7. 3-4 paragraf halinde akƒ±cƒ± bir anlatƒ±m yap

Robotik listeler yerine hikaye anlatƒ±r gibi konu≈ü!
"""
        
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": self.algorithm_expert_prompt},
                    {"role": "user", "content": context_prompt}
                ],
                max_tokens=800,
                temperature=0.8,
                presence_penalty=0.2,
                frequency_penalty=0.2
            )
            
            gpt_response = response.choices[0].message.content
            
            # Generate follow-up suggestions
            suggestions = [
                f"{recommendations[0]['algorithm']} hakkƒ±nda daha fazla bilgi",
                "Kod √∂rnekleri g√∂ster",
                "Performans kar≈üƒ±la≈ütƒ±rmasƒ± yap",
                "Hangi metriƒüi kullanmalƒ±yƒ±m?"
            ]
            
            return {
                "response": gpt_response,
                "suggestions": suggestions,
                "recommendations": recommendations,
                "success": True,
                "ai_powered": True
            }
            
        except Exception as e:
            logger.error(f"GPT-4 recommendations failed: {e}")
            return self._generate_template_enhanced_recommendations(user_message, context)

    def _generate_template_enhanced_recommendations(self, user_message: str, context: Dict) -> Dict:
        """Generate enhanced recommendations using creative templates"""
        # Get algorithm recommendations
        recommendations = self.algorithm_recommender.get_recommendations(
            project_type=context.get('project_type'),
            data_size=context.get('data_size'),
            data_type=context.get('data_type'),
            complexity_preference='medium',
            top_n=3
        )
        
        if not recommendations:
            return self._get_emergency_fallback()
    
        # Create storytelling response
        project_type = context.get('project_type', 'proje')
        top_algo = recommendations[0]
        
        storytelling_intros = [
            f"Harika! {project_type} projeniz i√ßin analiz yaptƒ±m ve ger√ßekten heyecan verici sonu√ßlar √ßƒ±ktƒ±. Benim deneyimime g√∂re, sizin durumunuz i√ßin birka√ß 's√ºper kahraman' algoritma var.",
            
            f"Vay canƒ±na! {project_type} projesi i√ßin m√ºkemmel bir kombinasyon buldum. ≈û√∂yle ki, her algoritmanƒ±n kendine √∂zg√º bir 'ki≈üiliƒüi' var ve sizin verilerinizle harika bir uyum saƒülayacak olanlarƒ± se√ßtim.",
            
            f"M√ºjde! {project_type} alanƒ±nda √ßok ba≈üarƒ±lƒ± sonu√ßlar veren algoritmalar var ve sizin veri setiniz i√ßin √∂zel olarak en uygun olanlarƒ± analiz ettim."
        ]
        
        response = random.choice(storytelling_intros) + "\n\n"
        
        # Describe top algorithm with personality
        algo_personalities = {
            'Random Forest': "Random Forest ger√ßek bir 'takƒ±m oyuncusu' - y√ºzlerce k√º√ß√ºk karar aƒüacƒ±ndan olu≈üan bir orkestra gibi √ßalƒ±≈üƒ±yor. Benim deneyimime g√∂re, √ßok g√ºvenilir ve hatalarƒ±nƒ± kendi kendine d√ºzelten nadir algoritmalardan biri.",
            
            'XGBoost': "XGBoost ise 'm√ºkemmeliyet√ßi' bir karakter - her hatadan √∂ƒürenen ve s√ºrekli kendini geli≈ütiren bir algoritma. Kaggle yarƒ±≈ümalarƒ±nƒ±n kralƒ± diye bo≈üuna demiyorlar!",
            
            'Logistic Regression': "Logistic Regression 'sade ve etkili' bir yakla≈üƒ±m - bazen en basit √ß√∂z√ºmler en g√º√ßl√º olanlar oluyor. Hƒ±zlƒ±, anla≈üƒ±lƒ±r ve g√ºvenilir.",
            
            'K-Means': "K-Means 'organizat√∂r' bir algoritma - karma≈üƒ±k veri yƒ±ƒüƒ±nlarƒ±nƒ± d√ºzenli gruplara ayƒ±rmada uzman. Basit ama √ßok etkili.",
            
            'SVM': "SVM 'm√ºkemmel sƒ±nƒ±r √ßizici' - veriler arasƒ±nda en optimal sƒ±nƒ±rlarƒ± bulan, matematiksel olarak √ßok zarif bir algoritma."
        }
        
        top_algo_name = top_algo['algorithm']
        if top_algo_name in algo_personalities:
            response += algo_personalities[top_algo_name]
        else:
            explanation = top_algo.get('explanation', top_algo.get('description', '√ßok uygun bir se√ßim'))
            response += f"{top_algo_name} sizin projeniz i√ßin m√ºkemmel bir se√ßim √ß√ºnk√º {explanation.lower()}"
        
        confidence = top_algo.get('confidence_score', top_algo.get('confidence', 0.8))
        response += f" G√ºven oranƒ± %{confidence * 100:.0f} - bu ger√ßekten y√ºksek bir skor!\n\n"
        
        # Add practical advice
        practical_advice = [
            "Benim tavsiyem, √∂nce bu algoritmayla ba≈ülayƒ±n ve sonu√ßlarƒ± g√∂zlemleyin. Genellikle ilk denemede √ßok iyi sonu√ßlar alƒ±yorsunuz.",
            
            "≈û√∂yle bir strateji √∂neriyorum: Bu algoritmayla temel modelinizi kurun, sonra diƒüer se√ßenekleri de deneyin ve kar≈üƒ±la≈ütƒ±rƒ±n.",
            
            "Pratik a√ßƒ±dan bakarsak, bu algoritma sizin veri setinizle harika √ßalƒ±≈üacak. ƒ∞sterseniz adƒ±m adƒ±m nasƒ±l uygulayacaƒüƒ±nƒ±zƒ± da anlatabilirim."
        ]
        
        response += random.choice(practical_advice)
        
        # Generate contextual suggestions
        suggestions = [
            f"{top_algo_name} nasƒ±l √ßalƒ±≈üƒ±r?",
            "Kod √∂rneƒüi ver",
            "Diƒüer algoritmalarƒ± da g√∂ster",
            "Performans kar≈üƒ±la≈ütƒ±rmasƒ± yap"
        ]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "recommendations": recommendations,
            "success": True
        }
    
    def _extract_enhanced_project_context(self, current_message: str, conversation_history: Optional[List[Dict]] = None) -> Dict:
        """
        Extract project context using AI analysis
        """
        # Handle None or empty messages
        if current_message is None:
            current_message = ""
            
        context = {
            'project_type': None,
            'data_size': None,
            'data_type': None,
            'class_count': None,
            'use_case': None,
            'constraints': [],
            'mentioned_algorithms': [],
            'conversation_stage': 'information_gathering'
        }
        
        # Combine all conversation content
        full_conversation = ""
        if conversation_history:
            for msg in conversation_history[-10:]:  # Last 10 messages
                if isinstance(msg, dict):
                    role = msg.get('role', '')
                    content = msg.get('content', '')
                    full_conversation += f"{role}: {content}\n"
        
        full_conversation += f"user: {current_message}"
        
        # Enhanced pattern matching with AI-like context understanding
        text_lower = full_conversation.lower()
        
        # Project type detection (more sophisticated)
        if any(word in text_lower for word in ['sƒ±nƒ±flandƒ±rma', 'classification', 'kategorilere ayƒ±r', 'sƒ±nƒ±flama', 'tahmin et', 'predict class']):
            context['project_type'] = 'classification'
        elif any(word in text_lower for word in ['k√ºmeleme', 'clustering', 'segmentasyon', 'gruplama', 'segment']):
            context['project_type'] = 'clustering'
        elif any(word in text_lower for word in ['regresyon', 'regression', 'deƒüer tahmin', 'fiyat tahmin', 'forecast']):
            context['project_type'] = 'regression'
        elif any(word in text_lower for word in ['anomali', 'outlier', 'anormal', 'dolandƒ±rƒ±cƒ±lƒ±k', 'fraud']):
            context['project_type'] = 'anomaly_detection'
        elif any(word in text_lower for word in ['√∂neri', 'recommendation', 'tavsiye', 'suggest']):
            context['project_type'] = 'recommendation'
        
        # Data type detection (more intelligent defaults)
        if any(word in text_lower for word in ['sayƒ±sal', 'numerical', 'numeric', 'number', 'regresyon', 'regression']):
            context['data_type'] = 'numerical'
        elif any(word in text_lower for word in ['kategorik', 'categorical', 'category']):
            context['data_type'] = 'categorical'
        elif any(word in text_lower for word in ['metin', 'text', 'kelime', 'word']):
            context['data_type'] = 'text'
        elif any(word in text_lower for word in ['g√∂r√ºnt√º', 'image', 'resim', 'photo']):
            context['data_type'] = 'image'
        elif context.get('project_type'):
            # Default to numerical if project type is known but data type isn't specified
            context['data_type'] = 'numerical'
            
        # Data size defaults (more intelligent guessing)
        import re
        numbers = re.findall(r'\d+', text_lower)
        size_detected = False
        for num in numbers:
            num_val = int(num)
            if num_val < 1000:
                context['data_size'] = 'small'
                size_detected = True
                break
            elif num_val < 10000:
                context['data_size'] = 'medium'
                size_detected = True
                break
            else:
                context['data_size'] = 'large'
                size_detected = True
                break
        
        # Default data size if not detected but project type is known        
        if not size_detected and context.get('project_type'):
            context['data_size'] = 'medium'  # Safe default
                
        # Class count for classification
        if context['project_type'] == 'classification':
            if any(word in text_lower for word in ['2 sƒ±nƒ±f', 'binary', 'ikili', 'two class']):
                context['class_count'] = 'binary'
            elif any(word in text_lower for word in ['3', '4', '5', 'few', 'az sƒ±nƒ±f']):
                context['class_count'] = 'multiclass'
            elif any(word in text_lower for word in ['√ßok sƒ±nƒ±f', 'many class', 'multiple']):
                context['class_count'] = 'multilabel'
            else:
                # Default to multiclass if classification is detected but no specific count given
                context['class_count'] = 'multiclass'
        
        # Extract mentioned algorithms
        algorithms = ['xgboost', 'random forest', 'svm', 'neural network', 'logistic regression', 'naive bayes', 'knn', 'decision tree']
        for algo in algorithms:
            if algo in text_lower:
                context['mentioned_algorithms'].append(algo)
        
        return context
    
    def _is_algorithm_specific_question(self, user_message: str, context: Dict) -> bool:
        """
        Check if user is asking specific questions about algorithms
        """
        user_msg_lower = user_message.lower()
        
        # Specific algorithm names that should always be handled regardless of context
        specific_algorithms = [
            'xgboost', 'random forest', 'svm', 'neural network', 'logistic regression',
            'holt-winters', 'linear regression', 'decision tree', 'naive bayes',
            'k-means', 'dbscan', 'pca', 'lstm', 'cnn', 'bert', 'transformer'
        ]
        
        # Algorithm-specific keywords that should bypass consultation
        algorithm_keywords = [
            'nasƒ±l uygulanƒ±r', 'kar≈üƒ±la≈ütƒ±r', 'kod √∂rneƒüi', 'performans', 
            'implementasyon', 'hangi algoritma', 'detay', 'a√ßƒ±kla',
            '√∂rnek g√∂ster', 'nasƒ±l yapƒ±lƒ±r', 'kƒ±yasla', 'comparison', 'compare',
            'nasƒ±l √ßalƒ±≈üƒ±r', 'avantaj', 'dezavantaj', 'ne zaman kullan',
            'performans kar≈üƒ±la≈ütƒ±r', 'algoritma kar≈üƒ±la≈ütƒ±r', 'hangisi daha iyi'
        ]
        
        # Check for specific algorithm names (these are handled regardless of context)
        contains_specific_algo = any(algo in user_msg_lower for algo in specific_algorithms)
        
        # Check for algorithm-specific keywords
        contains_algo_keyword = any(keyword in user_msg_lower for keyword in algorithm_keywords)
        
        # If user mentions specific algorithm, handle immediately
        if contains_specific_algo:
            return True
            
        # For general algorithm questions, we're more flexible now
        # Performance comparison and code examples should always be handled
        if contains_algo_keyword:
            # These specific types should always be handled
            if any(word in user_msg_lower for word in ['performans', 'kar≈üƒ±la≈ütƒ±r', 'kod √∂rneƒüi', 'nasƒ±l uygulanƒ±r']):
                return True
            # For other algorithm keywords, require some context
            has_minimum_info = context.get('project_type') is not None
            return has_minimum_info
        
        return False
    
    def _handle_algorithm_question(self, user_message: str, context: Dict) -> Dict:
        """
        Handle specific algorithm questions without restarting consultation
        """
        user_msg_lower = user_message.lower()
        
        # Code example requests
        if 'kod √∂rneƒüi' in user_msg_lower or 'nasƒ±l uygulanƒ±r' in user_msg_lower:
            return self._generate_code_example(user_message, context)
        
        # Performance comparison requests
        elif 'performans' in user_msg_lower or 'kar≈üƒ±la≈ütƒ±r' in user_msg_lower:
            return self._generate_performance_comparison(context)
        
        # Algorithm explanation requests - expanded keywords
        elif any(word in user_msg_lower for word in ['detay', 'a√ßƒ±kla', 'nedir', 'nasƒ±l √ßalƒ±≈üƒ±r', 'ne yapar', 'avantaj', 'dezavantaj', 'ne zaman kullan', 'bilgi', 'hakkƒ±nda', 'anlat', '√∂ƒüren']):
            return self._generate_algorithm_explanation(user_message, context)
        
        # Default: ask for clarification
        else:
            return {
                "response": "ü§î Hangi algoritma hakkƒ±nda bilgi almak istiyorsunuz?\n\nPop√ºler se√ßenekler:\n‚Ä¢ K-means\n‚Ä¢ Random Forest\n‚Ä¢ XGBoost\n‚Ä¢ SVM\n‚Ä¢ Neural Networks\n\nHangisi hakkƒ±nda detay istiyorsunuz?",
                "suggestions": [
                    "K-means hakkƒ±nda bilgi ver",
                    "Random Forest nasƒ±l √ßalƒ±≈üƒ±r?",
                    "XGBoost algoritmasƒ± nedir?",
                    "SVM a√ßƒ±kla"
                ],
                "success": True
            }
    
    def _generate_code_example(self, user_message: str, context: Dict) -> Dict:
        """
        Generate code examples using GPT-4 or enhanced fallback system
        """
        # Try GPT-4 first for personalized code examples
        if self.openai_enabled and self.openai_client:
            try:
                return self._generate_gpt4_code_example(user_message, context)
            except Exception as e:
                print(f"‚ö†Ô∏è GPT-4 code generation failed, using template: {e}")
        
        # Fallback to template system
        return self._generate_template_code_example(user_message, context)
    
    def _generate_gpt4_code_example(self, user_message: str, context: Dict) -> Dict:
        """
        Generate personalized code examples using GPT-4
        """
        project_type = context.get('project_type', 'classification')
        data_size = context.get('data_size', 'medium')
        
        # Detect which algorithm user is asking about
        user_msg_lower = user_message.lower()
        algorithm = "genel"
        
        for algo in ['xgboost', 'random forest', 'svm', 'neural network', 'logistic regression', 'holt-winters', 'linear regression']:
            if algo in user_msg_lower:
                algorithm = algo
                break
        
        context_info = f"""
Proje t√ºr√º: {project_type}
Veri boyutu: {data_size}
Veri t√ºr√º: {context.get('data_type', 'numerical')}
ƒ∞stenilen algoritma: {algorithm}
Kullanƒ±cƒ± sorusu: "{user_message}"
"""
        
        prompt = f"""
Sen senior-level bir makine √∂ƒürenmesi uzmanƒ± ve Python geli≈ütiricisisin. Kullanƒ±cƒ±ya industry-standard, production-ready kod √∂rnekleri sunuyorsun.

{context_info}

L√ºtfen profesyonel bir danƒ±≈üman gibi:

üìã **Kod Kalitesi:**
- Clean, readable ve well-documented Python kodu yaz
- Best practices ve design patterns kullan
- Error handling ve edge case'leri dahil et
- Type hints ve docstring'ler ekle

üéØ **Algoritma Se√ßimi:**
- Projenin gereksinimlerine g√∂re en optimal algoritmalarƒ± √∂ner
- Hyperparameter tuning stratejileri sun
- Performance optimization ipu√ßlarƒ± ver
- Cross-validation ve model evaluation detaylarƒ± ekle

üí° **A√ßƒ±klamalar:**
- Teknik detaylarƒ± paragraf halinde a√ßƒ±kla
- Algoritmanƒ±n √ßalƒ±≈üma prensiplerini anlat
- Ne zaman hangi algoritmanƒ±n kullanƒ±lacaƒüƒ±nƒ± belirt
- Production environment i√ßin deployment ipu√ßlarƒ± ver

üöÄ **Professional Touch:**
- Industry best practices dahil et
- Scalability ve maintainability dikkate al
- Memory ve computational efficiency √∂nerileri sun
- Real-world kullanƒ±m senaryolarƒ±nƒ± anlat

Yanƒ±tƒ±n hem teknik derinlikte hem de kolayca uygulanabilir olsun. Senior developer seviyesinde kod ve a√ßƒ±klama bekliyorum.
"""
        
        messages = [
            {"role": "system", "content": prompt},
            {"role": "user", "content": f"Bu proje i√ßin {algorithm} algoritmasƒ±nƒ±n Python implementasyonunu ve a√ßƒ±klamasƒ±nƒ± verir misin?"}
        ]
        
        response = self.openai_client.chat.completions.create(
            model="gpt-3.5-turbo",  # Use the latest GPT-3.5 Turbo model for best quality
            messages=messages,
            max_tokens=1500,  # Increased for more detailed responses
            temperature=0.2   # Lower temperature for more consistent professional responses
        )
        
        gpt_response = response.choices[0].message.content
        
        suggestions = [
            "Hiperparametre optimizasyonu",
            "Cross-validation ekleme",
            "Feature engineering ipu√ßlarƒ±",
            "Ba≈üka algoritma kodu"
        ]
        
        return {
            "response": gpt_response,
            "suggestions": suggestions,
            "success": True,
            "ai_powered": True
        }
    
    def _generate_template_code_example(self, user_message: str, context: Dict) -> Dict:
        """
        Enhanced template-based code examples with detailed explanations
        """
        project_type = context.get('project_type', 'classification')
        
        if 'xgboost' in user_message.lower() or 'random forest' in user_message.lower():
            algo_name = 'XGBoost' if 'xgboost' in user_message.lower() else 'Random Forest'
            
            if project_type == 'classification':
                code_example = f"""**{algo_name} ile Sƒ±nƒ±flandƒ±rma - Detaylƒ± Uygulama:**

Bu algoritma {context.get('data_size', 'orta')} boyuttaki veri setiniz i√ßin m√ºkemmel bir se√ßim. Hem y√ºksek performans hem de g√ºvenilirlik sunar.

```python
# Gerekli k√ºt√ºphaneleri y√ºkleme
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as plt

# Veri y√ºkleme ve ilk inceleme
df = pd.read_csv('your_data.csv')
print(f"Veri seti boyutu: {{df.shape}}")
print(f"Eksik deƒüer sayƒ±sƒ±: {{df.isnull().sum().sum()}}")

# √ñzellik ve hedef deƒüi≈ükenleri ayƒ±rma
X = df.drop('target_column', axis=1)  # Hedef s√ºtununuzun adƒ±nƒ± yazƒ±n
y = df['target_column']

# Veriyi eƒüitim ve test olarak b√∂lme
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Random Forest modelini olu≈üturma ve eƒüitme
# n_estimators: Aƒüa√ß sayƒ±sƒ± (daha fazla = daha iyi performans ama yava≈ü)
# max_depth: Aƒüa√ßlarƒ±n maksimum derinliƒüi (overfitting'i kontrol eder)
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    random_state=42,
    n_jobs=-1  # T√ºm CPU'larƒ± kullan
)

# Modeli eƒüitme
print("Model eƒüitiliyor...")
rf_model.fit(X_train, y_train)

# Tahmin yapma
y_pred = rf_model.predict(X_test)
y_pred_proba = rf_model.predict_proba(X_test)

# Performans deƒüerlendirme
accuracy = accuracy_score(y_test, y_pred)
print(f"Doƒüruluk oranƒ±: {{accuracy:.3f}}")

# Detaylƒ± performans raporu
print("\\nDetaylƒ± Performans Raporu:")
print(classification_report(y_test, y_pred))

# Cross-validation ile daha g√ºvenilir performans √∂l√ß√ºm√º
cv_scores = cross_val_score(rf_model, X, y, cv=5)
print(f"\\n5-Fold CV Ortalama Doƒüruluk: {{cv_scores.mean():.3f}} (+/- {{cv_scores.std()*2:.3f}})")

# √ñzellik √∂nemlerini g√∂r√ºnt√ºleme
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\\nEn √∂nemli √∂zellikler:")
print(feature_importance.head(10))
```

**√ñnemli ƒ∞pu√ßlarƒ±:**

Veri setinizin boyutuna g√∂re parametreleri ayarlayƒ±n. K√º√ß√ºk veri setlerde n_estimators=50-100 yeterli, b√ºy√ºk veri setlerde 200-500 arasƒ± deneyebilirsiniz. max_depth parametresi overfitting'i kontrol eder - ba≈ülangƒ±√ß i√ßin 10-15 arasƒ±nda deneyin.

Model eƒüitildikten sonra feature_importance deƒüerleriyle hangi √∂zelliklerin en √ßok etkili olduƒüunu g√∂rebilirsiniz. Bu size veri anlama konusunda b√ºy√ºk insight verir."""
            else:
                code_example = f"""**{algo_name} ile Regresyon - Kapsamlƒ± Uygulama:**

Sayƒ±sal tahmin problemleriniz i√ßin {algo_name} m√ºkemmel bir se√ßim. √ñzellikle {context.get('data_size', 'orta')} boyuttaki veri setlerde √ßok ba≈üarƒ±lƒ±.

```python
# Gerekli k√ºt√ºphaneler
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt

# Veri hazƒ±rlama
df = pd.read_csv('your_regression_data.csv')
X = df.drop('target_column', axis=1)
y = df['target_column']

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Model olu≈üturma - regresyon i√ßin optimize edilmi≈ü parametreler
rf_regressor = RandomForestRegressor(
    n_estimators=100,
    max_depth=15,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)

# Model eƒüitimi
rf_regressor.fit(X_train, y_train)

# Tahminler
y_pred = rf_regressor.predict(X_test)

# Performans metrikleri
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)

print(f"Model Performansƒ±:")
print(f"R¬≤ Score: {{r2:.3f}}")
print(f"RMSE: {{rmse:.3f}}")
print(f"MAE: {{mae:.3f}}")

# Tahmin vs Ger√ßek deƒüerler grafiƒüi
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred, alpha=0.6)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Ger√ßek Deƒüerler')
plt.ylabel('Tahmin Edilen Deƒüerler')
plt.title('Tahmin vs Ger√ßek Deƒüerler')
plt.show()
```

Bu kod size hem model performansƒ±nƒ± hem de tahminlerin g√∂rsel analizini saƒülar. R¬≤ deƒüeri 0.8'in √ºst√ºndeyse modeliniz √ßok ba≈üarƒ±lƒ± demektir."""
        else:
            code_example = f"""**Genel Machine Learning Pipeline - {project_type.title()} i√ßin:**

Projeniz i√ßin kapsamlƒ± bir ba≈ülangƒ±√ß ≈üablonu hazƒ±rladƒ±m. Bu kod yapƒ±sƒ±nƒ± temel alarak istediƒüiniz algoritmalarƒ± deneyebilirsiniz.

```python
# Temel k√ºt√ºphaneler
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Veri Y√ºkleme ve ƒ∞nceleme
print("=== VERƒ∞ ANALƒ∞Zƒ∞ ===")
df = pd.read_csv('your_data.csv')
print(f"Veri boyutu: {{df.shape}}")
print(f"S√ºtunlar: {{list(df.columns)}}")
print(f"\\nVeri tipleri:\\n{{df.dtypes}}")
print(f"\\nEksik deƒüerler:\\n{{df.isnull().sum()}}")

# 2. Veri √ñn ƒ∞≈üleme
print("\\n=== VERƒ∞ √ñN ƒ∞≈ûLEME ===")

# Kategorik deƒüi≈ükenleri encode etme
categorical_columns = df.select_dtypes(include=['object']).columns
for col in categorical_columns:
    if col != 'target_column':  # Hedef deƒüi≈üken deƒüilse
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col].astype(str))

# √ñzellik ve hedef ayƒ±rma
X = df.drop('target_column', axis=1)
y = df['target_column']

# Verileri normalize etme (√∂nemli!)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. Model Se√ßimi ve Eƒüitimi
print("\\n=== MODEL Eƒûƒ∞Tƒ∞Mƒ∞ ===")
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# Buraya istediƒüiniz algoritmanƒ±n kodunu ekleyebilirsiniz
# √ñrnek: RandomForestClassifier, SVM, XGBoost vb.

print("Model ba≈üarƒ±yla eƒüitildi!")
print("≈ûimdi istediƒüiniz algoritma kodunu ekleyebilirsiniz.")
```

Bu temel yapƒ±yƒ± kullanarak istediƒüiniz algoritmanƒ±n detaylƒ± kodunu sorabilirsiniz. Hangi algoritma ile devam etmek istersiniz?"""
        
        return {
            "response": code_example,
            "suggestions": [
                "XGBoost kodu",
                "SVM implementasyonu",
                "Hiperparametre optimizasyonu",
                "Cross-validation ekleme"
            ],
            "success": True
        }
    
    def _generate_performance_comparison(self, context: Dict) -> Dict:
        """
        Generate performance comparison between algorithms
        """
        project_type = context.get('project_type', 'classification')
        data_size = context.get('data_size', 'medium')
        
        if project_type == 'classification':
            comparison = """Sƒ±nƒ±flandƒ±rma Algoritmalarƒ± Kar≈üƒ±la≈ütƒ±rmasƒ±:

1. Logistic Regression
   - Doƒüruluk: Orta
   - Hƒ±z: √áok hƒ±zlƒ±
   - Anla≈üƒ±labilirlik: √áok kolay
   - En iyi: K√º√ß√ºk veri setleri

2. Random Forest
   - Doƒüruluk: ƒ∞yi
   - Hƒ±z: Orta
   - Anla≈üƒ±labilirlik: Kolay
   - En iyi: Genel kullanƒ±m

3. XGBoost
   - Doƒüruluk: √áok iyi
   - Hƒ±z: Orta
   - Anla≈üƒ±labilirlik: Zor
   - En iyi: B√ºy√ºk veri setleri

4. SVM
   - Doƒüruluk: ƒ∞yi
   - Hƒ±z: Yava≈ü
   - Anla≈üƒ±labilirlik: Zor
   - En iyi: K√º√ß√ºk, karma≈üƒ±k veriler

"""
            if data_size == 'small':
                comparison += "K√º√ß√ºk veri setiniz i√ßin: Logistic Regression veya SVM √∂nerilir."
            elif data_size == 'large':
                comparison += "B√ºy√ºk veri setiniz i√ßin: XGBoost veya Random Forest √∂nerilir."
            else:
                comparison += "Genel kullanƒ±m i√ßin: Random Forest ile ba≈ülayƒ±n."
        else:
            comparison = """Regresyon Algoritmalarƒ± Kar≈üƒ±la≈ütƒ±rmasƒ±:

1. Linear Regression
   - Doƒüruluk: Orta
   - Hƒ±z: √áok hƒ±zlƒ±
   - Anla≈üƒ±labilirlik: √áok kolay

2. Random Forest
   - Doƒüruluk: ƒ∞yi
   - Hƒ±z: Orta
   - Anla≈üƒ±labilirlik: Kolay

3. XGBoost
   - Doƒüruluk: √áok iyi
   - Hƒ±z: Orta
   - Anla≈üƒ±labilirlik: Zor

En iyi se√ßim veri setinizin boyutuna baƒülƒ±dƒ±r."""
        
        return {
            "response": comparison,
            "suggestions": [
                "Hangi metrik kullanmalƒ±yƒ±m?",
                "Cross-validation nasƒ±l yapƒ±lƒ±r?",
                "Hiperparametre optimizasyonu"
            ],
            "success": True
        }
    
    def _generate_algorithm_explanation(self, user_message: str, context: Dict) -> Dict:
        """
        Generate detailed explanation about specific algorithms
        """
        explanations = {
            'xgboost': """
üèÜ **XGBoost (Extreme Gradient Boosting):**

**Ne yapar?**
Zayƒ±f √∂ƒürenicileri (karar aƒüa√ßlarƒ±) sƒ±ralƒ± olarak birle≈ütirerek g√º√ßl√º bir model olu≈üturur.

**Avantajlarƒ±:**
‚úÖ √áok y√ºksek doƒüruluk
‚úÖ Eksik verilerle ba≈üa √ßƒ±kabilir
‚úÖ √ñzellik √∂nemini g√∂sterir
‚úÖ B√ºy√ºk veri setlerinde hƒ±zlƒ±

**Dezavantajlarƒ±:**
‚ùå Karma≈üƒ±k hiperparametre ayarƒ±
‚ùå Overfitting eƒüilimi
‚ùå Yorumlanmasƒ± zor

**Ne zaman kullanmalƒ±?**
‚Ä¢ Maksimum performans istediƒüinizde
‚Ä¢ Yarƒ±≈ümalarda (Kaggle'da √ßok pop√ºler)
‚Ä¢ B√ºy√ºk ve karma≈üƒ±k veri setlerinde
""",
            'random forest': """
üå≥ **Random Forest:**

**Ne yapar?**
Bir√ßok karar aƒüacƒ±nƒ± aynƒ± anda eƒüitir ve sonu√ßlarƒ±nƒ± birle≈ütirir.

**Avantajlarƒ±:**
‚úÖ Overfitting'e diren√ßli
‚úÖ Deƒüi≈üken √∂nemini g√∂sterir
‚úÖ Eksik verilerle √ßalƒ±≈üabilir
‚úÖ Hem classification hem regression

**Dezavantajlarƒ±:**
‚ùå B√ºy√ºk model boyutu
‚ùå Ger√ßek zamanlƒ± tahminlerde yava≈ü olabilir

**Ne zaman kullanmalƒ±?**
‚Ä¢ G√ºvenilir bir ba≈ülangƒ±√ß algoritmasƒ± olarak
‚Ä¢ √ñzellik √∂nemini anlamak i√ßin
‚Ä¢ Hem hƒ±z hem doƒüruluk istediƒüinizde
""",
            'k-means': """
üéØ **K-Means Clustering:**

**Ne yapar?**
Verileri √∂nceden belirlenen sayƒ±da (k) gruba b√∂ler. Her grup bir merkez etrafƒ±nda toplanƒ±r.

**Avantajlarƒ±:**
‚úÖ Basit ve hƒ±zlƒ±
‚úÖ B√ºy√ºk veri setlerinde etkili
‚úÖ Yorumlanmasƒ± kolay
‚úÖ Bellek kullanƒ±mƒ± d√º≈ü√ºk

**Dezavantajlarƒ±:**
‚ùå K sayƒ±sƒ±nƒ± √∂nceden belirlemelisiniz
‚ùå K√ºresel olmayan ≈üekillerde zayƒ±f
‚ùå Aykƒ±rƒ± deƒüerlere hassas
‚ùå Farklƒ± boyutlardaki gruplarƒ± ayƒ±rmada zor

**Ne zaman kullanmalƒ±?**
‚Ä¢ M√º≈üteri segmentasyonu
‚Ä¢ Veri √∂n i≈üleme i√ßin
‚Ä¢ G√∂r√ºnt√º i≈ülemede renk azaltma
‚Ä¢ Pazarlama analizi

**Python √ñrneƒüi:**
```python
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Model olu≈üturma
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(data)

# Sonu√ßlarƒ± g√∂rselle≈ütirme
plt.scatter(data[:, 0], data[:, 1], c=clusters)
plt.scatter(kmeans.cluster_centers_[:, 0], 
           kmeans.cluster_centers_[:, 1], 
           marker='x', s=200, c='red')
plt.show()
```
""",
            'svm': """
‚ö° **Support Vector Machine (SVM):**

**Ne yapar?**
Sƒ±nƒ±flar arasƒ±nda en geni≈ü marjinli ayƒ±rƒ±cƒ± √ßizgiyi/d√ºzlemi bulur.

**Avantajlarƒ±:**
‚úÖ Y√ºksek boyutlu verilerde etkili
‚úÖ Bellek kullanƒ±mƒ± verimli
‚úÖ √áok √ße≈üitli kernel fonksiyonlarƒ±
‚úÖ Overfitting'e diren√ßli

**Dezavantajlarƒ±:**
‚ùå B√ºy√ºk veri setlerinde yava≈ü
‚ùå Hiperparametre ayarƒ± kritik
‚ùå Olasƒ±lƒ±k tahmini yapmaz
‚ùå Noise'a hassas

**Ne zaman kullanmalƒ±?**
‚Ä¢ Metin sƒ±nƒ±flandƒ±rma
‚Ä¢ G√∂r√ºnt√º tanƒ±ma
‚Ä¢ Y√ºksek boyutlu veriler
‚Ä¢ K√º√ß√ºk-orta boyutlu veri setleri

**Python √ñrneƒüi:**
```python
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV

# Model olu≈üturma
svm = SVC(kernel='rbf', random_state=42)

# Hiperparametre optimizasyonu
param_grid = {'C': [0.1, 1, 10], 'gamma': [0.01, 0.1, 1]}
grid_search = GridSearchCV(svm, param_grid, cv=5)
grid_search.fit(X_train, y_train)

# En iyi model
best_svm = grid_search.best_estimator_
```
""",
            'holt-winters': """
üìà **Holt-Winters (Triple Exponential Smoothing):**

**Ne yapar?**
Zaman serisi verilerindeki trend, sezonluk ve seviye bile≈üenlerini ayrƒ± ayrƒ± modelleyerek gelecek tahminleri yapar.

**Avantajlarƒ±:**
‚úÖ Sezonsal verilerde √ßok ba≈üarƒ±lƒ±
‚úÖ Trend ve mevsimsellik yakalar
‚úÖ Yorumlanabilir sonu√ßlar
‚úÖ Hesaplama a√ßƒ±sƒ±ndan hƒ±zlƒ±

**Dezavantajlarƒ±:**
‚ùå Sadece zaman serisi verileri i√ßin
‚ùå Ani deƒüi≈üimlere kar≈üƒ± hassas
‚ùå Parametrelerin doƒüru ayarlanmasƒ± gerekli

**Ne zaman kullanmalƒ±?**
‚Ä¢ Mevsimsel satƒ±≈ü tahminleri
‚Ä¢ Enerji t√ºketim projeksiyonlarƒ±
‚Ä¢ D√ºzenli d√∂ng√ºsel veriler
‚Ä¢ Kƒ±sa-orta vadeli tahminler

**Python √ñrneƒüi:**
```python
from statsmodels.tsa.holtwinters import ExponentialSmoothing

# Model olu≈üturma
model = ExponentialSmoothing(data, trend='add', seasonal='add')
fitted_model = model.fit()

# Tahmin yapma
forecast = fitted_model.forecast(steps=12)
```
"""
        }
        
        user_msg_lower = user_message.lower()
        
        # Check for algorithm mentions with better matching
        for algo, explanation in explanations.items():
            algo_variants = [algo, algo.replace('-', ''), algo.replace(' ', '')]
            if any(variant in user_msg_lower for variant in algo_variants):
                return {
                    "response": explanation,
                    "suggestions": [
                        f"{algo.title()} kod √∂rneƒüi",
                        "Hiperparametre ayarlarƒ±",
                        "Diƒüer algoritmalarla kar≈üƒ±la≈ütƒ±r"
                    ],
                    "success": True
                }
        
        # Generic algorithm explanation - check if any algorithm mentioned in message
        mentioned_algorithms = []
        for algo in ['xgboost', 'random forest', 'svm', 'neural network', 'logistic regression', 'k-means', 'kmeans', 'dbscan', 'optics']:
            if algo in user_msg_lower or algo.replace('-', '').replace(' ', '') in user_msg_lower.replace('-', '').replace(' ', ''):
                mentioned_algorithms.append(algo)
        
        if mentioned_algorithms:
            algo = mentioned_algorithms[0]
            return {
                "response": f"ü§ñ {algo.title()} hakkƒ±nda bilgi istiyorsunuz. Size bu algoritmanƒ±n detaylarƒ±nƒ± a√ßƒ±klayabilirim. Hangi konuda daha fazla bilgi istiyorsunuz?",
                "suggestions": [
                    f"{algo.title()} nasƒ±l √ßalƒ±≈üƒ±r?",
                    f"{algo.title()} avantajlarƒ± neler?",
                    f"{algo.title()} kod √∂rneƒüi",
                    "Diƒüer algoritmalarla kar≈üƒ±la≈ütƒ±r"
                ],
                "success": True
            }
        else:
            return {
                "response": "ü§ñ Hangi algoritma hakkƒ±nda bilgi almak istiyorsunuz? Size detaylarƒ±nƒ± a√ßƒ±klayabilirim.",
                "suggestions": [
                    "XGBoost nedir?",
                    "Random Forest a√ßƒ±kla",
                    "SVM nasƒ±l √ßalƒ±≈üƒ±r?",
                    "K-means hakkƒ±nda bilgi ver"
                ],
                "success": True
            }
    
    def _should_recommend_algorithms(self, context: Dict) -> bool:
        """
        Determine if we have enough information to make algorithm recommendations
        """
        required_info = ['project_type', 'data_size', 'data_type']
        
        # For classification, we're more flexible about class_count
        # We can still give recommendations without it
        
        gathered_info = [key for key in required_info if context.get(key) is not None]
        
        print(f"üìã Required: {required_info}")
        print(f"üìã Gathered: {gathered_info}")
        
        # If we have project_type, we can give basic recommendations
        # Even more flexible: just 1 piece of info is enough for basic suggestions
        return len(gathered_info) >= 1
    
    def _generate_algorithm_recommendations(self, user_message: str, context: Dict) -> Dict:
        """
        Generate algorithm recommendations using our custom model + advanced AI explanation
        """
        try:
            # Use our algorithm recommender
            recommendations = self.algorithm_recommender.get_recommendations(
                project_type=context.get('project_type', 'classification'),
                data_size=context.get('data_size', 'medium'),
                data_type=context.get('data_type', 'numerical'),
                complexity_preference='medium'
            )
            
            # Always use our advanced AI system for better explanations
            return self._advanced_ai_recommendations(user_message, context, recommendations)
                
        except Exception as e:
            print(f"‚ùå Error in recommendations: {e}")
            return self._get_emergency_fallback()
    
    def _advanced_ai_recommendations(self, user_message: str, context: Dict, recommendations: List[Dict]) -> Dict:
        """
        Hybrid AI system: GPT-4 + Custom Algorithm Model for personalized recommendations
        """
        try:
            if not recommendations:
                return self._get_emergency_fallback()
            
            # Get top 3 recommendations
            top_algos = recommendations[:3]
            
            # Try GPT-4 first for detailed paragraph responses
            if self.openai_enabled and self.openai_client:
                try:
                    return self._generate_gpt4_recommendations(user_message, context, top_algos)
                except Exception as e:
                    print(f"‚ö†Ô∏è GPT-4 failed, using advanced fallback: {e}")
            
            # Fallback to enhanced template system
            return self._generate_enhanced_template_recommendations(user_message, context, top_algos)
                
        except Exception as e:
            print(f"‚ùå Advanced AI recommendation error: {e}")
            return self._template_recommendations(context, recommendations)
    
    def _generate_gpt4_recommendations(self, user_message: str, context: Dict, recommendations: List[Dict]) -> Dict:
        """
        Generate detailed paragraph recommendations using GPT-4
        """
        try:
            # Prepare algorithm details for GPT-4
            algo_details = []
            for algo in recommendations:
                algo_details.append(f"- {algo['algorithm']}: G√ºven skoru {algo['confidence_score']:.1f}/5.0")
            
            # Create context string
            project_info = f"""
Proje t√ºr√º: {context.get('project_type', 'Belirsiz')}
Veri boyutu: {context.get('data_size', 'Belirsiz')}
Veri t√ºr√º: {context.get('data_type', 'Belirsiz')}
Sƒ±nƒ±f sayƒ±sƒ±: {context.get('class_count', 'Belirsiz')}

√ñnerilen algoritmalar:
{chr(10).join(algo_details)}

Kullanƒ±cƒ± mesajƒ±: "{user_message}"
"""
            
            # GPT-4 prompt
            messages = [
                {"role": "system", "content": self.algorithm_expert_prompt},
                {"role": "user", "content": f"""
Yukarƒ±daki proje bilgilerine dayanarak algoritma √∂nerilerimi paragraf halinde detaylƒ± a√ßƒ±kla.

{project_info}

L√ºtfen:
1. Her algoritmayƒ± neden √∂nerdiƒüimi paragraf halinde a√ßƒ±kla
2. Projenin √∂zelliklerine g√∂re avantajlarƒ± belirt
3. Pratik uygulama ipu√ßlarƒ± ver
4. Hangi algoritma ile ba≈ülanmasƒ±nƒ± √∂neriyorsan belirt
5. Samimi ve anla≈üƒ±lƒ±r bir dille yaz

Kƒ±sa maddeler yerine akƒ±cƒ± paragraflar halinde cevap ver.
"""}
            ]
            
            response = self.openai_client.chat.completions.create(
                model="gpt-3.5-turbo",  # Use GPT-3.5 Turbo for superior algorithmic advice and detailed explanations
                messages=messages,
                max_tokens=800,
                temperature=0.7
            )
            
            gpt_response = response.choices[0].message.content
            
            # Generate smart suggestions
            suggestions = []
            if recommendations:
                suggestions.append(f"{recommendations[0]['algorithm']} kod √∂rneƒüi")
                suggestions.append("Performans kar≈üƒ±la≈ütƒ±rmasƒ± yap")
                suggestions.append("Hiperparametre optimizasyonu")
                if len(recommendations) > 1:
                    suggestions.append(f"{recommendations[1]['algorithm']} detaylarƒ±")
            
            return {
                "response": gpt_response,
                "suggestions": suggestions,
                "success": True,
                "ai_powered": True
            }
            
        except Exception as e:
            print(f"‚ùå GPT-4 recommendation error: {e}")
            raise e
    
    def _generate_enhanced_template_recommendations(self, user_message: str, context: Dict, recommendations: List[Dict]) -> Dict:
        """
        Enhanced fallback system with paragraph-style responses
        """
        project_type = context.get('project_type') or 'machine learning'
        data_size = context.get('data_size') or 'medium' 
        data_type = context.get('data_type') or 'numerical'
        
        # Track recommended algorithms
        for rec in recommendations:
            algo_name = rec.get('algorithm', '').lower()
            if algo_name and algo_name not in self.conversation_context['discussed_algorithms']:
                self.conversation_context['discussed_algorithms'].append(algo_name)
        
        # Create paragraph-style introduction
        if project_type == 'classification':
            intro = f"Sƒ±nƒ±flandƒ±rma projeniz i√ßin detaylƒ± analiz yaptƒ±m ve size en uygun algoritmalarƒ± se√ßtim. {data_size.title()} boyuttaki {data_type} veriniz i√ßin √∂zellikle etkili olacak √ß√∂z√ºmler buldum."
        elif project_type == 'regression':
            intro = f"Regresyon analiziniz i√ßin algoritma se√ßiminde dikkat ettiƒüim temel fakt√∂rler veri boyutunuz ({data_size}) ve veri tipinizdir ({data_type}). Bu √∂zelliklere g√∂re en ba≈üarƒ±lƒ± sonu√ßlarƒ± verecek algoritmalarƒ± √∂nceledim."
        else:
            intro = f"Projeniz i√ßin uygun algoritma se√ßiminde veri karakteristiklerinizi g√∂z √∂n√ºnde bulundurdum. {data_size.title()} boyuttaki {data_type} verileriniz i√ßin optimize edilmi≈ü √∂nerilerimi payla≈üƒ±yorum."
        
        response = intro + "\n\n"
        
        # Detailed algorithm explanations in paragraph form
        for i, algo in enumerate(recommendations[:3], 1):
            algo_name = algo['algorithm']
            confidence = algo['confidence_score']
            
            if i == 1:
                response += f"**{algo_name}** algoritmasƒ±nƒ± ilk sƒ±rada √∂neriyorum √ß√ºnk√º {confidence:.1f}/5.0 g√ºven skoru ile projenize en uygun se√ßenek. "
            else:
                response += f"**{algo_name}** da {confidence:.1f}/5.0 g√ºven skoru ile g√º√ßl√º bir alternatif. "
            
            # Get detailed explanation
            explanation = self._get_enhanced_explanation(algo_name, context)
            response += explanation + "\n\n"
        
        # Contextual advice paragraph
        if data_size == 'small':
            response += "K√º√ß√ºk veri setiniz g√∂z √∂n√ºnde bulundurulduƒüunda, overfitting riskini minimize etmek i√ßin daha basit modelleri tercih etmenizi √∂neriyorum. Ba≈ülangƒ±√ß i√ßin ilk √∂nerdiƒüim algoritmayƒ± deneyip sonu√ßlarƒ± deƒüerlendirdikten sonra diƒüer se√ßeneklere ge√ßebilirsiniz."
        elif data_size == 'large':
            response += "B√ºy√ºk veri setinizin avantajƒ±nƒ± kullanarak daha karma≈üƒ±k modelleri g√ºvenle deneyebilirsiniz. Bu durumda ensemble metotlarƒ± ve derin √∂ƒürenme yakla≈üƒ±mlarƒ± √∂zellikle etkili sonu√ßlar verebilir."
        else:
            response += "Orta boyuttaki veri setiniz i√ßin dengeli bir yakla≈üƒ±m √∂neriyorum. ƒ∞lk etapta daha basit algoritmalarla ba≈ülayƒ±p performans sonu√ßlarƒ±na g√∂re karma≈üƒ±klƒ±ƒüƒ± artƒ±rabilirsiniz."
        
        # Generate suggestions
        suggestions = [
            f"{recommendations[0]['algorithm']} nasƒ±l uygulanƒ±r?",
            "Performans kar≈üƒ±la≈ütƒ±rmasƒ±",
            "Kod √∂rnekleri ver",
            "Hangi metriƒüi kullanmalƒ±yƒ±m?"
        ]
        
        if len(recommendations) > 1:
            suggestions.append(f"{recommendations[1]['algorithm']} detaylarƒ±")
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
    
    def _get_simple_explanation(self, algorithm: str, context: Dict) -> str:
        """
        Get simple, clean explanation for each algorithm
        """
        explanations = {
            'XGBoost': "Y√ºksek doƒüruluk oranƒ±na sahip, g√º√ßl√º bir algoritma. √áoƒüu durumda √ßok iyi sonu√ßlar verir.",
            'Random Forest': "G√ºvenilir ve dengeli bir se√ßim. Overfitting yapmaz, sonu√ßlarƒ± yorumlamasƒ± kolay.",
            'Logistic Regression': "Basit ve hƒ±zlƒ±. Ba≈ülangƒ±√ß i√ßin ideal, sonu√ßlarƒ± anla≈üƒ±lƒ±r.",
            'SVM': "Karma≈üƒ±k veri ili≈ükilerini iyi yakalar. K√º√ß√ºk veri setlerinde ba≈üarƒ±lƒ±.",
            'Neural Network': "Karma≈üƒ±k problemleri √ß√∂zebilir. B√ºy√ºk veri setleri gerektir.",
            'Linear Regression': "Basit ve hƒ±zlƒ± regresyon algoritmasƒ±. Yorumlamasƒ± kolay.",
            'Decision Tree': "Anla≈üƒ±lmasƒ± kolay kural tabanlƒ± algoritma.",
            'Naive Bayes': "Hƒ±zlƒ± ve basit sƒ±nƒ±flandƒ±rma algoritmasƒ±.",
            'K-Means': "Veri gruplarƒ±nƒ± otomatik olarak bulur.",
            'DBSCAN': "G√ºr√ºlt√ºl√º verilerde grup bulma algoritmasƒ±.",
        }
        
        return explanations.get(algorithm, "G√ºvenilir bir makine √∂ƒürenmesi algoritmasƒ±.")
    
    def _get_algorithm_explanation(self, algorithm: str, context: Dict, confidence: float) -> str:
        """
        Get intelligent, contextual explanation for each algorithm
        """
        explanations = {
            'XGBoost': {
                'classification': "üèÜ Gradient boosting'in ≈üampiyonu! Karma≈üƒ±k ili≈ükileri yakalama konusunda uzman. Kaggle yarƒ±≈ümalarƒ±nƒ±n favorisi.",
                'regression': "üìà Sayƒ±sal tahminlerde √ßok g√º√ßl√º! Eksik verilerle bile ba≈üarƒ±lƒ± √ßalƒ±≈üƒ±r.",
                'general': "‚ö° Hƒ±zlƒ±, g√º√ßl√º ve esnek. √áoƒüu problemde harika sonu√ßlar verir."
            },
            'Random Forest': {
                'classification': "üå≥ Karar aƒüa√ßlarƒ±nƒ±n g√ºc√ºn√º birle≈ütirir. Overfitting'e kar≈üƒ± diren√ßli ve yorumlanabilir.",
                'regression': "üå≤ Stabil tahminler yapar. √ñzellik √∂nemini g√∂sterir.",
                'general': "üîí G√ºvenilir ve robust. Hemen hemen her veri t√ºr√ºyle √ßalƒ±≈üƒ±r."
            },
            'Logistic Regression': {
                'classification': "üìä Basit ama etkili! ƒ∞kili sƒ±nƒ±flandƒ±rmada m√ºkemmel. Sonu√ßlarƒ± anlamak kolay.",
                'general': "‚ú® Hƒ±zlƒ± ve yorumlanabilir. Ba≈ülangƒ±√ß i√ßin ideal se√ßim."
            },
            'SVM': {
                'classification': "üéØ Karma≈üƒ±k veri sƒ±nƒ±rlarƒ±nƒ± √ßizer. Y√ºksek boyutlu verilerde ba≈üarƒ±lƒ±.",
                'general': "üí™ G√º√ßl√º matematik temeli. Kernel trick ile sihir yapar."
            },
            'Neural Network': {
                'classification': "üß† Beyin yapƒ±sƒ±nƒ± taklit eder. √áok karma≈üƒ±k pattern'leri √∂ƒürenebilir.",
                'general': "üöÄ Derin √∂ƒürenmenin kapƒ±sƒ±. B√ºy√ºk verilerle ≈üaha kalkar."
            }
        }
        
        project_type = context.get('project_type', 'general')
        
        if algorithm in explanations:
            if project_type in explanations[algorithm]:
                base_explanation = explanations[algorithm][project_type]
            else:
                base_explanation = explanations[algorithm]['general']
        else:
            base_explanation = "üîß G√ºvenilir bir algoritma. Projenizde iyi sonu√ßlar verebilir."
        
        # Add confidence-based comment
        if confidence >= 4.5:
            confidence_note = "‚úÖ Size √∂zel olarak optimize edilmi≈ü!"
        elif confidence >= 4.0:
            confidence_note = "üëç Verilerinizle uyumlu!"
        elif confidence >= 3.5:
            confidence_note = "üìù Denemeye deƒüer!"
        else:
            confidence_note = "ü§î Alternatif se√ßenek olabilir."
            
        return f"{base_explanation} {confidence_note}"
    
    def _generate_consultation_response(self, user_message: str, context: Dict) -> Dict:
        """
        Generate consultation questions using advanced AI to gather more information
        """
        # Always use our advanced AI system for better user experience
        return self._advanced_ai_consultation_response(user_message, context)
    
    def _advanced_ai_consultation_response(self, user_message: str, context: Dict) -> Dict:
        """
        Hybrid AI consultation: GPT-4 + template fallback for gathering project information
        """
        try:
            # Handle None or empty messages
            if user_message is None:
                user_message = ""
            
            # Try GPT-4 first for personalized consultation
            if self.openai_enabled and self.openai_client:
                try:
                    return self._generate_gpt4_consultation(user_message, context)
                except Exception as e:
                    print(f"‚ö†Ô∏è GPT-4 consultation failed, using template: {e}")
            
            # Fallback to enhanced template consultation
            return self._generate_template_consultation(user_message, context)
            
        except Exception as e:
            print(f"‚ùå Advanced AI consultation error: {e}")
            return self._template_consultation_response(context)
    
    def _generate_gpt4_consultation(self, user_message: str, context: Dict) -> Dict:
        """
        Generate personalized consultation using GPT-4
        """
        # Determine what information we still need
        missing_info = []
        if not context.get('project_type'):
            missing_info.append('proje t√ºr√º')
        if not context.get('data_size'):
            missing_info.append('veri boyutu')
        if not context.get('data_type'):
            missing_info.append('veri t√ºr√º')
        if context.get('project_type') == 'classification' and not context.get('class_count'):
            missing_info.append('sƒ±nƒ±f sayƒ±sƒ±')
        
        # Prepare context for GPT-4
        context_info = f"""
Mevcut proje bilgileri:
- Proje t√ºr√º: {context.get('project_type', 'Hen√ºz belirlenmedi')}
- Veri boyutu: {context.get('data_size', 'Hen√ºz belirlenmedi')}
- Veri t√ºr√º: {context.get('data_type', 'Hen√ºz belirlenmedi')}
- Sƒ±nƒ±f sayƒ±sƒ±: {context.get('class_count', 'Hen√ºz belirlenmedi')}

Eksik bilgiler: {', '.join(missing_info) if missing_info else 'Yok'}

Kullanƒ±cƒ± mesajƒ±: "{user_message}"
"""
        
        messages = [
            {"role": "system", "content": self.consultation_prompt},
            {"role": "user", "content": f"""
Bir kullanƒ±cƒ± algoritma danƒ±≈ümanlƒ±ƒüƒ± i√ßin geldi. A≈üaƒüƒ±daki bilgileri g√∂z √∂n√ºnde bulundurarak ona yardƒ±m et:

{context_info}

L√ºtfen:
1. Kullanƒ±cƒ±nƒ±n mesajƒ±na samimi ve paragraf halinde cevap ver
2. Eksik bilgileri nazik√ße sor ama zorlama
3. Projenin hedefini net anlayƒ±p doƒüru y√∂nlendir
4. Teknik terimlerden ka√ßƒ±n, sade konu≈ü
5. 2-3 paragraf halinde cevap ver

Kƒ±sa listeler yerine akƒ±cƒ± konu≈üma yap.
"""}
        ]
        
        response = self.openai_client.chat.completions.create(
            model="gpt-3.5-turbo",  # Use GPT-3.5 Turbo for consultation responses
            messages=messages,
            max_tokens=400,
            temperature=0.8
        )
        
        gpt_response = response.choices[0].message.content
        
        # Generate contextual suggestions
        suggestions = self._generate_consultation_suggestions(missing_info, context)
        
        return {
            "response": gpt_response,
            "suggestions": suggestions,
            "success": True,
            "ai_powered": True
        }
    
    def _generate_template_consultation(self, user_message: str, context: Dict) -> Dict:
        """
        Enhanced template-based consultation with paragraph responses
        """
        # Determine what information we still need
        missing_info = []
        if not context.get('project_type'):
            missing_info.append('project_type')
        if not context.get('data_size'):
            missing_info.append('data_size')
        if not context.get('data_type'):
            missing_info.append('data_type')
        if context.get('project_type') == 'classification' and not context.get('class_count'):
            missing_info.append('class_count')
        
        # Analyze user's message sentiment and content
        user_msg_lower = user_message.lower()
        
        # Generate paragraph-style responses
        if any(word in user_msg_lower for word in ['merhaba', 'selam', 'hello', 'hi']):
            if not context.get('project_type'):
                response = "Merhaba! Size en uygun makine √∂ƒürenmesi algoritmalarƒ±nƒ± bulmaya yardƒ±mcƒ± olmaktan memnuniyet duyarƒ±m. Projenizin detaylarƒ±nƒ± anlayarak size √∂zel √∂neriler geli≈ütirebilirim.\n\nHangi t√ºr bir problem √ß√∂zmek istediƒüinizi payla≈üabilir misiniz? Bu ≈üekilde size en uygun algoritmalarƒ± √∂nerebilirim."
                suggestions = [
                    "Veri sƒ±nƒ±flandƒ±rmasƒ± yapacaƒüƒ±m",
                    "Sayƒ±sal deƒüer tahmini yapmak istiyorum", 
                    "Veri k√ºmelerini gruplamaya ihtiyacƒ±m var"
                ]
            else:
                response = f"Merhaba! {context['project_type']} projesi √ºzerinde √ßalƒ±≈ütƒ±ƒüƒ±nƒ±zƒ± g√∂r√ºyorum, bu ger√ßekten ilgin√ß bir alan. Size en uygun algoritmalarƒ± √∂nerebilmek i√ßin birka√ß detay daha √∂ƒürenmem gerekiyor."
                suggestions = self._generate_consultation_suggestions(missing_info, context)
        
        elif not context.get('project_type'):
            response = "Projenizin amacƒ±nƒ± biraz daha detayƒ±na inmek istiyorum. Makine √∂ƒürenmesinde farklƒ± problem t√ºrleri i√ßin farklƒ± yakla≈üƒ±mlar gerekiyor ve size en uygun √ß√∂z√ºm√º sunabilmek i√ßin projenizin hedefini anlamam √∂nemli.\n\nHangi t√ºr bir sonu√ß elde etmeyi hedefliyorsunuz?"
            suggestions = [
                "Verileri kategorilere ayƒ±rma (sƒ±nƒ±flandƒ±rma)",
                "Sayƒ±sal deƒüer tahmin etme (regresyon)",
                "Veri gruplarƒ±nƒ± ke≈üfetme (k√ºmeleme)"
            ]
        
        elif not context.get('data_size'):
            response = f"{context['project_type'].title()} projesi harika bir se√ßim! Bu alandaki deneyimime dayanarak size √ßok etkili algoritmalar √∂nerebilirim. Ancak veri setinizin boyutu algoritma se√ßiminde kritik bir fakt√∂r.\n\nKa√ß tane veri kaydƒ±nƒ±z var? Bu bilgi sayesinde performans ve hƒ±z a√ßƒ±sƒ±ndan en uygun algoritmalarƒ± se√ßebilirim."
            suggestions = [
                "1000'den az kayƒ±t (k√º√ß√ºk veri)",
                "1000-10000 arasƒ± (orta boyut)",
                "10000'den fazla (b√ºy√ºk veri)"
            ]
        
        elif not context.get('data_type'):
            response = "Veri boyutunu √∂ƒürendiƒüim i√ßin te≈üekk√ºrler! ≈ûimdi veri t√ºr√ºn√º anlamam gerekiyor √ß√ºnk√º farklƒ± veri t√ºrleri i√ßin optimize edilmi≈ü algoritmalar var. Bu bilgi ile size en uygun ve verimli √ß√∂z√ºm√º √∂nerebilirim.\n\nVerileriniz hangi t√ºrde? Bu detay algoritma performansƒ±nƒ± doƒürudan etkiliyor."
            suggestions = [
                "Sayƒ±sal veriler (rakamlar, √∂l√ß√ºmler)",
                "Kategorik veriler (gruplar, etiketler)",
                "Metin verileri (yazƒ±lar, yorumlar)",
                "G√∂r√ºnt√º verileri (fotoƒüraflar, resimler)"
            ]
        
        elif context.get('project_type') == 'classification' and not context.get('class_count'):
            response = "Sƒ±nƒ±flandƒ±rma projesi i√ßin son bir √∂nemli detay kaldƒ±! Ka√ß farklƒ± kategori veya sƒ±nƒ±fƒ±nƒ±z olduƒüu algoritma se√ßimini etkileyecek. ƒ∞kili sƒ±nƒ±flandƒ±rma ile √ßok sƒ±nƒ±flƒ± problemler farklƒ± yakla≈üƒ±mlar gerektiriyor.\n\nVerilerinizi ka√ß kategoriye ayƒ±rmayƒ± planlƒ±yorsunuz?"
            suggestions = [
                "2 kategori (ikili sƒ±nƒ±flandƒ±rma)",
                "3-10 kategori arasƒ± (√ßoklu sƒ±nƒ±f)",
                "10'dan fazla kategori (karma≈üƒ±k sƒ±nƒ±flandƒ±rma)"
            ]
        
        else:
            # We have enough info, this shouldn't happen
            response = "Harika! Proje detaylarƒ±nƒ±zƒ± topladƒ±m ve size √∂zel algoritma √∂nerilerini hazƒ±rlƒ±yorum. Bir an i√ßinde en uygun se√ßenekleri sunacaƒüƒ±m."
            suggestions = ["Algoritma √∂nerilerini g√∂ster"]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
    
    def _generate_consultation_suggestions(self, missing_info: List[str], context: Dict) -> List[str]:
        """
        Generate contextual suggestions based on missing information and context
        """
        if 'proje t√ºr√º' in missing_info or 'project_type' in missing_info:
            return [
                "Sƒ±nƒ±flandƒ±rma projesi yapƒ±yorum",
                "Regresyon analizi yapmak istiyorum",
                "Veri k√ºmeleme yapacaƒüƒ±m"
            ]
        elif 'veri boyutu' in missing_info or 'data_size' in missing_info:
            return [
                "K√º√ß√ºk veri setim var (1000<)",
                "Orta boyut veri (1000-10000)",
                "B√ºy√ºk veri setim var (10000+)"
            ]
        elif 'veri t√ºr√º' in missing_info or 'data_type' in missing_info:
            return [
                "Sayƒ±sal verilerle √ßalƒ±≈üƒ±yorum",
                "Kategorik verilerim var",
                "Metin verileri i≈üliyorum"
            ]
        else:
            return [
                "Algoritma √∂nerilerini ver",
                "Performans kar≈üƒ±la≈ütƒ±rmasƒ± yap",
                "Hangi metrik kullanmalƒ±yƒ±m?"
            ]
    
    def _ai_consultation_response(self, user_message: str, context: Dict) -> Dict:
        """
        Fallback to advanced AI when OpenAI fails
        """
        return self._advanced_ai_consultation_response(user_message, context)
    
    def _template_consultation_response(self, context: Dict) -> Dict:
        """
        Template-based consultation when AI is not available
        """
        if not context.get('project_type'):
            return {
                "response": "Merhaba! Projeniz i√ßin en uygun algoritmalarƒ± √∂nerebilmek i√ßin biraz daha bilgiye ihtiyacƒ±m var. Hangi t√ºr bir makine √∂ƒürenmesi problemi √ß√∂zmek istiyorsunuz?",
                "suggestions": [
                    "Veri sƒ±nƒ±flandƒ±rmasƒ± yapacaƒüƒ±m",
                    "Sayƒ±sal deƒüer tahmini (regresyon)",
                    "Veri k√ºmeleme i≈ülemi"
                ],
                "success": True
            }
        elif not context.get('data_size'):
            return {
                "response": f"Harika! {context['project_type']} projesi i√ßin size yardƒ±mcƒ± olabilirim. Veri setinizin boyutu nasƒ±l?",
                "suggestions": [
                    "1000'den az veri",
                    "1000-10000 arasƒ± veri",
                    "10000+ b√ºy√ºk veri seti"
                ],
                "success": True
            }
        else:
            return self._get_emergency_fallback()
    
    def _template_recommendations(self, context: Dict, recommendations: List[Dict]) -> Dict:
        """
        Template-based recommendations when AI is not available
        """
        # Track recommended algorithms
        for rec in recommendations:
            algo_name = rec.get('algorithm', '').lower()
            if algo_name and algo_name not in self.conversation_context['discussed_algorithms']:
                self.conversation_context['discussed_algorithms'].append(algo_name)
        
        response = f"üéØ **{context.get('project_type', 'ML').title()} Projesi i√ßin √ñnerilerim:**\n\n"
        
        for i, rec in enumerate(recommendations[:3], 1):
            response += f"**{i}. {rec['algorithm']}**\n"
            response += f"   ‚Ä¢ G√ºven Skoru: {rec['confidence_score']:.2f}\n"
            response += f"   ‚Ä¢ {rec.get('description', 'G√ºvenilir algoritma')}\n\n"
        
        response += "Bu algoritmalarƒ±n hangisi hakkƒ±nda daha fazla bilgi almak istersiniz?"
        
        suggestions = [rec['algorithm'] for rec in recommendations[:3]]
        
        return {
            "response": response,
            "suggestions": suggestions,
            "success": True
        }
    
    def _generate_smart_suggestions(self, context: Dict, recommendations: List[Dict]) -> List[str]:
        """
        Generate contextual suggestions based on recommendations
        """
        suggestions = []
        
        if recommendations:
            suggestions.append(f"{recommendations[0]['algorithm']} hakkƒ±nda detay")
            suggestions.append("Implementasyon √∂rneƒüi")
            suggestions.append("Performans kar≈üƒ±la≈ütƒ±rmasƒ±")
        
        return suggestions[:3]
    
    def _generate_context_suggestions(self, missing_info: List[str]) -> List[str]:
        """
        Generate suggestions based on missing information
        """
        if 'proje t√ºr√º' in str(missing_info):
            return [
                "Sƒ±nƒ±flandƒ±rma projesi yapƒ±yorum",
                "Regresyon analizi yapacaƒüƒ±m",
                "Veri k√ºmeleme yapacaƒüƒ±m"
            ]
        elif 'veri boyutu' in str(missing_info):
            return [
                "K√º√ß√ºk veri setim var (1000<)",
                "Orta boyut veri (1000-10000)",
                "B√ºy√ºk veri setim var (10000+)"
            ]
        else:
            return [
                "Daha fazla detay ver",
                "√ñrnek g√∂ster",
                "Ba≈üka yakla≈üƒ±m"
            ]
    
    def _get_enhanced_explanation(self, algorithm: str, context: Dict) -> str:
        """
        Get enhanced paragraph-style explanation for each algorithm
        """
        project_type = context.get('project_type', 'general')
        data_size = context.get('data_size', 'medium')
        
        explanations = {
            'XGBoost': {
                'classification': f"Bu gradient boosting algoritmasƒ±, sƒ±nƒ±flandƒ±rma problemlerinde √ßok y√ºksek doƒüruluk oranlarƒ± saƒülar. √ñzellikle {data_size} boyuttaki veri setlerde m√ºkemmel sonu√ßlar verir √ß√ºnk√º bir√ßok zayƒ±f √∂ƒüreniciyi birle≈ütirerek g√º√ßl√º bir model olu≈üturur. Eksik verilerle bile ba≈üarƒ±lƒ± √ßalƒ±≈ümasƒ± ve √∂zellik √∂nemini g√∂stermesi b√ºy√ºk avantajlarƒ±.",
                'regression': f"Sayƒ±sal tahminlerde √ºst√ºn performans g√∂steren bu algoritma, karma≈üƒ±k veri ili≈ükilerini yakalama konusunda uzman. {data_size.title()} veri setinizde trend analizi ve pattern recognition konularƒ±nda √ßok ba≈üarƒ±lƒ± olacak.",
                'general': "Hemen hemen her machine learning probleminde g√ºvenle kullanabileceƒüiniz, end√ºstri standardƒ± bir algoritma. Kaggle yarƒ±≈ümalarƒ±nƒ±n favorisi olmasƒ±nƒ±n sebebi y√ºksek performansƒ± ve esnekliƒüi."
            },
            'Random Forest': {
                'classification': f"Karar aƒüa√ßlarƒ±nƒ±n kollektif g√ºc√ºn√º kullanarak overfitting problemini √ß√∂zen akƒ±llƒ± bir yakla≈üƒ±m. {data_size.title()} veri setinizde hem hƒ±zlƒ± √ßalƒ±≈üacak hem de yorumlanabilir sonu√ßlar verecek. √ñzellik √∂nemini g√∂rmek i√ßin ideal.",
                'regression': f"Tahmin problemlerinde g√ºvenilirlik arƒ±yorsanƒ±z m√ºkemmel bir se√ßim. Bir√ßok karar aƒüacƒ±nƒ±n oybirliƒüi ile tahmin yaptƒ±ƒüƒ± i√ßin tek bir aƒüaca g√∂re √ßok daha stabil sonu√ßlar verir.",
                'general': "Ba≈ülangƒ±√ß i√ßin ideal √ß√ºnk√º hiperparametre ayarlamaya √ßok ihtiya√ß duymaz ve neredeyse her durumda makul sonu√ßlar verir. G√ºvenilir bir algoritma."
            },
            'Logistic Regression': {
                'classification': f"Basitliƒüi ve etkinliƒüi ile √∂ne √ßƒ±kan bu algoritma, {data_size} veri setlerde hƒ±zlƒ± sonu√ßlar verir. ƒ∞kili sƒ±nƒ±flandƒ±rmada √∂zellikle ba≈üarƒ±lƒ± ve sonu√ßlarƒ± anlamak √ßok kolay. Doƒürusal ili≈ükileri √ßok iyi yakalar.",
                'general': "Machine learning'e yeni ba≈ülayanlar i√ßin m√ºkemmel bir ba≈ülangƒ±√ß noktasƒ±. Hem hƒ±zlƒ± hem de yorumlanabilir sonu√ßlar verir."
            },
            'SVM': {
                'classification': f"Karma≈üƒ±k sƒ±nƒ±r √ßizgilerini √ßizme konusunda uzman bu algoritma, √∂zellikle doƒürusal olmayan ili≈ükilerin olduƒüu durumlarda √ßok ba≈üarƒ±lƒ±. {data_size} veri setlerde kernel trick sayesinde y√ºksek boyutlu problemleri √ß√∂zebilir.",
                'general': "G√º√ßl√º matematik temeli olan, teorik olarak saƒülam bir algoritma. √ñzellikle y√ºksek boyutlu verilerde etkili."
            },
            'Neural Network': {
                'classification': f"ƒ∞nsan beyninden ilham alan bu algoritma, √ßok karma≈üƒ±k pattern'leri √∂ƒürenebilir. {data_size} veri setiniz b√ºy√ºkse harika sonu√ßlar verecek, ancak parametre ayarlamasƒ± biraz sabƒ±r gerektirir.",
                'general': "Derin √∂ƒürenmenin kapƒ±sƒ±nƒ± a√ßan temel algoritma. Karma≈üƒ±k problemlerde √ßok g√º√ßl√º ama yeterli veri gerektir."
            }
        }
        
        if algorithm in explanations:
            if project_type in explanations[algorithm]:
                return explanations[algorithm][project_type]
            else:
                return explanations[algorithm]['general']
        else:
            return f"Bu algoritma {project_type} problemlerde g√ºvenilir sonu√ßlar verir ve veri setinizin karakteristikleriyle uyumlu √ßalƒ±≈üacaktƒ±r."
    
    def _get_emergency_fallback(self) -> Dict:
        """
        Emergency response when everything fails - should be used sparingly
        """
        # Generate diverse fallback responses with better context awareness
        fallback_responses = [
            "ü§î **√ñz√ºr dilerim, sorunuzu tam anlayamadƒ±m.** Makine √∂ƒürenmesi projeniz hakkƒ±nda daha net bilgi verebilir misiniz? Hangi t√ºr bir problem √ß√∂zmeye √ßalƒ±≈üƒ±yorsunuz?",
            
            "üîç **Biraz daha detay verebilir misiniz?** Projenizin amacƒ±nƒ± ve hangi t√ºr verilerle √ßalƒ±≈ütƒ±ƒüƒ±nƒ±zƒ± anlamak istiyorum. Bu ≈üekilde size daha iyi yardƒ±m edebilirim.",
            
            "üí° **Size daha iyi yardƒ±m edebilmek i√ßin** projenizin detaylarƒ±nƒ± √∂ƒürenmek istiyorum. Hangi alanda √ßalƒ±≈üƒ±yorsunuz ve ne t√ºr bir analiz yapmak istiyorsunuz?",
            
            "üéØ **Anladƒ±ƒüƒ±m kadarƒ±yla** bir makine √∂ƒürenmesi projesi √ºzerinde √ßalƒ±≈üƒ±yorsunuz. Hangi t√ºr bir problem √ß√∂zmeye odaklanƒ±yorsunuz? Sƒ±nƒ±flandƒ±rma, tahmin, yoksa ba≈üka bir ≈üey mi?"
        ]
        
        # Use hash of current time to ensure variety but avoid complete randomness
        import time
        response_index = int(time.time()) % len(fallback_responses)
        
        return {
            "response": fallback_responses[response_index],
            "suggestions": [
                "Veri sƒ±nƒ±flandƒ±rmasƒ± yapacaƒüƒ±m",
                "Sayƒ±sal tahmin modeli geli≈ütiriyorum", 
                "Veri k√ºmeleme i≈ülemi yapacaƒüƒ±m",
                "Hangi algoritma en uygun?"
            ],
            "success": True
        } 